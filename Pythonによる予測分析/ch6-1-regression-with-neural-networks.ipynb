{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of an MLP:  elements of a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEICAYAAAB74HFBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hc5Zn38e+t5iLLVZYsy733hsC0gA0GbAg1OIE0QsiyyRuSTd2QslmSbHaT7CakkbAkSyAJgWBTTDHFNogOtmUb23LvGvXe28zc7x8zIoNQGUmjOVPuz3Xp8sycc2Z+Gs/R3Oc8z3keUVWMMcYYY0z/JDgdwBhjjDEmmlkxZYwxxhgzAFZMGWOMMcYMgBVTxhhjjDEDYMWUMcYYY8wAWDFljDHGGDMAVkw5TEQ+ISIvRtrrikiuiHwunJlM/BnI50xETonIGv/t74jIH0ObzhhjgmPFVJiIyIUi8qaI1IpIlYi8ISJnq+pDqnp5uPM49brGWYEFSMBjnxGR153KFAqq+p+q2qeiTETyRaTB/+MRkZaA+98ZrKz9JSIPiMh/OJ3DOMe//zb7P6Ml/s/EiCC26/KgJVb/HjjBiqkwEJGRwDPAb4CxQDbwA6DVyVzGOEV8HP37o6oLVXWEqo4AXgPu6Livqv/pZDZjenC1/zO7DFgOfNvhPAYrpsJlDoCqPqyqHlVtVtUXVXVv56MAEblcRA77z2D9TkRe6Tii8K/7hojcLSI1InJCRM73P14gImUickvAc40SkT+LSLmInBaR73V8gXXxupeJyCH/6/4WkLC9OyZiiMg3ReSxTo/9RkR+6b+dKyL/JSLb/Z+VTSIyNmDdc/1nYGtE5F0RWRWwLFdEfiwibwBNwAz/opk9PN81/jNINf7t53eT+y4R+WvA/QsDchSIyGf68B7MFJGXRKRSRCpE5CERGR2w/JSIfENE9voz/11EhgYs/1cRKRaRIhH5nIioiMzyLxsiIv8jImdEpFRE7hWRYf5lq0TEJSJf9+/LxSJyq3/Z7cAngH/1n5V4Otjfx8QmVS0BXsBXVPW475nBZ8VUeBwBPCLyoIisE5ExXa0kIunARnxHGuOAw8D5nVZbCez1L/8b8AhwNjAL+CTw24DTvr8BRuH70roY+DRwazev+xjwPSAdOA5c0N9f1kS1vwJrO4oHEUkCPgb8JWCdTwOfBSYCbuDX/nWzgWeB/8B3BvYbwGMiMj5g208BtwNpwOlenm8O8DDwFWA8sBl4WkRSevoFRGQK8By+z/94fF82e/rwHgjwX/4884HJwF2d1vkosBaYDiwBPuN/7bXA14A1+PbJiztt91N8B1fL/Muzge8HLJ+Ab5/NBm4D7hGRMap6H/AQ8DP/mbOr+/D7mBgkIpOAdcCxIPc9M4ismAoDVa0DLgQU+ANQLiJPiUhmp1WvBPJV9XFV7fhSKem0zklV/ZOqeoC/4/tD/0NVbVXVF4E2YJaIJOL7Evy2qtar6ing5/i+zDq7EjigqhtVtR34ZReva2LHk/6j1xoRqQF+17FAVYuBV4H1/ofWAhWqmhew/V9Udb+qNgL/BnzU/3n7JLBZVTerqldVtwA78X2+Ojygqvmq6vZ/1np6vo8Bz6rqFv+6/wMM44MHGJ19AtjqPxPcrqqVqhp0MaWqx/yv2aqq5cAv+GBR9GtVLVLVKuBp/GcH8BVZf/L/jk34mvMBX9Mm8E/AV1W1SlXrgf8Ebgp43nZ8+3O7qm4GGoC5wWY3ceFJEakHCoAy4N8Jbt8zg8iKqTBR1YOq+hlVnQQswnfU+8tOq03Et4N0bKOAq9M6pQG3m/3rdX5sBL4zTCn84+gf/+3sLuJ19boFXaxnYsN1qjq64wf4f52WP4jvjzP+f//SaXngZ+M0kIzv8zYVWN+pULsQyOpm296ebyIBn19V9frX7eozHGgyvrOr/SIiGSLyiIgUikgdvrN16Z1WCzzYaMK3z0GnfanT7fHAcCAv4P153v94h0r/gVRXz20M+PbfNGAVMI/g972uuPHtb4GS8RX1pg+smHKAqh4CHsBXVAUqBiZ13PEfyU6ifyrw7RBTAx6bAhR2sW4xvi+gwNed3MV6Jj48CSwRkUXAh/E1LwUK/GxMwfc5q8BXOPwlsFBT1VRV/UnA+trF63X3fEUEfH4DPpddfYYDFQAze1mnJ//lz7lEVUfiKyiD7UP4vn2Y9/9uFfgOdhYGvD+j/J2Jg9HVe2filKq+gu975H8Ibt/ryhlgWqfHpvP+g3ATBCumwkBE5vk7lU7y358M3Ay83WnVZ4HFInKdv6/KF/H1oegzfzPgo8CPRSRNRKbi68vx1y5WfxZYKCI3+F/3y/19XRP9VLUFX9+9vwHbVfVMp1U+KSILRGQ48ENgo//z9lfgahG5QkQSRWSov1N1bwcE3T3fo8BVInKpiCQDX8d3BeybvTzfQ8AaEfmoiCSJyDgRWdbLNoHS8DWv1fj7onyzD9s+CtwqIvP9v897/aH8Z9b+ANwtIhng62cmIlcE+dyl/KPTvjHga924DHid3ve9JP/jHT/J+LqKfMX/HSUikoOv/+Ij4f9VopsVU+FRj6/j+Dsi0oiviNqP78vhPapaga+vys+ASmABvnbv/g6h8CWgETiBb2f7G3B/55UCXvcn/tedDbzRz9c0seFBYDEfbOLD/9gD+Jq6huIrvlHVAuBa4DtAOb6j5W/S+9+Z7p7vML6zQr/Bd1bnanyXhbf19GT+4u9KfPtXFb7O50t7yRDoB8AKoBbfgcbjwW6oqs/h6+v4MnAMeMu/qGMf/pb/8bf9TYhbCb5P1P8BC/zNOE8Gm8nELn+fvj/ju0ijt33v9/jOjHb8/Alfcf8nfP3+av3P9V1VfT5Mv0LMEF/3GBOJxDeMgQv4hKq+7HQeEz/8V8QdAib4L6DoeDwX+Kuq2mjjQRDfUA77gSGd+kIZY2KInZmKMP7TtKNFZAi+owzhg82BxgwafxH/NeCRwELKBEdErheRFP8QKD8FnrZCypjYZsVU5DkP35VIHc0a16lqs7ORTLwQkVSgDl8/jH93OE60+md8TS3HAQ/wBWfjGGMGmzXzGWOMMcYMgJ2ZMsYYY4wZgCSnXjg9PV2nTZvW7fLGxkZSU1PDFygIlil4kZirp0x5eXkVquro1Au2T4SGZQqe7ROhZ5mCE4mZYAD7hKo68nPWWWdpT15++eUelzvBMgUvEnP1lAnYqQ7tCx0/tk+EhmUKnu0ToWeZghOJmVT7v09YM58xxhhjzABYMWWMMcYYMwBWTBljjDHGDIAVU8YYY4wxA9BrMSUi94tImYjs72a5iMivReSYiOwVkRWhj2mMMcYYE5mCOTP1ALC2h+Xr8E2MOxu4Hd9kisZEvYEcSIjIWhE57F92Z/hSGxPZROSUiOwTkT0istPpPMaEQq/FlKq+im/m9e5cC/zZf+Xg28BoEckKVUBjHPQA/TiQEJFE4B7/8gXAzSKyYFCTGhNdVqvqMlXNcTqIMaEQikE7s4GCgPsu/2PFnVcUkdvxfemQmZlJbm5ut0/a0NDQ43InWKbgOZ2rxa2UNyvVLV5qWpWaVmVcUhv0IZOqvioi03pY5b0DCeBt/wTVWcA04JiqngAQkUf86x7o329jYpmq0tjmoa65neZ2D81tHlrdHlravTS3eWhxe2j3ePF4wetVPKp4vIrX/+8/boNXFa9X0fee2/8vGnD7HwuSat2sCvPva0yk+vmLhxnZ6OnXPhGKYkq6eKzLCf9U9T7gPoCcnBxdtWpVt0+am5tLT8udYJmCF45c7R4vJysaOVRSz5GSek5XNXGmqglXVROVjW0fWP+iScl8N7SZujuQ6OrxlV09gR1ghF6kZXJ7laNljbz1t62UN3upaFYqmr3UtioN7dDQpngcmCJVgNXZ6sR7pcCLIqLA//q/F/6Ry/aJkLNMvStq8PKb15u5fnr/9olQFFMuYHLA/UlAUQie15j3qCpnqprYcaqanaeq2Ouq5VhZA20eLwCJCUL26GFMHjuMyxdmMmnMcCaPHc7EUUPJSBtKxsghvP3Ga6GO1d2BhB1gOMjpTC3tHrafrOKVI+XsPFXFweJ62jwCtAKQPmIIk8eOYNGEIYwZnsLo4SmMTU1m5NBkhqUkMjTZ/5OU8N795MQEEkVISPB91n23A/597zYkiCCAiO9j2PFhFPnHYx0ceq8uUNUiEckAtojIIX93EsD2icFgmXr3X5sPkpRwktXThvcrVyiKqaeAO/xNGSuBWlX9QBOfMX1V19LOa0cq2HaolNeOVlBe7/syGjk0iaWTR/Oh2dOYl5XG3MyRzMxIZUhSYrgjdncgkdLN4yZGqSq7ztTw6I4Cnt1XTEOrm5SkBM6aMoZbL5hGQm0hN1yykkljhjMsJeyf04iiqkX+f8tE5AngHODVnrcyZvC4PV4e313IqrkZjBzS0K/n6LWYEpGHgVVAuoi4gH8HkgFU9V5gM3AlcAxoAm7tVxJjgPqWdp7bX8KmPYW8c6IKt1cZPTyZi2aPZ+WMseRMHcvsjBEkJHR18ifsujyQEJFyYLaITAcKgZuAjzuY0wyit09U8ostR9h+sorhKYlcuTiLq5Zkce70ce8VTrm5pczOTHM4qfNEJBVIUNV6/+3LgR86HMvEuVePllNe38r6nElQfqhfz9FrMaWqN/eyXIEv9uvVjfHbfaaaB988xfP5JbS0e5menso/XTSDS+dlsGzyaJISwz++bH8PJFTVLSJ3AC8AicD9qpof9l/ADKrSuhb+fVM+z+eXkJE2hLuuXsD6nMmkDgnFCf+YlQk84W9uTAL+pqrPOxvJxLuNeS7Gpqawem4Gbw5WMWXMYPF6lRfyS/jj6yfJO11N2tAkbjxrEjesmMTyyaM/0L8j3AZyIKGqm/EVWyYG5R4u4yt/30Nzm4dvXjGX2y6cztDk+G6+C4b/CtelTucwpkN1YxtbD5TxyXOnkpLU/4N2K6ZM2Kkqrx6t4GfPHyK/qI4pY4dz19ULuDFnMiPsqN5EuPtfP8mPnj3A3Mw07vnECmaOH+F0JGNMP23aU0ibx+tr4hsA++YyYXWsrJ7vb8rnzeOVTBozjLs/tpRrlmaTGBl9oIzp0a+2HuXurUdYu3ACd39sWdx3Jjcm2m3c5WLhxJHMzxo5oOexYsqERZvby72vHOe3Lx1jWEoid129gI+vHNhpVWPC6YE3TnL31iN8ZMUkfvqRxY704zPGhM7B4jr2F9Zx19UDn6DCiikz6A6X1PPlh3dzuLSeq5dO5PsfXsD4tCFOxzImaNsOlvKDZw5w2YJMfnbjEjuTakwM2JjnIjlRuGZZ9oCfy4opM2hUlQ15Lr6/aT8jhiTzf7fkcOn8TKdjGdMnRTXNfH3DuyzIGsmvb1puhZQxMaDd4+XJ3YWsmZ/J2NSUAT+fFVNmUHi8yvee3M9D75zhglnjuPtjy8hIG+p0LGP6xOtVvvLIHtwe5Z6Pr7A+UsbEiJcOlVHZ2DbgjucdrJgyIVff0s7du1rZX3GGz188k29eMdeO5k1UenjHGbafquJ/1i9lWnqq03GMMSGyMc/F+LQhXDR7fEiez4opE1LVjW186v53OFjp4acfWczHzp7idCRj+qW8vpWfPneI82aM4yMrBt6nwhgTGSoaWnn5UBm3XTg9ZBeSWDFlQqaioZVP/vEdTlY08i8rhlghZaLa3VuP0Nzu4UfXLXJ8AFljTOg8ubsQt1e58azQNPEB2LW9JiRqmtr4+B/e5lRlI/d/5myWjLc63USv05WNPLqjgJvOnsKsDBuU05hYoaps2Oli6eTRIZ0v04opM2DNbR4++8AOTlU0cf9nzuaCWelORzJmQH659SiJCcIdl8xyOooxJoT2F9ZxuLSe9SE8KwVWTJkBcnu8fPFvu9hdUMOvb17G+TOtkDLRraCqiU17CvnUuVPJHGlXoBoTSzbmFZCSlMDVSyaG9HmtmDID8tPnD/HSoTJ+eO0i1i7KcjqOMQP24JunEBE+e+F0p6MYY0Ko1e1h07tFXLFwAqOGJ4f0ua2YMv22aU8hf3jtJJ8+byqfOneq03GMGbCGVjd/31HAlYuzmDh6mNNxjDEhtPVAGTVN7SFv4gMrpkw/5RfV8q8b93LO9LH824cHPq+RMZHg8V0u6lvd3GZnpYyJORvzCsgaNXRQ+vVaMWX6rLnNw5cf3s2oYcnc8/EVJNuEryZGPLqzgIUTR7Js8minoxhjQqi0roVXjpRzw4rsQRlE2r4FTZ/9x7MHOF7eyC8+uiymJywWkbUiclhEjonInV0s/6aI7PH/7BcRj4iM9S87JSL7/Mt2hj+96auOGeRDOfaMMSYyPLG7EK/CR1YMzv5tgwGZPtlyoJSH3jnD7RfN4MLZsXvlnogkAvcAlwEuYIeIPKWqBzrWUdX/Bv7bv/7VwFdVtSrgaVarakUYY5sBeMw/g/y1IZhB3hgTOXxjSxWQM3UMM8YPzrhxdmbKBK22qZ3vPLGPBVkj+cblc52OM9jOAY6p6glVbQMeAa7tYf2bgYfDksyEnMerPLmniEvnhWYGeWNM5NhdUMPx8saQTWrcFTszZYL2k+cPUtXYxp8+czYpSTFfh2cDBQH3XcDKrlYUkeHAWuCOgIcVeFFEFPhfVb2vm21vB24HyMzMJDc3t9tADQ0NPS53QqxkOlTloaKhlRnJ1YPy+0Ti+wSRm8uYUNqY52JocgJXLh684XusmDJBeftEJQ9vL+CfL5rBouxRTscJh656KGo3614NvNGpie8CVS0SkQxgi4gcUtVXP/CEviLrPoCcnBxdtWpVt4Fyc3PpabkTYiVT7lP5DEk6wxevX0XqkND/WYzE9wkiN5cxodLS7uHpd4u4clEWaUNDO7ZUoJg/vWAGrs3t5TtP7GPK2OF8Zc0cp+OEiwuYHHB/ElDUzbo30amJT1WL/P+WAU/gazY0EcjrVZ7fX8LFc8YPSiFljHHOC/kl1Le4B/3CEiumTK/+/NYpTpQ38oNrFjIsJdHpOOGyA5gtItNFJAVfwfRU55VEZBRwMbAp4LFUEUnruA1cDuwPS2rTZ3tcNZTUtbB20QSnoxhjQmxjnotJY4Zx7oxxg/o6dhhmelTZ0Mqvth3l4jnjWT0vw+k4YaOqbhG5A3gBSATuV9V8Efm8f/m9/lWvB15U1caAzTOBJ0QEfPvY31T1+fClN32x9UApiQnCpfMznY5ijAmhwppmXj9WwZcvmU3CIIwtFciKKdOjX2w5QlObh+9dNd/pKGGnqpuBzZ0eu7fT/QeABzo9dgJYOsjxTIi8cqScs6aMYdSwwetPYYwJvyd2uVAlLGPHWTOf6dbR0noe3n6GT507ldmZaU7HMSbkyutbyS+q4+K5452OYowJIVVlY56Lc2eMZfLY4YP+elZMmW7dvfUIw5IT+fKls52OYsygeO1oOQAXz7FiyphYsuNUNacqm1h/1uTeVw4BK6ZMl/YX1rJ5Xwm3XTjdBjE0MeuVI+Wkj0hhQdZIp6MYY0JoY14BqSmJrFscngtLrJgyXfr5i4cZNSyZz100w+koxgwKr1d57WgFH5o9ftA7pxpjwqepzc2ze4u5akkWw1PC0zXciinzAXmnq3n5cDn/fPEMRg7iIGfGOOloWQNVjW2cN3NwL5k2xoTXc/tKaGzzcGOYmvggyGJKRNaKyGEROSYid3axfJSIPC0i74pIvojcGvqoJlzuefkYY4Yn85nzpzkdxZhB887JSgDOnW7FlDGxZENeAdPGDefsaWPC9pq9FlMikgjcA6wDFgA3i8iCTqt9ETigqkuBVcDP/QMdmihzsLiOlw6VcesF08N2etQYJ7xzooqsUUOZPHaY01HiiogkishuEXnG6Swm9pypbOLtE1XceNYk/GP9hUUwZ6bOAY6p6glVbQMeAa7ttI4CaeJLPgKoAtwhTWrC4t5XjpOaksgt501zOooxg0ZVeedkJefOGBfWP7gGgH8BDjodwsSmx3a5EIEbVgz+2FKBgjn1kA0UBNx3ASs7rfNbfFNtFAFpwMdU1dv5iUTkduB2gMzMzB5nK4/E2cxjPVNZk5en9jRzxbQkdm9/I2JyhUokZjLOOF7eSEVDGyunj3U6SlwRkUnAVcCPga85HMfEGK/XN7bUhbPSmTg6vGecgymmujps0073rwD2AJcAM4EtIvKaqta9byPV+4D7AHJycrSn2cojcTbzWM/0b0/uJzmxgB98/GIyRw6NmFyhEomZjDO2n6wCYOUgz9dlPuCXwL/iO+jukh10h168ZDpY6aGwpoUPT/H2+7n7myuYYsoFBHaJn4TvDFSgW4GfqKoCx0TkJDAP2N7nRMYRdS3tPLbLxdVLJw64kDIm0u06U8241BSmjRv8kZGNj4h8GChT1TwRWdXdenbQHXrxkumpv+8hbWgpX12/mqHJiWHNFUyfqR3AbBGZ7u9UfhO+Jr1AZ4BLAUQkE5gLnOhzGuOYDTtdNLV57Ao+Exd2n6lm+ZTR1l8qvC4ArhGRU/j63l4iIn91NpKJFfUt7WzeX8zVSyf2u5AaiF6LKVV1A3cAL+DrNPioquaLyOdF5PP+1X4EnC8i+4BtwLdUtWKwQpvQ8nqVv7x1ihVTRrN40iin4xgzqGqb2jle3sjyKeG7bNqAqn5bVSep6jR8B+UvqeonHY5lYsTmfcW0tHvDMqlxV4K69l1VNwObOz12b8DtIuDy0EYz4fLKkXJOVTbx1cvmOB3FmEG3x1UDwPLJox1OYowJlQ07Xcwcn+rYfm0joBsefOsU49OGsG5RltNRjBl0u89UI4KdhXWQquaq6oedzmFiw4nyBnaerubGsyY71nRvxVScO1nRSO7hcj6xcgopSfZxCBTEyP+rRKRWRPb4f74f7LbGObvP1DAnI400myrJmJjw2C4XCQI3rMh2LIMNcR3n/vLWaZIThY+vnOJ0lIgSMPL/ZfiuaN0hIk+p6oFOq77W+Qi7D9uaMFNV9hTUsHZheGaSN8YMLo9XeSyvkIvnjHf0SnQ7FRHHWt0eHt/t4vIFE8hIs+EQOglm5P/B2NYMIld1M7XN7dbEZ0yMeONYBSV1LWGd1LgrVkzFsa0HyqhpauejZzv7IYxQXY3839U55PP8E3w/JyIL+7itCbP8It84wgsnjnQ4iTEmFDbkuRg9PJk1CzIczWHNfHHs0Z0FTBw1lAtnpTsdJRIFM/L/LmCqqjaIyJXAk8DsILf1vYiN9hxyPWV69mgbApQd3UPuifB1VI3E9wkiN5cxwahtaueF/BJuPnsyQ5LCP7ZUICum4lRRTTOvHi3nS6tnkZhgAxd2odeR/wOnS1LVzSLyOxFJD2bbgO1stOcQ6ynTn0/tYFZGE1dcenHEZHJSpOYyJhhP7y2ize11vIkPrJkvbj2W50KViPgQRqheR/4XkQnivw5XRM7Btz9VBrOtcUZ+US2Lsq2/lDGxYEOei3kT0liU7XyzvZ2ZikNer7Ihz8X5M8cxxeYm65KqukWkY+T/ROD+jpH//cvvBW4EviAibqAZuMk/P2WX2zryi5j3lNe3UlrXav2ljIkBR0vrebeghu9dNT8ipoWyYioOvX2ykjNVTXzNRjzvURAj//8W+G2w2xpn5RfVArDAiiljot7GPBdJCcJ1yyPj2h5r5otDG3e6SBuaxNpFNtaOiR//uJLPmvmMiWZuj5fHdxeyel4G6SOGOB0HsGIq7jS3eXghv4SrFmc5MrO2MU45UFTH5LHDGDXMRj43Jpq9erSc8vpWxyY17ooVU3Fm26FSGts8XLNsotNRjAmr/KJaFmbZWSljot2GnS7GpaZwyTxnx5YKZMVUnNm0p4jMkUNYOX2c01GMCZv6lnZOVTZZ53NjolxVYxtbD5Zy7bJskhMjp4SJnCRm0NU0tZF7uIyrl0y0saVMXDlcUg9Y53Njot1Tewpp9yjrcyKniQ+smIorz+0vod2jXLssMq5+MCZcDpf6iqm5E9IcTmKMGYgNeS4WZY9kflZkHRhZMRVHNu0pZMb41IgY4MyYcDpSUk9qSiLZo4c5HcUY008HiurIL6rjxhWRdVYKrJiKG8W1zbxzsoprl2ZHxABnxoTT4dJ65kxIs8++MVFsY56L5ESJyNYVK6bixNPvFqGKXcVn4tLR0gbmZFgTnzHRqs3t5ck9hayZn8mY1BSn43yAFVNx4tm9xSzOHsX09FSnoxgTVhUNrVQ2tjHH+ksZE7VePlxGVWNbxHU872DFVBxwVTfxrquWdYttxHMTf474r+Sbm2nFlDHRasNOF+PThnDR7PFOR+mSFVNx4Pn9JQCsW5TlcBJjwu+I/0q+ORNGOJzEGNMf5fWtvHy4jBuWZ5MUQWNLBYrMVCaknt9fwrwJadbEZ+LS4dIGRg9PZnyEzOFljOmbTXsK8Xgjb2ypQFZMxbjSuhZ2nq7mysV2VsrEpyOl9czJtCv5jIlGqsqGnS6WTR7NrAi+iMSKqRj3Qn5HE5/1lzLxR1U5UlJv/aWMiVL7C+s4XFofUZMad8WKqRi3eV8xszJGMNu+TEwcKqlrob7VzZxM6y9lTDTakFdASlICVy+N7GF9rJiKYRUNrWw/WWVnpfpJRNaKyGEROSYid3ax/BMistf/86aILA1YdkpE9onIHhHZGd7kpkPHnHxz7GDCmKjT6vawaU8RVyycwKhhyU7H6VGS0wHM4HkxvxSv2lV8/SEiicA9wGWAC9ghIk+p6oGA1U4CF6tqtYisA+4DVgYsX62qFWELbT7gaGkDYMWUMdFo64EyapvbWR/hTXxgZ6Zi2nP7i5k6bjjzs+yLpB/OAY6p6glVbQMeAa4NXEFV31TVav/dt4HI3+PjzImKBsampkTkiMnGmJ5tyCsga9RQLpiV7nSUXtmZqRhV09TGW8cr+dyHZthVTP2TDRQE3Hfx/rNOnd0GPBdwX4EXRUSB/1XV+7raSERuB24HyMzMJDc3t9sXaGho6HG5EyI9U97RZtJTcDxjJL5PELm5jCmta+HVI+V8YdVMEhMi/zvMiqkYtfVgGW6vWn+p/utq79UuVxRZja+YujDg4QtUtUhEMoAtInJIVV/9wBP6iqz7AHJycnTVqlXdBsrNzaWn5U6I9EzfeH0Ll+qFXQoAACAASURBVM7LZNWqJRGTKZJEai5jHt9ViFfhxrMmOx0lKEE18/XWEde/zip/Z9t8EXkltDFNX209UErmyCEsmTTK6SjRygUE7sWTgKLOK4nIEuCPwLWqWtnxuKoW+f8tA57A12xowqi2qZ2KhjZmZthgtZFARIaKyHYRedf/PfEDpzOZyKSqbMgrIGfqmKgZbLrXYiqgI+46YAFws4gs6LTOaOB3wDWquhBYPwhZTZBa2j28erScS+dnWhNf/+0AZovIdBFJAW4CngpcQUSmAI8Dn1LVIwGPp4pIWsdt4HJgf9iSGwCOV/g6n89It2ERIkQrcImqLgWWAWtF5FyHM5kItLughhPljRE94nlnwTTzvdcRF0BEOjriBl7V9HHgcVU9A+8djRuHvH2ikqY2D2vmZzgdJWqpqltE7gBeABKB+1U1X0Q+719+L/B9YBzwO3/R6lbVHCATeML/WBLwN1V93oFfI66dKG8EYGaGFVORQFUVaPDfTfb/dNl0buLbhp0uhiUnctWSyB5bKlAwxVQwHXHnAMkikgukAb9S1T93fiLrbBt6XWX684FWUhLBXXiA3JKDEZPLaX3NpKqbgc2dHrs34PbngM91sd0JYGnnx014HS9vIDlRmDxmmNNRjJ+/pSMPmAXco6rvdLGOfU+EWDRlavMoT+5qYnlGEjvfej1icvUmmGIqmI64ScBZwKXAMOAtEXk7sOkDrLPtYOicSVX5zlsvcfHccVx+aU7E5IoEkZjJDJ4T5Q1MGTs8YmeZj0eq6gGW+buGPCEii1R1f6d17HsixKIp06Y9hTS793DHVWdx/szwD4nQ3/cqmL8ywXTEdQHPq2qjf5DCV7Ejc0ccKK6jqLbFmvhM3Dte3sjM8dbEF4lUtQbIBdY6HMVEmA07XUwaM4xzp49zOkqfBFNM9doRF9gEfEhEkkRkOL5mQGfal+LctoNliMAl8zKdjmKMY9weL6crG5lhxVTEEJHx/jNSiMgwYA1wyNlUJpIU1jTzxvEKPrJiEglRMLZUoF6b+YLpiKuqB0XkeWAv4AX+2PnUrQmPbQdLWTppNOPThjgdxRjHuKqbafcoM8dHx2XVcSILeNDfbyoBeFRVn3E4k4kgj+e5UIUbo2D6mM6CGrSzt464/vv/Dfx36KKZviqta+FdVy3fuHyO01GMcdTxcv+wCHZmKmKo6l5gudM5TGRSVTbucnHujLFMHjvc6Th9Zj0zY8hLh3wjUqxZYE18Jr69NyyCnZkyJirsOFXN6com1kfJiOedWTEVQ7YdLCV79DDmZtrExia+HS9vYFxqCqOH2wTHxkSDDTsLSE1JZN3i6JwCzYqpGNHc5uG1oxVctsBGPTfmRHkjM+yslDFRobHVzbP7irlqSRbDU6JzymArpmLEG8cqaHV7udSGRDCGExUNNiyCMVHiuf0lNLV5WJ8TnU18YMVUzNh2qJQRQ5JYGWVjcxgTao3tSkVDm52ZMiZKbNhZwLRxw8mZOsbpKP1mxVQM8HqVrQfLuHjOeFKS7L/UxLfiRi9gExwbEw3OVDbxzskqbjxrUlR3UbFv3hiwr7CW8vpWa+IzBihu8BVTNsGxMZFv4y4XInDDiugbWyqQFVMxYNvBUhIEVs+1YsqYkka1CY6NiQJer/JYnosLZ6UzcXR0769WTMWALQfLyJk6ljGpdhm4MSVNXqaOS7UJjo2JcG+fqKSwpjkqRzzvzP7aRLnKZi8Hi+usic8Yv+IGLzPSrfO5MZFuQ56LtKFJXLEwOseWCmTFVJTbU+4B4NL5Nuq5MW6Pl9ImtWlkjIlwzW7luf3FXL10IkOTE52OM2BWTEW53WUepqen2rQZg0BE1orIYRE5JiJ3drFcROTX/uV7RWRFsNuawVFQ3YxHbRoZYyLd9mI3Le1e1sdAEx9YMRXVGlrdHKr0cOm8jKi+pDQS+We2vwdYBywAbhaRBZ1WWwfM9v/cDvy+D9uaQXDCJjg2Jiq8Xuhm5vhUlk0e7XSUkLBiKoq9frQct9rExoPkHOCYqp5Q1TbgEeDaTutcC/xZfd4GRotIVpDbmkFgExwbE/lOlDdwtMbL+pzJMXMiIDonwTEAbDlQRmoyUT1qbATLBgoC7ruAlUGskx3ktgCIyO34zmqRmZlJbm5ut4EaGhp6XO6ESMv02v5WRiQre7a/6XSU94m096lDpOYysW1jngsBrl+e7XSUkLFiKkp5vMrLh8tYnJ5ol4APjq4OlzTIdYLZ1veg6n3AfQA5OTm6atWqbgPl5ubS03InRFqm3x16i4kjaiIqE0Te+9QhUnOZ2OXxKo/vKmTx+EQyRw51Ok7I2LdwlNpTUE1VYxvLM6weHiQuIHDWzUlAUZDrBLOtGQTHyxuYkGp/1oyJVK8fq6CkroUPZcfWd5f91YlSWw6UkZQgLE6P/ktKI9QOYLaITBeRFOAm4KlO6zwFfNp/Vd+5QK2qFge5rQmx2qZ2KhvbyLJiypiItTHPxejhySzLiK3vrtgqDePItoOlnDN9LMOTW5yOEpNU1S0idwAvAInA/aqaLyKf9y+/F9gMXAkcA5qAW3va1oFfI64cr/BdyZeVGhsdWo2JNbVN7byQX8LNZ08mOaHC6TghZcVUFDpd2cjRsgZuPmcKuE87HSdmqepmfAVT4GP3BtxW4IvBbmsG1/EyXzFlzXzGRKan9hbR5vZdxVdxNLaKKfurE4W2HiwDYI2Nem7Me05UNJKcKIwfZmemjIlEG/NczJuQxsKJI52OEnJWTEWhbQdLmZ0xginjhjsdxZiIcbysganjUklMsGLKmEhztLSedwtquPGsSTEztlQgK6aiTG1zO9tPVtlAncZ0cqKi0QbrNCZCbchzkZQgXBdDY0sFsmIqyuQeLsPtVdbMz3A6ijERo93j5XRlIzNtGhljIo7b4+XxXYWsnpdB+oghTscZFFZMRZmtB8tIH5HCssk26rkxHQqqmmj3qBVTxkSgV46UU9HQGjOTGnfFiqko0ub2knu4jEvnZVq/EGMCHO+Yky/DiiljIs3GPBfjUlNYPS92W1SsmIoi209WUd/itv5SxnRyvNw3LMIM6zNlTESpamxj68FSrlueTXIMT30Wu79ZDNp6sJShyQlcOCvd6SjGRJTjZQ1kpA1h5NBkp6MYYwJs2lNIu0e5MYab+MCKqaihqmw5UMqFs8YzLCW2huE3ZqCOlzdYfyljItDGPBeLskcyPyv2xpYKZMVUlDhYXE9hTTOXLYjdNmdj+kNVOV7eyMwMa+IzJpIcKKojv6iO9WdN7n3lKGfFVJTYcqAUEbhknvWXMiZQZWMbtc3tdmbKmAizMc9FSmIC1yyd6HSUQRdUMSUia0XksIgcE5E7e1jvbBHxiMiNoYtowNdfavnk0YxPi80xOozpr445+ayYimwiMllEXhaRgyKSLyL/4nQmM3ja3F6e3FPImgUZjElNcTrOoOu1mBKRROAeYB2wALhZRBZ0s95PgRdCHTLeFdc2s6+wlssWTHA6ijERx4ZFiBpu4OuqOh84F/hiV98lJja8dKiMqsa2mO943iGYM1PnAMdU9YSqtgGPANd2sd6XgMeAshDmM/xjYmPrL2XMBx0vb2BYciJZI4c6HcX0QFWLVXWX/3Y9cBCIzblFDBvzXGSkDeGi2eOdjhIWSUGskw0UBNx3ASsDVxCRbOB64BLg7O6eSERuB24HyMzMJDc3t9sXbWho6HG5E5zK9OjOFjKHCwX5O3EdeP9gnZH4PkFk5orETGbgjpc3MGN8Kgk2kG3UEJFpwHLgnS6W2fdEiIU7U22r8tKhJtZOS+b1116NiEzB6m+uYIqprv5Caaf7vwS+paqenmaDVtX7gPsAcnJydNWqVd2um5ubS0/LneBEpoZWN4e3bOGW86exevUHz4hH4vsEkZkrEjOZgTte3sBym14paojICHytGF9R1brOy+17IvTCnekPr57Aqwf52vXnMSsjLSIyBau/uYJp5nMBgdc1TgKKOq2TAzwiIqeAG4Hfich1fU5jPuDVI+W0ebysmW9X8YWTiIwVkS0ictT/7we+rXvqUCsid4lIoYjs8f9cGd7fID60tHtwVTdb5/MoISLJ+Aqph1T1cafzmNBTVTbmuVg2eXS3hVQsCqaY2gHMFpHpIpIC3AQ8FbiCqk5X1WmqOg3YCPw/VX0y5Gnj0Iv5JYwZnsxZU+3IO8zuBLap6mxgm/9+Z711qL1bVZf5fzYPfuT4c7KiEVVsjKkoIL5mi/8DDqrqL5zOYwbHvsJaDpfWsz4nPjqed+i1mFJVN3AHvqv0DgKPqmq+iHxeRD4/2AHjWavbw7aDZVy2IJOkGJ7TKEJdCzzov/0g8IEzrdah1nkdc/LZmamocAHwKeASO2MbuzbmuRiSlMCHl8T+2FKBgukzhf+oenOnx+7tZt3PDDyWAXjjWAX1rW7WLcpyOko8ylTVYvAVTSLS46WU3XSovUNEPg3sxHcGq7qL7ayz7QBsO9aGAAUH8ig9LBGRqSuRmAnCm0tVX6frPrgmRrS0e9i0p4grFk5g1LD4miczqGLKOOO5fSWkDU3i/FnjnI4Sk9asWUNJSUnH3YUist9/+7t9eZ5uOtT+HvgRvos1fgT8HPhs522ts+3APFa8m+wx1Vx+6eqIydSVSMwEkZvLRKetB0upbW6Pm7GlAlkxFaHaPV5ePFDKmvmZDEmyiY0Hw9atW9+7LSL5qpoTcL9URLL8Z6Wy6Gb8tO461KpqacA6fwCeGYRfIe4dLa1nTmb8dHI1JpJtzHORNWooF8xKdzpK2FlHnAj19olKapvbWbfIRj13yFPALf7btwCbOq/QU4dafwHW4XpgPyak2j1ejpc3WDFlTAQoqW3h1SPlfGTFJBLjcMw3K6Yi1OZ9JQxPSeSiOfExemwE+glwmYgcBS7z30dEJopIR//BnjrU/kxE9onIXmA18NUw5495pysbafcoczKt87kxTntidyFehY/EYRMfWDNfRPJ4lRfzS7hkXgZDk62JzwmqWglc2sXjRcCV/tvddqhV1U8NakDD4RLflXx2ZsoYZ6kqG/IKOHvaGKanx+cwJXZmKgJtP1lFZWObXcVnTA8Ol9aTIDDLJjg2xlG7ztRworwxLjued7BiKgI9t7+YockJrJprTXzGdOdoaT1Tx6Xa2VtjHLYxz8Ww5ESuirOxpQJZMRVhvF7l+f0lXDxnPKlDrBXWmO4cLq23/lLGOKy5zcMz7xaxbvEERsTxd5YVUxFm15lqyupbuXKxNfEZ052Wdg+nK5usv5QxDnshv4T6VndcN/GBFVMR5+l3i0hJSuCSeT0OuG1MXDtR3ojHq1ZMGeOwjXkuJo0ZxrnT43twaSumIojb4+WZvcWsmZ9B2tD4GorfmL44UloPwNwJVkwZ45TCmmbeOF7BR1ZMIiEOx5YKZMVUBHnjeCWVjW1cs9TmyjWmJ0dK60lKEKaNi8/LsI2JBI/nuVAl7pv4wIqpiLJpTyFpQ5PsKj5jenGktJ4Z41NJSbI/YcY4QVXZuMvFeTPGMXnscKfjOM7+EkWIlnYPL+wvYd2iCXaptzG9OGxz8hnjqO0nqzhd2WRnpfysmIoQ2w6W0djm4dpl1sRnTE/qWtopqGpmnvWXMsYxG/NcjBiSxLrFNn8sWDEVMZ7cU0hG2hDOnRHfV0QY05sDRXUALMwe5XASY+JTY6ubZ/cVc9XiLIanxO/YUoGsmIoAtU3t5B4u4+qlE+Nytm1j+iK/o5iaONLhJMbEp+f2l9DU5uHGHGvi62DFVAR4dl8x7R7lmqXxOxS/McHKL6wlI20IGWlDnY5iTFzasLOAaeOGkzN1jNNRIoYVUxHg0Z0FzMkcwZJJ1mxhTG/yi+rsrJQxDjlT2cQ7J6u48axJiFhLSgcrphx2pLSePQU1fDRnsn0wjelFS7uHY+UNLJxoBx7GOGHjLhcicMMKa+ILZMWUwzbsLCApQbhuuV3FF0lEZKyIbBGRo/5/uzyfLSKnRGSfiOwRkZ193d70zeGSejxeZVG2nZkyJty8XuWxPBcXzkpn4uhhTseJKFZMOajN7eXxXYWsmZ9J+oghTscx73cnsE1VZwPb/Pe7s1pVl6lqTj+3N0HaX1QLYGemjHHA2ycqKaxptrGlumDFlINeOlRGZWMbHz3bPpgR6FrgQf/tB4Hrwry96UJ+UR0jhyYxaYwdFRsTbhvyXKQNTeKKhTa2VGdWTDlow84CMkcO4aLZNn1MBMpU1WIA/78Z3aynwIsikicit/dje9MHvs7no6x/oTFhVtfSznP7i7l66USbpaMLNtqWQ0rrWnj5cBmfv3gmSYlW0zphzZo1lJSUdNxdKCL7/be/24enuUBVi0QkA9giIodU9dVgN/YXYLcDZGZmkpub2+26DQ0NPS53QjgzebzKgcImLpmSZO9TiERqLhN5Nu8tpqXdy3pr4uuSFVMOeXRHAV6F9TmTnY4St7Zu3frebRHJD+zzJCKlIpKlqsUikgWUdfUcqlrk/7dMRJ4AzgFeBYLd/j7gPoCcnBxdtWpVt3lzc3PpabkTwpnpUEkd7S++xtqVC1m1vPs/6PH+PvVFpOYykWdDnotZGSNYNnm001Eikp0ScYDb4+Whd87wodnpTE9PdTqO6dpTwC3+27cAmzqvICKpIpLWcRu4HNgf7Pamb/acqQFg2WS7MNKYcDpe3kDe6WobW6oHVkw5YMuBUkrqWvj0edOcjmK69xPgMhE5Clzmv4+ITBSRzf51MoHXReRdYDvwrKo+39P2pv92n6lh9PBkpo0b7nQUY+LKY3kuEgRusCF8umXNfA7481unyR49jEvmWZ/kSKWqlcClXTxeBFzpv30CWNqX7U3/7S6oZvnk0XZkbEwYebzK47sKuXjOeDJG2hRO3bEzU2F2pLSet05U8slzp9qkxsYEqa6lnaNlDSyfYk18xoTT68cqKKlrsf69vbBiKswefPMUKUkJfOxs+2AaE6y9BbWowvIp1vk1monI/SJSFnDlrIlwG3YWMHp4MpfOt5aUngRVTInIWhE5LCLHROQDIzmLyCdEZK//500R6bLpI95VNLSyMc/F9cuyGZua4nQcY6LG7jPViMBSu5Io2j0ArHU6hAlObVM7Lx4o5dqlExmSZGNL9aTXYkpEEoF7gHXAAuBmEVnQabWTwMWqugT4Ef5Lvc37/fmt07S6vfzTRTOcjmJMVMk7U82s8SMYOTTZ6ShmAPxjsFU5ncME56m9RbS5vdbEF4RgOqCfAxzzd7ZFRB7BN1XGgY4VVPXNgPXfBmxUr06a2zz85a1TrJmfyayMEU7HMSZquD1edp6q5tplE52OYsLABrINvf5muv+tZianJVB+ZBe5R0PbxzcS3yfof65giqlsoCDgvgtY2cP6twHPdbUgnneSrafbqW5q55yRtSH9vSLxfYLIzBWJmUzvDhTX0dDqZuWMcU5HMWFgA9mGXn8yHSmt5+Tzr/K9q+az+kOhb02JxPcJ+p8rmGKqq3JUu1xRZDW+YurCrpbH607S7vHyb9tzWT5lNP903fkhvbQ7Et8niMxckZjJ9O6dE75WoXOnj3U4iTHxY2Oei6QE4TobWyoowXRAdwGBDaaTgKLOK4nIEuCPwLX+MXaM3xO7CimoauZLl8yyMXKM6aN3TlYyPT3VxrgxJkzaPV4e31XI6nkZpI8Y4nScqBBMMbUDmC0i00UkBbgJ31QZ7xGRKcDjwKdU9UjoY0avdo+X37x8lCWTRrF6rl1aakxfeLzK9pNVrLSzUjFBRB4G3gLmiohLRG5zOpP5oFePlFPR0GqTGvdBr818quoWkTuAF4BE4H5VzReRz/uX3wt8HxgH/M5/5sUdOGlsPHt8l4uCqmZ+cM1COytlTB8dLK6jrsXNyhlWTMUCVb3Z6Qymdxt2uhiXmsJqm6UjaEFNJ6Oqm4HNnR67N+D254DPhTZa9Gtze/nNS8dYameljOmXV46UA3DBrHSHkxgTH6oa29h2qJRPnzeN5EQb1ztY9k4Nor+9cxpXdTNfvWyOnZUyph9eOVLOwokjyUiz/lLGhMOmPYW0e5QbrYmvT6yYGiS1ze38attRLpyVzsVzxjsdx5ioU9/Szq7T1bb/GBNGG3a6WJQ9kvlZI52OElWsmBokv8s9Rk1zO9++cp6dlTKmH948Xonbq1ZMGRMm+UW1HCiuY/1ZNuJ5X1kxNQgKqpr40xunuGH5JBZOHOV0HGOiUu7hckYMSWLF1DFORzEmLmzMc5GSmMA1S222gb6yYmoQ/PCZAySK8I0r5jgdxZio5PEqWw6UctGcdOsEa0wYtLm9bNpTxJoFGYxJTXE6TtSxv1IhtuVAKVsOlPIva2aTNWqY03FMP4nIWBHZIiJH/f9+4PSIiMwVkT0BP3Ui8hX/srtEpDBg2ZXh/y2iV97paioaWlm7KMvpKMbEhZcOlVHV2GZNfP1kxVQINbW5ueupfOZkjuC2C6c7HccMzJ3ANlWdDWzz338fVT2sqstUdRlwFtAEPBGwyt0dy/3Di5ggPbe/mJSkBC6xcW6MCYuNeQVkpA3hQ7NtGJL+sGIqhO7ecoTCmmZ+fP1ia5qIftcCD/pvPwhc18v6lwLHVfX0oKaKA6rKC/tLuGh2OiOGBDUUnjFmAMrrW3n5cDnXr8gmyb67+sX+UoXI9pNV/PH1k3x85RTOnmajNceATFUtBlDVYhHp7RTJTcDDnR67Q0Q+DewEvq6q1Z03EpHbgdsBMjMzyc3N7fYFGhoaelzuhMHIdKzaQ1FtC1dO8fbruePlfQqFSM1lwuvJ3YV4vGrTxwyAFVMh0NDq5usb9jB5zHC+e+V8p+OYIK1Zs4aSkpKOuwtFZL//9nf78jz+OSuvAb4d8PDvgR8B6v/358BnO2+rqvcB9wHk5OToqlWrun2d3NxcelruhMHI9OIT+xiWXMhXblzdrzNT8fI+hUKk5jLho6psyCtg2eTRzMpIczpO1LJiKgT+45kDuKqb2fDP55FqzRJRY+vWre/dFpH8wPkkRaRURLL8Z6WygLIenmodsEtVSzseCLwtIn8Anglp+BjV0u7h6XeLWLdogjXxGRMG+wprOVLawI+vX+R0lKhmjaMD9PguF4/sKOALF88kx5r3YslTwC3+27cAm3pY92Y6NfH5C7AO1wP7Mb16Ib+E+hY3N+ZYc4Mx4bBhp4shSQl8eImNLTUQVkwNwKGSOr7zxD5WTh/L1y6zMaVizE+Ay0TkKHCZ/z4iMlFE3rsyT0SG+5c/3mn7n4nIPhHZC6wGvhqe2NHtke0FZI8exrnTxzkdxZiY19Lu4al3i7hi4QRGDUt2Ok5Us/Po/VTb1M4X/rqLkUOT+c3Hl9sVEDFGVSvxXaHX+fEi4MqA+03AB775VfVTgxowBuUX1fLWiUq+vW4eCQk2BZMxg23rwVJqm9tZb2eCB8yKqX5odXu4/S87Kaxu5qF/Wmkz2hsTAve/forhKYncdM4Up6MYExc27HSRNWoo58+0saUGyk6n9JGq8q2Ne3nnZBX/vX6JDYNgTAiU1bXw9LtFrD9rkjU3GBMGJbUtvHa0nI+smESinQkeMCum+kBV+eEzB3hyTxHfvGIu1y7LdjqSMTHhty8fw6vKbRfOcDqKMXHh8d0uvAo32thSIWHNfEFSVR453MYLp07x2Qum8/9WzXQ6kjExoaCqiYe3n+GjZ09myrjhTscxJuapKht3ujh72himpac6HScm2JmpIHi9yo+eOcgLp9zcct5U/u3D8xGx06LGhMIvthxBRPjyJbOdjmJMXNh1poYTFY02qXEI2ZmpXrS6PXxjw16efreIy6Ymcdc1C62QMiZE3jxewRO7C7lj9SwmjLILOYwJh415BQxLTuTKJVm9r2yCYsVUDyoaWvniQ7t452QVd66bx1zvGSukjAmRlnYP33tyP1PGDueOS2Y5HceYuNDc5uGZd4tZt9hmGQgla+brxu4z1Vz9m9fZU1DDLz+2jM9fPNMKKWNC6L82H+REeSP/cd0ihiYnOh3HmLjwQn4J9a1ua+ILMStLO3F7vPzvqyf45dYjZI4cymNfOJ9F2aOcjmVMTHl+fzEPvnWa2y6czkVzxjsdx5i4sSGvgEljhrFyug3rE0pWTAU4UlrPnY/tZdeZGq5anMWPr1/E6OEpTscyJqa8W1DDV//+LksnjeJba+c5HceYuOGqbuLN45X8y6WzbZaBELNiCt/UMHdvPcJf3j7NiCFJ/OqmZVyzdKI16xkTYkdK6/nsAzsYNyKFP9ySQ0qS9TQwJlwe31WIKnxkhY0tFWpxXUw1tbl56O0z/P6V49Q0tfHxlVP4+mVzGZNqZ6OMCbXdZ6q59YEdpCQm8OBnz7FpmIwJI1VlY56L82aMY/JYG88t1OKymKppauOhd87wf6+fpKqxjQtmjeM7V85n4UTrG2VMqKkqj+wo4N835ZM5agh/vW0lU8fZQIHGhNP2k1WcqWriK2tsPLfBEDfFlKqSd7qav71zhmf2FdPm9rJq7ni+dMlszpo6xul4xsSkwppmvv/kfrYdKuNDs9P51U3LGWtnfo0Juw15LkYMSWLtoglOR4lJMV1MqSr7Cmt5dl8xm/cVU1DVzIghSXw0ZxKfWDmV+VkjnY5oTEwqrWvhdy8f4+HtBSQkwPeums+tF0y3CVWNcUCLW9m8r5irl0xkeEpMf+07Jube1eLaZt44VsnrR8t5/VglFQ2tJCUIF8xK50uXzOaqxVmk2kBlxoRcU5ubV4+UszGvkNzDZQCsz5nEHZfMJnv0MIfTGRO/dpS4aWrzsD7HOp4PlqitKlSV8oZWDhXXs9dVw7uuWva6aiitawUgfUQKF8xK50Ozx7NmfoYNcWD6RETWA3cB84FzVHVnN+utBX4FJAJ/VNWf+B8fC/wdmAacAj6qqtWDHjxMVJXSulZ2l7nZteUIeaer2HGymjaPl/FpQ7jtcrAbmQAACSFJREFUQ9P5xDlTbeJi8z7d7S9mcL1e6GZ6eqp1aRlEQRVTve0A4htD4FfAlUAT8BlV3TXQcE1tboprWyipbaG4toXimmZOVjRyvKKRE2UN1Le631t3Rnoq580Yx5JJozl3xjjmTUizcTTMQOwHbgD+t7sVRCQRuAe4DHABO0TkKVU9ANwJbFPVn4jInf773xr82H3j9nhpdft+2txeWt0eWt1emto81DS1UdvcTnVjGzX+fwtrmimoaqaguommNg8ACXKUOZlpfOaCaVw8Zzwrp48lKdGGPDDv18v+YgbJ4ZJ6Dld7+eYVk2y4n0HUazEV5A6wDpjt/1kJ/N7/b5+V1bXw6fu3U1DZSOPzL3xgedaoocwYn8r1K7KZkZ7K7Mw0FmWPYtSw5P68nDFdUtWDQG9/fM4BjqnqCf+6jwDXAgf8/67yr/cgkEs/i6mCqiZufWAHjY1NDNuZi1cVBd+/Cqr/uO3V/9/e/YbIcddxHH9/LnfX/E/axiSXS2orzZP2keUoaVUMVCWkYsgTWxQa9EEIGFGIoBCQQp9YRB8IaonYB5WKCBobakqr4CmiqW1ik/RI1EQiiYlpbCT1mrRpel8fzFzcXGd3f7e7szt393nBcrM7053PzOwn/Do7uxtMBED2N/L7ExFQMz8I3nk3eDdbOMnS+f2sWb6Adbcs5P47b+X2Wxdx9fxJPvvgR30dhqVo1JdpOf6vN/jij//Mm5cvs+jQbzscsz1Vy3Rh/G2WDMCnR/zzMWVK+RcwpQBbgKciIoADkpZLGoqIc9MNtHTBALfdspDhwSuM3HUnq5fdxOqlCxhaNp/Vy+b7N7ysSoaB0zX3z/D//4lYNfn6j4hzklYWPYGk7cB2gFWrVjE6OvqeZf7z1gTLdZWlCyYY6H8LCQQg6EPX71//Wzv9nnnZ8tDHQB8MzIOBPmXTfdDfBwPzxGAfLB4QiwbE4kGxsJ/84vEJYDy7Xb3A+MAV/vSH37e3FztsfHy8cD/2UhUzQddzNerLdSmdOP/mBMt0lcU3TTBPV8pJ26KqZbp5KXxkZTB28I+9jnKD2daJlMFUSgGKlhkGbhhMpZQE4DO3wfj4OyzmNFyCty/BqdPZhSe9VMWDX8VMUM1cUzPt2rWLixcvTt69W9Kr+fTuiHgm4SmLTluln+oBImIPsAdgZGQkNm7cWLjc1k0wOjpKvfm94kxpqpgJup4rqS+pnXjowWruV2dKU8VM0HqulMFUSgE6WhKo5o52pnRVzDU108GDB69PSxqLiJFpPuUZoPbc+VrgbD59fvLsrKQh4LWWQpvNHo36YjajpVwlmlIAl8TmopeA9ZLukDQIPAzsy+ftA7bl09uAlDNdZrNZo76YzWgpg6mUAuwDHlFmA3CpleulzKpC0lZJZ4D7gF9Kej5/fI2k/QARcQ3YCTwPHAN+GhFj+VN8A/i4pL+RfXjDHwG3Oa1JX8xmtKZv80XENUmTBZgHPBkRY5J25POfAPaTfS3CCbKvRvhceZHNyhcRe4G9BY+fJXutT97fT/b6n7rc68ADZWY0m2nq9cVspkv6PHNRAfJB1OR0AF/obDQzMzOz6vM365mZmZm1wYMpMzMzszZ4MGVmZmbWBmWXO/VgxdIF4B8NFlkB/LtLcVI5U7oq5mqU6f0R8b5uhpnKnegYZ0rnTnSeM6WpYiZosRM9G0w1I+nlFr5EsVTOlK6KuaqYaTqqmN+Z0lQxE1Q3V6oq5nemNFXMBK3n8tt8ZmZmZm3wYMrMzMysDVUeTO3pdYACzpSuirmqmGk6qpjfmdJUMRNUN1eqKuZ3pjRVzAQt5qrsNVNmZmZmM0GVz0yZmZmZVZ4HU2ZmZmZtqMxgStKjkv4p6ZX8trnOcpsk/UXSCUlfKznTNyUdl3RE0l5Jy+ssd0rS0Tz3yyVlabjdynwnn39E0j1l5KhZ3zpJv5F0TNKYpC8VLLNR0qWaY/r1MjPVrLfh8ej2vmqVO9E0izuRnm3Gd6KKfcjX507UzzN3OhERlbgBjwJfabLMPOAk8AFgEDgM3FVipk8A/fn048DjdZY7BawoMUfT7QY2A88BAjYAL5Z8vIaAe/LpJcBfCzJtBJ7twWup4fHo9r5qYzvciTa2251IPx4zoRNV7EO+TneifqY504nKnJlKdC9wIiL+HhFXgZ8AW8paWUS8EBHX8rsHgLVlrauJlO3eAjwVmQPAcklDZQWKiHMRcSif/i9wDBgua30d1tV9VTJ3wp3ohNnSia72AdyJRuZSJ6o2mNqZn057UtLNBfOHgdM198/QvQPzebJRapEAXpB0UNL2Etadst092zeSbgc+CLxYMPs+SYclPSfp7m7kofnx6OXraLrciWLuxPTMlk5UuQ/gTtQ12zvR3+FwDUn6NbC6YNZu4PvAY2Qb+BjwLbIX5g1PUfDftvXdDo0yRcQz+TK7gWvA03We5kMRcVbSSuBXko5HxO/ayTU1ZsFjU7e74/smhaTFwM+AL0fEG1NmHyL7LaPx/PqGXwDry85E8+PRk31VxJ1oPWbBY+5EfTOiE1XsQ7Nc7kRzc6ETXR1MRcTHUpaT9APg2YJZZ4B1NffXAmfLzCRpG/BJ4IHI30gteI6z+d/XJO0lO93ayZKkbHfH900zkgbICvJ0RPx86vza0kTEfknfk7QiIkr9ccuE49H1fVWPO9Eyd2IaZkonqtiHlFzuRH1zpROVeZtvynuRW4FXCxZ7CVgv6Q5Jg8DDwL4SM20Cvgp8KiIu11lmkaQlk9NkFyMWZW9HynbvAx7JP4GwAbgUEec6nOM6SQJ+CByLiG/XWWZ1vhyS7iV7vb1eVqZ8PSnHo6v7qlXuREPuRHquWdGJKvYhz+VO1DGnOhFdvoK+3g34EXAUOJJvxFD++Bpgf81ym8k+EXCS7BRrmZlOkL1n+kp+e2JqJrJPThzOb2NlZSrabmAHsCOfFvDdfP5RYKTkffNhslOeR2r2z+YpmXbm++Qw2YWZ93fhdVR4PHq5r9rYFneicRZ3Ii3XrOhEFfuQr8+dqJ9nznTCPydjZmZm1obKvM1nZmZmNhN5MGVmZmbWBg+mzMzMzNrgwZSZmZlZGzyYMjMzM2uDB1NmZmZmbfBgyszMzKwN/wMljeevJO3zIwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-5, 5, 200)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10,4))\n",
    "ax[0].plot(x, 1/(1+np.exp(-x)))\n",
    "ax[0].set_title('Sigmoid')\n",
    "     \n",
    "ax[1].plot(x, np.tanh(x))\n",
    "ax[1].set_title('Hyperbolic Tangent')\n",
    "\n",
    "ax[2].plot(x, np.maximum(0, x))\n",
    "ax[2].set_title('ReLU')\n",
    "\n",
    "for p in ax:\n",
    "    p.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "FILE_NAME = 'diamonds.csv'\n",
    "data_path = os.path.join(DATA_DIR, FILE_NAME)\n",
    "diamonds = pd.read_csv(data_path)\n",
    "## Preparation done from Chapter 2\n",
    "diamonds = diamonds.loc[(diamonds['x']>0) | (diamonds['y']>0)]\n",
    "diamonds.loc[11182, 'x'] = diamonds['x'].median()\n",
    "diamonds.loc[11182, 'z'] = diamonds['z'].median()\n",
    "diamonds = diamonds.loc[~((diamonds['y'] > 30) | (diamonds['z'] > 30))]\n",
    "diamonds = pd.concat([diamonds, pd.get_dummies(diamonds['cut'], prefix='cut', drop_first=True)], axis=1)\n",
    "diamonds = pd.concat([diamonds, pd.get_dummies(diamonds['color'], prefix='color', drop_first=True)], axis=1)\n",
    "diamonds = pd.concat([diamonds, pd.get_dummies(diamonds['clarity'], prefix='clarity', drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diamonds.drop(['cut','color','clarity','price'], axis=1)\n",
    "y = diamonds['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaito\\AppData\\Local\\Temp\\ipykernel_18792\\1275030885.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['dim_index'] = pca.transform(X_train[['x','y','z']]).flatten()\n",
      "C:\\Users\\Kaito\\AppData\\Local\\Temp\\ipykernel_18792\\1275030885.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.drop(['x','y','z'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1, random_state=123)\n",
    "pca.fit(X_train[['x','y','z']])\n",
    "X_train['dim_index'] = pca.transform(X_train[['x','y','z']]).flatten()\n",
    "X_train.drop(['x','y','z'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaito\\AppData\\Local\\Temp\\ipykernel_18792\\2339634155.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, numerical_features] = scaler.transform(X_train[numerical_features])\n"
     ]
    }
   ],
   "source": [
    "numerical_features = ['carat', 'depth', 'table', 'dim_index']\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numerical_features])\n",
    "X_train.loc[:, numerical_features] = scaler.transform(X_train[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the MLP for predicting diamond prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "nn_reg = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = X_train.shape[1]\n",
    "n_hidden1 = 32\n",
    "# first hidden layer\n",
    "nn_reg.add(Dense(units=n_hidden1, activation='relu', input_shape=(n_input,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden2 = 16\n",
    "n_hidden3 = 8\n",
    "# add second hidden layer\n",
    "nn_reg.add(Dense(units=n_hidden2, activation='relu'))\n",
    "# add third hidden layer\n",
    "nn_reg.add(Dense(units=n_hidden3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "nn_reg.add(Dense(units=1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13838723],\n",
       "       [-0.01856311],\n",
       "       [ 0.09687743],\n",
       "       [ 0.05564625],\n",
       "       [-0.13368006]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_reg.predict(X_train.iloc[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compiling step\n",
    "nn_reg.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                704       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,433\n",
      "Trainable params: 2,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 20138640.3000\n",
      "Epoch 2/50\n",
      "759/759 [==============================] - 1s 1ms/step - loss: 1177435.2735\n",
      "Epoch 3/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 890959.4201\n",
      "Epoch 4/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 711147.9567\n",
      "Epoch 5/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 646303.4166\n",
      "Epoch 6/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 571772.0749\n",
      "Epoch 7/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 524975.2692\n",
      "Epoch 8/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 489518.5923\n",
      "Epoch 9/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 454421.4896\n",
      "Epoch 10/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 438860.7836\n",
      "Epoch 11/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 425955.9200\n",
      "Epoch 12/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 387109.3079\n",
      "Epoch 13/50\n",
      "759/759 [==============================] - 2s 3ms/step - loss: 385643.3847\n",
      "Epoch 14/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 384729.9137\n",
      "Epoch 15/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 365926.7338\n",
      "Epoch 16/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 355428.9558\n",
      "Epoch 17/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 355730.1028\n",
      "Epoch 18/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 356139.3676\n",
      "Epoch 19/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 355498.2394\n",
      "Epoch 20/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 364256.9082\n",
      "Epoch 21/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 335075.1593\n",
      "Epoch 22/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 343028.1878\n",
      "Epoch 23/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 336395.3655\n",
      "Epoch 24/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 335523.2337: 0s - l\n",
      "Epoch 25/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 335490.3628\n",
      "Epoch 26/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 329823.2673\n",
      "Epoch 27/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 329749.6900\n",
      "Epoch 28/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 329292.4508\n",
      "Epoch 29/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 323262.4309\n",
      "Epoch 30/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 328421.0863\n",
      "Epoch 31/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 319262.8769\n",
      "Epoch 32/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 322218.3645\n",
      "Epoch 33/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 320374.5575\n",
      "Epoch 34/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 329481.3763\n",
      "Epoch 35/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 319965.1866\n",
      "Epoch 36/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 319711.3700\n",
      "Epoch 37/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 319634.6248\n",
      "Epoch 38/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 313398.4982\n",
      "Epoch 39/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 317040.7332\n",
      "Epoch 40/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 322681.4084\n",
      "Epoch 41/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 314938.3128\n",
      "Epoch 42/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 317823.9820\n",
      "Epoch 43/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 317046.9541\n",
      "Epoch 44/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 315992.0028: 0s - loss: 315994.22\n",
      "Epoch 45/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 305358.9598\n",
      "Epoch 46/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 323901.3475\n",
      "Epoch 47/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 307493.8117\n",
      "Epoch 48/50\n",
      "759/759 [==============================] - 2s 2ms/step - loss: 312815.6005\n",
      "Epoch 49/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 321894.2375\n",
      "Epoch 50/50\n",
      "759/759 [==============================] - 1s 2ms/step - loss: 309508.7838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x290bbafc280>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 50\n",
    "nn_reg.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform and scale the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaito\\AppData\\Local\\Temp\\ipykernel_18792\\386648586.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['dim_index'] = pca.transform(X_test[['x','y','z']]).flatten()\n",
      "C:\\Users\\Kaito\\AppData\\Local\\Temp\\ipykernel_18792\\386648586.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop(['x','y','z'], axis=1, inplace=True)\n",
      "C:\\Users\\Kaito\\AppData\\Local\\Temp\\ipykernel_18792\\386648586.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])\n"
     ]
    }
   ],
   "source": [
    "## PCA for dimentionality reduction:\n",
    "X_test['dim_index'] = pca.transform(X_test[['x','y','z']]).flatten()\n",
    "X_test.drop(['x','y','z'], axis=1, inplace=True)\n",
    "## Scale our numerical features so they have zero mean and a variance of one\n",
    "X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.313 \n",
      "Test MSE: 0.326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred_train = nn_reg.predict(X_train)\n",
    "y_pred_test = nn_reg.predict(X_test)\n",
    "train_mse = mean_squared_error(y_true=y_train, y_pred=y_pred_train)\n",
    "test_mse = mean_squared_error(y_true=y_test, y_pred=y_pred_test)\n",
    "print(\"Train MSE: {:0.3f} \\nTest MSE: {:0.3f}\".format(train_mse/1e6, test_mse/1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg2 = Sequential()\n",
    "n_hidden = 64\n",
    "# hidden layers\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu', input_shape=(n_input,)))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "# output layer\n",
    "nn_reg2.add(Dense(units=1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg2.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 22,273\n",
      "Trainable params: 22,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_reg2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "683/683 [==============================] - 3s 3ms/step - loss: 10948597.6371 - mse: 10948597.6371 - mae: 1813.6424 - val_loss: 962274.1250 - val_mse: 962274.1250 - val_mae: 509.7831\n",
      "Epoch 2/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 741153.5630 - mse: 741153.5630 - mae: 444.2895 - val_loss: 625954.4375 - val_mse: 625954.4375 - val_mae: 400.6062\n",
      "Epoch 3/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 538401.6122 - mse: 538401.6122 - mae: 386.5743 - val_loss: 548081.8125 - val_mse: 548081.8125 - val_mae: 390.1127\n",
      "Epoch 4/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 462546.7381 - mse: 462546.7381 - mae: 368.4099 - val_loss: 467269.3438 - val_mse: 467269.3438 - val_mae: 372.9443\n",
      "Epoch 5/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 408271.6508 - mse: 408271.6508 - mae: 352.6646 - val_loss: 454741.0312 - val_mse: 454741.0312 - val_mae: 390.7357\n",
      "Epoch 6/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 409208.6487 - mse: 409208.6487 - mae: 355.7362 - val_loss: 383815.3438 - val_mse: 383815.3438 - val_mae: 338.3141\n",
      "Epoch 7/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 358555.7573 - mse: 358555.7573 - mae: 335.8250 - val_loss: 405267.5625 - val_mse: 405267.5625 - val_mae: 342.6313\n",
      "Epoch 8/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 349565.0389 - mse: 349565.0389 - mae: 333.3224 - val_loss: 393499.2188 - val_mse: 393499.2188 - val_mae: 343.6149\n",
      "Epoch 9/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 358621.0581 - mse: 358621.0581 - mae: 334.6499 - val_loss: 351401.7188 - val_mse: 351401.7188 - val_mae: 322.9339\n",
      "Epoch 10/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 343969.8660 - mse: 343969.8660 - mae: 326.2273 - val_loss: 384689.9688 - val_mse: 384689.9688 - val_mae: 349.2740\n",
      "Epoch 11/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 332071.0876 - mse: 332071.0876 - mae: 320.6738 - val_loss: 356550.8125 - val_mse: 356550.8125 - val_mae: 325.2465\n",
      "Epoch 12/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 323220.1349 - mse: 323220.1349 - mae: 319.0190 - val_loss: 350788.3438 - val_mse: 350788.3438 - val_mae: 324.3795\n",
      "Epoch 13/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 334477.6684 - mse: 334477.6684 - mae: 322.0449 - val_loss: 351955.2188 - val_mse: 351955.2188 - val_mae: 326.8738\n",
      "Epoch 14/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 336332.9278 - mse: 336332.9278 - mae: 321.8231 - val_loss: 415826.3438 - val_mse: 415826.3438 - val_mae: 371.1784\n",
      "Epoch 15/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 326395.8146 - mse: 326395.8146 - mae: 319.9078 - val_loss: 361443.1250 - val_mse: 361443.1250 - val_mae: 328.4554\n",
      "Epoch 16/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 327160.1059 - mse: 327160.1059 - mae: 318.2043 - val_loss: 390320.4375 - val_mse: 390320.4375 - val_mae: 349.6302\n",
      "Epoch 17/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 330059.3035 - mse: 330059.3035 - mae: 316.9468 - val_loss: 396664.8750 - val_mse: 396664.8750 - val_mae: 351.9953\n",
      "Epoch 18/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 312694.2821 - mse: 312694.2821 - mae: 311.3869 - val_loss: 327623.5625 - val_mse: 327623.5625 - val_mae: 310.9727\n",
      "Epoch 19/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 313442.9048 - mse: 313442.9048 - mae: 309.8302 - val_loss: 361574.6250 - val_mse: 361574.6250 - val_mae: 329.0094\n",
      "Epoch 20/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 316686.3107 - mse: 316686.3107 - mae: 312.7858 - val_loss: 349218.1250 - val_mse: 349218.1250 - val_mae: 343.3924\n",
      "Epoch 21/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 315684.4102 - mse: 315684.4102 - mae: 308.8828 - val_loss: 345643.7500 - val_mse: 345643.7500 - val_mae: 312.6309\n",
      "Epoch 22/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 315365.4727 - mse: 315365.4727 - mae: 311.8292 - val_loss: 345665.0312 - val_mse: 345665.0312 - val_mae: 307.3818\n",
      "Epoch 23/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 320745.3307 - mse: 320745.3307 - mae: 312.9429 - val_loss: 355459.3750 - val_mse: 355459.3750 - val_mae: 321.8510\n",
      "Epoch 24/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 319218.0241 - mse: 319218.0241 - mae: 313.1114 - val_loss: 317561.6250 - val_mse: 317561.6250 - val_mae: 301.9707\n",
      "Epoch 25/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 310167.1319 - mse: 310167.1319 - mae: 308.8443 - val_loss: 322648.4062 - val_mse: 322648.4062 - val_mae: 305.6371\n",
      "Epoch 26/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 300917.9460 - mse: 300917.9460 - mae: 303.0986 - val_loss: 407341.7500 - val_mse: 407341.7500 - val_mae: 344.1186\n",
      "Epoch 27/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 313251.1240 - mse: 313251.1240 - mae: 308.3570 - val_loss: 325445.4062 - val_mse: 325445.4062 - val_mae: 305.1887\n",
      "Epoch 28/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 309852.1461 - mse: 309852.1461 - mae: 307.3964 - val_loss: 327769.4062 - val_mse: 327769.4062 - val_mae: 306.0602\n",
      "Epoch 29/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 303405.1903 - mse: 303405.1903 - mae: 304.9159 - val_loss: 337267.7500 - val_mse: 337267.7500 - val_mae: 307.1419\n",
      "Epoch 30/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 307062.1020 - mse: 307062.1020 - mae: 305.8162 - val_loss: 318545.2500 - val_mse: 318545.2500 - val_mae: 303.0034\n",
      "Epoch 31/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 314272.0341 - mse: 314272.0341 - mae: 307.8216 - val_loss: 341488.7188 - val_mse: 341488.7188 - val_mae: 311.1223\n",
      "Epoch 32/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 301244.8305 - mse: 301244.8305 - mae: 304.2414 - val_loss: 337901.5000 - val_mse: 337901.5000 - val_mae: 317.3240\n",
      "Epoch 33/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 304093.1457 - mse: 304093.1457 - mae: 304.9276 - val_loss: 319087.8438 - val_mse: 319087.8438 - val_mae: 299.1516\n",
      "Epoch 34/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 292368.6235 - mse: 292368.6235 - mae: 299.9829 - val_loss: 333591.1562 - val_mse: 333591.1562 - val_mae: 305.9756\n",
      "Epoch 35/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 300616.5616 - mse: 300616.5616 - mae: 302.8311 - val_loss: 360027.7812 - val_mse: 360027.7812 - val_mae: 333.1285\n",
      "Epoch 36/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 303801.6920 - mse: 303801.6920 - mae: 305.7823 - val_loss: 336943.5312 - val_mse: 336943.5312 - val_mae: 314.7289\n",
      "Epoch 37/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 308040.3042 - mse: 308040.3042 - mae: 305.8962 - val_loss: 354603.1562 - val_mse: 354603.1562 - val_mae: 328.1599\n",
      "Epoch 38/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 289388.7055 - mse: 289388.7055 - mae: 295.3273 - val_loss: 327442.6562 - val_mse: 327442.6562 - val_mae: 302.4800\n",
      "Epoch 39/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 298867.1314 - mse: 298867.1314 - mae: 301.0111 - val_loss: 330308.5000 - val_mse: 330308.5000 - val_mae: 311.1503\n",
      "Epoch 40/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 305121.5612 - mse: 305121.5612 - mae: 301.8707 - val_loss: 325037.8438 - val_mse: 325037.8438 - val_mae: 307.7484\n",
      "Epoch 41/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 287763.3180 - mse: 287763.3180 - mae: 294.7174 - val_loss: 335804.5312 - val_mse: 335804.5312 - val_mae: 303.1373\n",
      "Epoch 42/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 298110.5076 - mse: 298110.5076 - mae: 297.9571 - val_loss: 323519.0000 - val_mse: 323519.0000 - val_mae: 304.2766\n",
      "Epoch 43/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 295227.4573 - mse: 295227.4573 - mae: 296.5526 - val_loss: 363816.7188 - val_mse: 363816.7188 - val_mae: 338.0334\n",
      "Epoch 44/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683/683 [==============================] - 2s 3ms/step - loss: 284219.0986 - mse: 284219.0986 - mae: 293.4085 - val_loss: 321237.2500 - val_mse: 321237.2500 - val_mae: 307.0283\n",
      "Epoch 45/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 286440.2711 - mse: 286440.2711 - mae: 295.0623 - val_loss: 326871.4688 - val_mse: 326871.4688 - val_mae: 296.4868\n",
      "Epoch 46/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 287475.5990 - mse: 287475.5990 - mae: 296.7168 - val_loss: 355806.3125 - val_mse: 355806.3125 - val_mae: 322.3969\n",
      "Epoch 47/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 295789.4915 - mse: 295789.4915 - mae: 295.9941 - val_loss: 338841.0000 - val_mse: 338841.0000 - val_mae: 325.1914\n",
      "Epoch 48/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 285980.4581 - mse: 285980.4581 - mae: 293.9253 - val_loss: 313742.7188 - val_mse: 313742.7188 - val_mae: 298.7589\n",
      "Epoch 49/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 283220.5294 - mse: 283220.5294 - mae: 290.9003 - val_loss: 324715.0312 - val_mse: 324715.0312 - val_mae: 307.1643\n",
      "Epoch 50/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 295417.1394 - mse: 295417.1394 - mae: 297.4106 - val_loss: 375340.3125 - val_mse: 375340.3125 - val_mae: 337.9149\n",
      "Epoch 51/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 284668.3062 - mse: 284668.3062 - mae: 295.9440 - val_loss: 347618.6875 - val_mse: 347618.6875 - val_mae: 330.2571\n",
      "Epoch 52/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 291245.0515 - mse: 291245.0515 - mae: 296.4920 - val_loss: 382713.5000 - val_mse: 382713.5000 - val_mae: 313.2527\n",
      "Epoch 53/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 295149.9273 - mse: 295149.9273 - mae: 296.5919 - val_loss: 321515.1562 - val_mse: 321515.1562 - val_mae: 293.7878\n",
      "Epoch 54/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 291310.5146 - mse: 291310.5146 - mae: 294.7517 - val_loss: 326162.6562 - val_mse: 326162.6562 - val_mae: 295.8672\n",
      "Epoch 55/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 276613.8644 - mse: 276613.8644 - mae: 288.6111 - val_loss: 319283.0000 - val_mse: 319283.0000 - val_mae: 292.5891\n",
      "Epoch 56/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 304018.0845 - mse: 304018.0845 - mae: 305.2572 - val_loss: 315285.2500 - val_mse: 315285.2500 - val_mae: 295.4875\n",
      "Epoch 57/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 298440.2620 - mse: 298440.2620 - mae: 300.1170 - val_loss: 324910.1875 - val_mse: 324910.1875 - val_mae: 311.8059\n",
      "Epoch 58/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 292490.7934 - mse: 292490.7934 - mae: 295.0694 - val_loss: 338126.9375 - val_mse: 338126.9375 - val_mae: 313.3631\n",
      "Epoch 59/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 288544.4551 - mse: 288544.4551 - mae: 292.4657 - val_loss: 317858.1562 - val_mse: 317858.1562 - val_mae: 307.5044\n",
      "Epoch 60/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 287341.1492 - mse: 287341.1492 - mae: 292.1116 - val_loss: 325414.6562 - val_mse: 325414.6562 - val_mae: 315.6963\n",
      "Epoch 61/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 265227.5668 - mse: 265227.5668 - mae: 283.4149 - val_loss: 322137.4062 - val_mse: 322137.4062 - val_mae: 305.5070\n",
      "Epoch 62/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 275926.5336 - mse: 275926.5336 - mae: 289.4865 - val_loss: 329100.7188 - val_mse: 329100.7188 - val_mae: 318.5037\n",
      "Epoch 63/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 285670.2820 - mse: 285670.2820 - mae: 293.8726 - val_loss: 329506.3438 - val_mse: 329506.3438 - val_mae: 325.0404\n",
      "Epoch 64/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 291671.4882 - mse: 291671.4882 - mae: 295.3005 - val_loss: 317656.1562 - val_mse: 317656.1562 - val_mae: 295.8162\n",
      "Epoch 65/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 285337.2966 - mse: 285337.2966 - mae: 292.0465 - val_loss: 326351.7188 - val_mse: 326351.7188 - val_mae: 305.7986\n",
      "Epoch 66/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 276083.0442 - mse: 276083.0442 - mae: 286.8796 - val_loss: 309720.6875 - val_mse: 309720.6875 - val_mae: 299.7555\n",
      "Epoch 67/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 274410.2667 - mse: 274410.2667 - mae: 288.0586 - val_loss: 406962.6562 - val_mse: 406962.6562 - val_mae: 359.1459\n",
      "Epoch 68/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 278672.6116 - mse: 278672.6116 - mae: 290.3552 - val_loss: 321755.6250 - val_mse: 321755.6250 - val_mae: 301.9820\n",
      "Epoch 69/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 277567.8532 - mse: 277567.8532 - mae: 287.1334 - val_loss: 313446.6875 - val_mse: 313446.6875 - val_mae: 295.7659\n",
      "Epoch 70/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 275311.4351 - mse: 275311.4351 - mae: 286.6400 - val_loss: 317731.5625 - val_mse: 317731.5625 - val_mae: 293.4728\n",
      "Epoch 71/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 269667.2328 - mse: 269667.2328 - mae: 284.8093 - val_loss: 306863.0312 - val_mse: 306863.0312 - val_mae: 289.2551\n",
      "Epoch 72/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 287059.9355 - mse: 287059.9355 - mae: 291.9246 - val_loss: 314548.2500 - val_mse: 314548.2500 - val_mae: 293.5210\n",
      "Epoch 73/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 278879.8371 - mse: 278879.8371 - mae: 289.9580 - val_loss: 378204.0625 - val_mse: 378204.0625 - val_mae: 326.8362\n",
      "Epoch 74/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 286679.9939 - mse: 286679.9939 - mae: 297.7320 - val_loss: 312077.0000 - val_mse: 312077.0000 - val_mae: 295.5763\n",
      "Epoch 75/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 268337.7903 - mse: 268337.7903 - mae: 282.2967 - val_loss: 306031.1875 - val_mse: 306031.1875 - val_mae: 292.1204\n",
      "Epoch 76/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 283152.4667 - mse: 283152.4667 - mae: 288.8645 - val_loss: 352248.1562 - val_mse: 352248.1562 - val_mae: 328.9931\n",
      "Epoch 77/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 284293.2035 - mse: 284293.2035 - mae: 292.3226 - val_loss: 319735.1250 - val_mse: 319735.1250 - val_mae: 299.0181\n",
      "Epoch 78/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 261870.6842 - mse: 261870.6842 - mae: 282.1822 - val_loss: 320502.6562 - val_mse: 320502.6562 - val_mae: 296.7598\n",
      "Epoch 79/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 275824.5910 - mse: 275824.5910 - mae: 284.4944 - val_loss: 310879.8438 - val_mse: 310879.8438 - val_mae: 295.2036\n",
      "Epoch 80/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 277579.8416 - mse: 277579.8416 - mae: 287.0607 - val_loss: 317350.4375 - val_mse: 317350.4375 - val_mae: 296.7151\n",
      "Epoch 81/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 277125.0914 - mse: 277125.0914 - mae: 286.7766 - val_loss: 308194.3750 - val_mse: 308194.3750 - val_mae: 289.8687\n",
      "Epoch 82/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 278377.1751 - mse: 278377.1751 - mae: 286.2965 - val_loss: 312016.0938 - val_mse: 312016.0938 - val_mae: 296.0407\n",
      "Epoch 83/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 281297.0373 - mse: 281297.0373 - mae: 286.8506 - val_loss: 323336.3438 - val_mse: 323336.3438 - val_mae: 296.5896\n",
      "Epoch 84/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 270037.9083 - mse: 270037.9083 - mae: 285.5416 - val_loss: 312946.2500 - val_mse: 312946.2500 - val_mae: 297.5944\n",
      "Epoch 85/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 278319.8574 - mse: 278319.8574 - mae: 288.2265 - val_loss: 324116.8125 - val_mse: 324116.8125 - val_mae: 314.0722\n",
      "Epoch 86/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 272879.3515 - mse: 272879.3515 - mae: 286.3838 - val_loss: 322181.0625 - val_mse: 322181.0625 - val_mae: 300.7899\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683/683 [==============================] - 2s 3ms/step - loss: 275014.3115 - mse: 275014.3115 - mae: 284.1815 - val_loss: 320617.7188 - val_mse: 320617.7188 - val_mae: 293.5753\n",
      "Epoch 88/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 278276.4752 - mse: 278276.4752 - mae: 288.4016 - val_loss: 345470.0000 - val_mse: 345470.0000 - val_mae: 333.5504\n",
      "Epoch 89/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 272027.3728 - mse: 272027.3728 - mae: 287.7043 - val_loss: 340617.6562 - val_mse: 340617.6562 - val_mae: 327.0978\n",
      "Epoch 90/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 281296.7368 - mse: 281296.7368 - mae: 289.8047 - val_loss: 322548.8125 - val_mse: 322548.8125 - val_mae: 295.5013\n",
      "Epoch 91/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 270834.2445 - mse: 270834.2445 - mae: 285.3641 - val_loss: 404310.7500 - val_mse: 404310.7500 - val_mae: 320.6823\n",
      "Epoch 92/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 288410.3893 - mse: 288410.3893 - mae: 292.4433 - val_loss: 313232.7188 - val_mse: 313232.7188 - val_mae: 291.4069\n",
      "Epoch 93/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 272988.2467 - mse: 272988.2467 - mae: 287.0605 - val_loss: 355965.9688 - val_mse: 355965.9688 - val_mae: 328.5996\n",
      "Epoch 94/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 265073.8737 - mse: 265073.8737 - mae: 279.9151 - val_loss: 383949.8125 - val_mse: 383949.8125 - val_mae: 344.2806\n",
      "Epoch 95/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 266257.2151 - mse: 266257.2151 - mae: 282.7649 - val_loss: 330066.4062 - val_mse: 330066.4062 - val_mae: 306.8088\n",
      "Epoch 96/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 269664.7589 - mse: 269664.7589 - mae: 284.8824 - val_loss: 321816.0000 - val_mse: 321816.0000 - val_mae: 294.7813\n",
      "Epoch 97/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 278220.8196 - mse: 278220.8196 - mae: 289.1196 - val_loss: 327679.8438 - val_mse: 327679.8438 - val_mae: 323.6871\n",
      "Epoch 98/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 259896.3435 - mse: 259896.3435 - mae: 278.3299 - val_loss: 330335.5625 - val_mse: 330335.5625 - val_mae: 307.8887\n",
      "Epoch 99/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 270982.0384 - mse: 270982.0384 - mae: 285.4544 - val_loss: 319131.3750 - val_mse: 319131.3750 - val_mae: 298.1243\n",
      "Epoch 100/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 274934.6325 - mse: 274934.6325 - mae: 285.8190 - val_loss: 321183.4375 - val_mse: 321183.4375 - val_mae: 299.864575221.6161 - mae: 285.8\n",
      "Epoch 101/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 260376.4410 - mse: 260376.4410 - mae: 285.2610 - val_loss: 318003.5625 - val_mse: 318003.5625 - val_mae: 296.8975\n",
      "Epoch 102/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 268088.6594 - mse: 268088.6594 - mae: 280.5346 - val_loss: 315275.2812 - val_mse: 315275.2812 - val_mae: 289.2974\n",
      "Epoch 103/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 259641.9316 - mse: 259641.9316 - mae: 279.5986 - val_loss: 324060.0000 - val_mse: 324060.0000 - val_mae: 305.9413\n",
      "Epoch 104/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 263238.5587 - mse: 263238.5587 - mae: 282.6594 - val_loss: 322265.6562 - val_mse: 322265.6562 - val_mae: 294.5126\n",
      "Epoch 105/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 263102.5439 - mse: 263102.5439 - mae: 279.5430 - val_loss: 376137.5625 - val_mse: 376137.5625 - val_mae: 327.2783\n",
      "Epoch 106/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 270284.4044 - mse: 270284.4044 - mae: 284.4796 - val_loss: 337332.7812 - val_mse: 337332.7812 - val_mae: 311.8172\n",
      "Epoch 107/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 269078.3177 - mse: 269078.3177 - mae: 283.9447 - val_loss: 360859.3438 - val_mse: 360859.3438 - val_mae: 312.0871\n",
      "Epoch 108/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 259971.8478 - mse: 259971.8478 - mae: 280.7123 - val_loss: 315399.2500 - val_mse: 315399.2500 - val_mae: 296.4554\n",
      "Epoch 109/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 267241.5819 - mse: 267241.5819 - mae: 282.9729 - val_loss: 341911.9062 - val_mse: 341911.9062 - val_mae: 318.6870\n",
      "Epoch 110/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 263895.7417 - mse: 263895.7417 - mae: 281.5387 - val_loss: 353516.3125 - val_mse: 353516.3125 - val_mae: 321.2156\n",
      "Epoch 111/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 268806.2791 - mse: 268806.2791 - mae: 281.4637 - val_loss: 322009.6250 - val_mse: 322009.6250 - val_mae: 300.6753\n",
      "Epoch 112/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 265877.5138 - mse: 265877.5138 - mae: 281.0840 - val_loss: 327028.7500 - val_mse: 327028.7500 - val_mae: 302.2135\n",
      "Epoch 113/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 267102.3914 - mse: 267102.3914 - mae: 281.6430 - val_loss: 309831.3125 - val_mse: 309831.3125 - val_mae: 288.8334\n",
      "Epoch 114/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 264525.3197 - mse: 264525.3197 - mae: 279.0650 - val_loss: 329881.5938 - val_mse: 329881.5938 - val_mae: 287.9545\n",
      "Epoch 115/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 271828.5999 - mse: 271828.5999 - mae: 281.4626 - val_loss: 313023.8438 - val_mse: 313023.8438 - val_mae: 295.0254\n",
      "Epoch 116/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 278180.5106 - mse: 278180.5106 - mae: 288.4153 - val_loss: 316645.5625 - val_mse: 316645.5625 - val_mae: 297.5996\n",
      "Epoch 117/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 250807.7552 - mse: 250807.7552 - mae: 273.5117 - val_loss: 350537.2188 - val_mse: 350537.2188 - val_mae: 316.3588\n",
      "Epoch 118/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 272132.7471 - mse: 272132.7471 - mae: 283.5313 - val_loss: 311421.2188 - val_mse: 311421.2188 - val_mae: 297.0084\n",
      "Epoch 119/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 261678.0240 - mse: 261678.0240 - mae: 278.8757 - val_loss: 316708.7500 - val_mse: 316708.7500 - val_mae: 291.2303\n",
      "Epoch 120/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 260056.2283 - mse: 260056.2283 - mae: 280.6856 - val_loss: 324748.0000 - val_mse: 324748.0000 - val_mae: 303.8638\n",
      "Epoch 121/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 266381.4987 - mse: 266381.4987 - mae: 281.2766 - val_loss: 306042.1562 - val_mse: 306042.1562 - val_mae: 287.8324\n",
      "Epoch 122/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 263243.9283 - mse: 263243.9283 - mae: 281.4393 - val_loss: 336144.6562 - val_mse: 336144.6562 - val_mae: 313.2661\n",
      "Epoch 123/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 256801.5373 - mse: 256801.5373 - mae: 278.5925 - val_loss: 307938.9375 - val_mse: 307938.9375 - val_mae: 289.2214\n",
      "Epoch 124/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 255463.6167 - mse: 255463.6167 - mae: 277.2905 - val_loss: 314564.6250 - val_mse: 314564.6250 - val_mae: 294.6814\n",
      "Epoch 125/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 254193.5341 - mse: 254193.5341 - mae: 275.5583 - val_loss: 309720.0000 - val_mse: 309720.0000 - val_mae: 290.3236\n",
      "Epoch 126/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 255748.9151 - mse: 255748.9151 - mae: 274.6183 - val_loss: 307879.7188 - val_mse: 307879.7188 - val_mae: 292.2763\n",
      "Epoch 127/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 270206.8606 - mse: 270206.8606 - mae: 286.1790 - val_loss: 335967.1562 - val_mse: 335967.1562 - val_mae: 314.1707\n",
      "Epoch 128/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 257162.1161 - mse: 257162.1161 - mae: 275.0700 - val_loss: 321771.7188 - val_mse: 321771.7188 - val_mae: 305.6824\n",
      "Epoch 129/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 253364.4273 - mse: 253364.4273 - mae: 275.8339 - val_loss: 333100.1562 - val_mse: 333100.1562 - val_mae: 308.8643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 254017.2454 - mse: 254017.2454 - mae: 276.3402 - val_loss: 352145.2188 - val_mse: 352145.2188 - val_mae: 305.5449\n",
      "Epoch 131/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 255860.1274 - mse: 255860.1274 - mae: 277.1921 - val_loss: 307900.9375 - val_mse: 307900.9375 - val_mae: 294.0042\n",
      "Epoch 132/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 250219.0695 - mse: 250219.0695 - mae: 271.4880 - val_loss: 309302.3750 - val_mse: 309302.3750 - val_mae: 298.3054\n",
      "Epoch 133/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 252880.5679 - mse: 252880.5679 - mae: 276.4890 - val_loss: 313531.2188 - val_mse: 313531.2188 - val_mae: 295.4058\n",
      "Epoch 134/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 264861.4451 - mse: 264861.4451 - mae: 280.6303 - val_loss: 329701.5625 - val_mse: 329701.5625 - val_mae: 296.6551\n",
      "Epoch 135/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 255504.7142 - mse: 255504.7142 - mae: 277.1094 - val_loss: 340416.5000 - val_mse: 340416.5000 - val_mae: 313.7736\n",
      "Epoch 136/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 258570.5581 - mse: 258570.5581 - mae: 278.4712 - val_loss: 312290.9375 - val_mse: 312290.9375 - val_mae: 301.8774\n",
      "Epoch 137/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 253148.6954 - mse: 253148.6954 - mae: 276.2709 - val_loss: 324599.8125 - val_mse: 324599.8125 - val_mae: 309.1070\n",
      "Epoch 138/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 246075.1803 - mse: 246075.1803 - mae: 270.7969 - val_loss: 343041.2812 - val_mse: 343041.2812 - val_mae: 327.8264\n",
      "Epoch 139/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 247207.6078 - mse: 247207.6078 - mae: 272.6703 - val_loss: 326326.2188 - val_mse: 326326.2188 - val_mae: 291.8723\n",
      "Epoch 140/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 248061.5259 - mse: 248061.5259 - mae: 270.9238 - val_loss: 322320.3750 - val_mse: 322320.3750 - val_mae: 302.1950\n",
      "Epoch 141/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 256828.4587 - mse: 256828.4587 - mae: 274.1465 - val_loss: 310169.0625 - val_mse: 310169.0625 - val_mae: 290.4179\n",
      "Epoch 142/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 244518.7401 - mse: 244518.7401 - mae: 271.5396 - val_loss: 322394.7812 - val_mse: 322394.7812 - val_mae: 301.5329\n",
      "Epoch 143/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 259855.2481 - mse: 259855.2481 - mae: 279.4000 - val_loss: 323853.4375 - val_mse: 323853.4375 - val_mae: 297.7811\n",
      "Epoch 144/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 251446.1473 - mse: 251446.1473 - mae: 274.9979 - val_loss: 313940.7812 - val_mse: 313940.7812 - val_mae: 292.9081\n",
      "Epoch 145/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 257791.8657 - mse: 257791.8657 - mae: 277.4713 - val_loss: 321818.1875 - val_mse: 321818.1875 - val_mae: 292.6717\n",
      "Epoch 146/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 250763.4355 - mse: 250763.4355 - mae: 273.7201 - val_loss: 309650.9688 - val_mse: 309650.9688 - val_mae: 296.1693\n",
      "Epoch 147/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 251449.4172 - mse: 251449.4172 - mae: 277.2588 - val_loss: 314813.7812 - val_mse: 314813.7812 - val_mae: 298.2676\n",
      "Epoch 148/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 257015.5286 - mse: 257015.5286 - mae: 277.2064 - val_loss: 315411.2812 - val_mse: 315411.2812 - val_mae: 298.5437\n",
      "Epoch 149/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 240113.4211 - mse: 240113.4211 - mae: 271.8954 - val_loss: 319600.1562 - val_mse: 319600.1562 - val_mae: 291.6960\n",
      "Epoch 150/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 250768.4192 - mse: 250768.4192 - mae: 272.4222 - val_loss: 306558.5625 - val_mse: 306558.5625 - val_mae: 288.2919\n",
      "Epoch 151/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 249806.7882 - mse: 249806.7882 - mae: 273.4223 - val_loss: 301362.0938 - val_mse: 301362.0938 - val_mae: 289.4679\n",
      "Epoch 152/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 252488.4881 - mse: 252488.4881 - mae: 272.8378 - val_loss: 343256.0312 - val_mse: 343256.0312 - val_mae: 297.0023\n",
      "Epoch 153/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 252344.5653 - mse: 252344.5653 - mae: 276.0005 - val_loss: 357007.6250 - val_mse: 357007.6250 - val_mae: 327.5662\n",
      "Epoch 154/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 253095.4912 - mse: 253095.4912 - mae: 276.3712 - val_loss: 308837.9688 - val_mse: 308837.9688 - val_mae: 292.5923\n",
      "Epoch 155/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 254172.7513 - mse: 254172.7513 - mae: 276.3240 - val_loss: 314391.7188 - val_mse: 314391.7188 - val_mae: 296.2277\n",
      "Epoch 156/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 252501.6295 - mse: 252501.6295 - mae: 274.5640 - val_loss: 335413.9375 - val_mse: 335413.9375 - val_mae: 312.8003\n",
      "Epoch 157/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 254844.2021 - mse: 254844.2021 - mae: 274.4288 - val_loss: 332945.5312 - val_mse: 332945.5312 - val_mae: 309.7404\n",
      "Epoch 158/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 247765.9436 - mse: 247765.9436 - mae: 274.2985 - val_loss: 306250.8125 - val_mse: 306250.8125 - val_mae: 290.5080\n",
      "Epoch 159/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 244721.0477 - mse: 244721.0477 - mae: 270.3594 - val_loss: 321696.9062 - val_mse: 321696.9062 - val_mae: 297.7775\n",
      "Epoch 160/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 250976.7783 - mse: 250976.7783 - mae: 274.1543 - val_loss: 319245.5625 - val_mse: 319245.5625 - val_mae: 295.3769\n",
      "Epoch 161/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 240605.3941 - mse: 240605.3941 - mae: 270.7007 - val_loss: 316946.0000 - val_mse: 316946.0000 - val_mae: 291.3502\n",
      "Epoch 162/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 232720.0553 - mse: 232720.0553 - mae: 264.6388 - val_loss: 318374.5312 - val_mse: 318374.5312 - val_mae: 300.0701\n",
      "Epoch 163/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 242754.9213 - mse: 242754.9213 - mae: 269.5528 - val_loss: 320126.9062 - val_mse: 320126.9062 - val_mae: 300.6027\n",
      "Epoch 164/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 246167.6141 - mse: 246167.6141 - mae: 271.2672 - val_loss: 384607.4688 - val_mse: 384607.4688 - val_mae: 337.5691\n",
      "Epoch 165/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 252710.5190 - mse: 252710.5190 - mae: 278.5344 - val_loss: 311107.3125 - val_mse: 311107.3125 - val_mae: 289.7810\n",
      "Epoch 166/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 245155.7776 - mse: 245155.7776 - mae: 270.5028 - val_loss: 389202.3125 - val_mse: 389202.3125 - val_mae: 320.6888\n",
      "Epoch 167/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 257089.5626 - mse: 257089.5626 - mae: 278.3749 - val_loss: 313651.1250 - val_mse: 313651.1250 - val_mae: 297.4253\n",
      "Epoch 168/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 242554.1198 - mse: 242554.1198 - mae: 270.8333 - val_loss: 317482.2188 - val_mse: 317482.2188 - val_mae: 296.2514\n",
      "Epoch 169/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 244527.4910 - mse: 244527.4910 - mae: 271.7310 - val_loss: 311091.2812 - val_mse: 311091.2812 - val_mae: 293.2897\n",
      "Epoch 170/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 256251.4541 - mse: 256251.4541 - mae: 277.3001 - val_loss: 328163.5625 - val_mse: 328163.5625 - val_mae: 308.4927\n",
      "Epoch 171/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 248258.8834 - mse: 248258.8834 - mae: 272.5746 - val_loss: 315331.8438 - val_mse: 315331.8438 - val_mae: 296.8526\n",
      "Epoch 172/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 255549.3424 - mse: 255549.3424 - mae: 275.4755 - val_loss: 303492.2500 - val_mse: 303492.2500 - val_mae: 290.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 256739.6133 - mse: 256739.6133 - mae: 275.2732 - val_loss: 311231.8750 - val_mse: 311231.8750 - val_mae: 295.2270\n",
      "Epoch 174/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 238497.6043 - mse: 238497.6043 - mae: 265.5734 - val_loss: 317025.2500 - val_mse: 317025.2500 - val_mae: 298.9705\n",
      "Epoch 175/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 247192.7453 - mse: 247192.7453 - mae: 271.9811 - val_loss: 320997.9062 - val_mse: 320997.9062 - val_mae: 307.0769\n",
      "Epoch 176/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 243385.9411 - mse: 243385.9411 - mae: 272.0150 - val_loss: 316479.4062 - val_mse: 316479.4062 - val_mae: 291.8618\n",
      "Epoch 177/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 245653.3200 - mse: 245653.3200 - mae: 270.5044 - val_loss: 326840.3438 - val_mse: 326840.3438 - val_mae: 311.1054\n",
      "Epoch 178/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 243625.8631 - mse: 243625.8631 - mae: 271.5614 - val_loss: 337348.8125 - val_mse: 337348.8125 - val_mae: 311.8299\n",
      "Epoch 179/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 246312.1502 - mse: 246312.1502 - mae: 271.6835 - val_loss: 304021.0625 - val_mse: 304021.0625 - val_mae: 288.8462\n",
      "Epoch 180/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 239046.1564 - mse: 239046.1564 - mae: 267.3249 - val_loss: 312338.6250 - val_mse: 312338.6250 - val_mae: 298.4880\n",
      "Epoch 181/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 243861.6296 - mse: 243861.6296 - mae: 268.4262 - val_loss: 312770.7812 - val_mse: 312770.7812 - val_mae: 293.4369\n",
      "Epoch 182/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 243216.5552 - mse: 243216.5552 - mae: 270.1187 - val_loss: 308710.2188 - val_mse: 308710.2188 - val_mae: 291.9953\n",
      "Epoch 183/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 231913.9222 - mse: 231913.9222 - mae: 264.1439 - val_loss: 318943.1562 - val_mse: 318943.1562 - val_mae: 293.3457\n",
      "Epoch 184/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 235315.5990 - mse: 235315.5990 - mae: 265.8316 - val_loss: 323490.9688 - val_mse: 323490.9688 - val_mae: 291.2559\n",
      "Epoch 185/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 247942.6024 - mse: 247942.6024 - mae: 272.1218 - val_loss: 319919.9375 - val_mse: 319919.9375 - val_mae: 296.6281\n",
      "Epoch 186/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 245802.4177 - mse: 245802.4177 - mae: 269.1015 - val_loss: 319281.8750 - val_mse: 319281.8750 - val_mae: 298.8192\n",
      "Epoch 187/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 247420.1641 - mse: 247420.1641 - mae: 270.6338 - val_loss: 323416.6562 - val_mse: 323416.6562 - val_mae: 294.4049\n",
      "Epoch 188/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 246104.4825 - mse: 246104.4825 - mae: 270.0169 - val_loss: 304746.1250 - val_mse: 304746.1250 - val_mae: 292.0586\n",
      "Epoch 189/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 232228.3332 - mse: 232228.3332 - mae: 266.8194 - val_loss: 311385.5312 - val_mse: 311385.5312 - val_mae: 298.2264\n",
      "Epoch 190/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 243426.5643 - mse: 243426.5643 - mae: 268.6512 - val_loss: 309900.4688 - val_mse: 309900.4688 - val_mae: 293.0898\n",
      "Epoch 191/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 236945.0357 - mse: 236945.0357 - mae: 267.1331 - val_loss: 345581.1562 - val_mse: 345581.1562 - val_mae: 297.6038\n",
      "Epoch 192/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 231772.8075 - mse: 231772.8075 - mae: 263.8320 - val_loss: 336708.8438 - val_mse: 336708.8438 - val_mae: 311.9797\n",
      "Epoch 193/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 243613.2597 - mse: 243613.2597 - mae: 273.6322 - val_loss: 310431.8125 - val_mse: 310431.8125 - val_mae: 295.5113\n",
      "Epoch 194/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 240058.2240 - mse: 240058.2240 - mae: 266.8991 - val_loss: 309969.7188 - val_mse: 309969.7188 - val_mae: 292.6071\n",
      "Epoch 195/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 232417.6538 - mse: 232417.6538 - mae: 263.4943 - val_loss: 311823.0625 - val_mse: 311823.0625 - val_mae: 290.6372\n",
      "Epoch 196/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 240416.7689 - mse: 240416.7689 - mae: 270.3276 - val_loss: 343287.5625 - val_mse: 343287.5625 - val_mae: 300.6598\n",
      "Epoch 197/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 242806.5649 - mse: 242806.5649 - mae: 270.1694 - val_loss: 318246.3750 - val_mse: 318246.3750 - val_mae: 302.4414\n",
      "Epoch 198/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 234536.1568 - mse: 234536.1568 - mae: 267.3672 - val_loss: 327714.1250 - val_mse: 327714.1250 - val_mae: 302.6744\n",
      "Epoch 199/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 235756.8437 - mse: 235756.8437 - mae: 266.8597 - val_loss: 309455.7500 - val_mse: 309455.7500 - val_mae: 294.6651\n",
      "Epoch 200/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 234034.1086 - mse: 234034.1086 - mae: 266.9911 - val_loss: 338091.4688 - val_mse: 338091.4688 - val_mae: 322.2314\n",
      "Epoch 201/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 246059.6084 - mse: 246059.6084 - mae: 275.1215 - val_loss: 303656.2812 - val_mse: 303656.2812 - val_mae: 289.4969\n",
      "Epoch 202/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 228100.6259 - mse: 228100.6259 - mae: 263.2740 - val_loss: 310620.0000 - val_mse: 310620.0000 - val_mae: 295.1638\n",
      "Epoch 203/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 235055.7070 - mse: 235055.7070 - mae: 264.1290 - val_loss: 320470.3438 - val_mse: 320470.3438 - val_mae: 306.8421\n",
      "Epoch 204/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 236836.9504 - mse: 236836.9504 - mae: 269.1203 - val_loss: 335162.5000 - val_mse: 335162.5000 - val_mae: 305.3810\n",
      "Epoch 205/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 236716.5801 - mse: 236716.5801 - mae: 266.9763 - val_loss: 321319.3750 - val_mse: 321319.3750 - val_mae: 300.8274\n",
      "Epoch 206/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 239018.4990 - mse: 239018.4990 - mae: 269.7210 - val_loss: 316497.7500 - val_mse: 316497.7500 - val_mae: 294.4376\n",
      "Epoch 207/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 237081.7880 - mse: 237081.7880 - mae: 267.3762 - val_loss: 313695.6562 - val_mse: 313695.6562 - val_mae: 294.4023\n",
      "Epoch 208/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 233902.0789 - mse: 233902.0789 - mae: 264.8207 - val_loss: 312934.9375 - val_mse: 312934.9375 - val_mae: 300.3330\n",
      "Epoch 209/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 239623.6143 - mse: 239623.6143 - mae: 269.7721 - val_loss: 317687.2188 - val_mse: 317687.2188 - val_mae: 298.6624\n",
      "Epoch 210/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 234670.8502 - mse: 234670.8502 - mae: 267.6139 - val_loss: 321232.8750 - val_mse: 321232.8750 - val_mae: 302.0017\n",
      "Epoch 211/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 235226.2033 - mse: 235226.2033 - mae: 267.7312 - val_loss: 315777.8438 - val_mse: 315777.8438 - val_mae: 295.9114\n",
      "Epoch 212/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 240757.5574 - mse: 240757.5574 - mae: 266.5021 - val_loss: 320670.6875 - val_mse: 320670.6875 - val_mae: 295.3771\n",
      "Epoch 213/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 233961.1052 - mse: 233961.1052 - mae: 267.5687 - val_loss: 312410.2812 - val_mse: 312410.2812 - val_mae: 294.4917\n",
      "Epoch 214/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 247278.3210 - mse: 247278.3210 - mae: 271.5517 - val_loss: 314261.5000 - val_mse: 314261.5000 - val_mae: 291.4211\n",
      "Epoch 215/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 242381.2525 - mse: 242381.2525 - mae: 268.7164 - val_loss: 309212.0938 - val_mse: 309212.0938 - val_mae: 293.9939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 238662.9530 - mse: 238662.9530 - mae: 267.1513 - val_loss: 314253.4062 - val_mse: 314253.4062 - val_mae: 294.3423\n",
      "Epoch 217/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 228884.8906 - mse: 228884.8906 - mae: 264.6933 - val_loss: 323009.3438 - val_mse: 323009.3438 - val_mae: 292.1854\n",
      "Epoch 218/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 236174.2480 - mse: 236174.2480 - mae: 268.7834 - val_loss: 323088.9688 - val_mse: 323088.9688 - val_mae: 295.2176\n",
      "Epoch 219/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 244907.0462 - mse: 244907.0462 - mae: 270.7650 - val_loss: 321094.9062 - val_mse: 321094.9062 - val_mae: 290.7967\n",
      "Epoch 220/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 246306.9705 - mse: 246306.9705 - mae: 269.8759 - val_loss: 335228.8438 - val_mse: 335228.8438 - val_mae: 307.5865\n",
      "Epoch 221/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 240096.5881 - mse: 240096.5881 - mae: 269.3267 - val_loss: 322839.2500 - val_mse: 322839.2500 - val_mae: 303.5317\n",
      "Epoch 222/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 225152.8729 - mse: 225152.8729 - mae: 263.7711 - val_loss: 371509.3750 - val_mse: 371509.3750 - val_mae: 338.7170\n",
      "Epoch 223/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 244595.3133 - mse: 244595.3133 - mae: 270.2669 - val_loss: 324317.3438 - val_mse: 324317.3438 - val_mae: 307.8027\n",
      "Epoch 224/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 228826.7028 - mse: 228826.7028 - mae: 263.0863 - val_loss: 314873.8750 - val_mse: 314873.8750 - val_mae: 305.1473\n",
      "Epoch 225/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 222610.3017 - mse: 222610.3017 - mae: 259.9479 - val_loss: 316801.3125 - val_mse: 316801.3125 - val_mae: 296.4160\n",
      "Epoch 226/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 233248.4756 - mse: 233248.4756 - mae: 267.5940 - val_loss: 315154.0625 - val_mse: 315154.0625 - val_mae: 296.5942\n",
      "Epoch 227/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 235836.2489 - mse: 235836.2489 - mae: 266.4699 - val_loss: 317084.8750 - val_mse: 317084.8750 - val_mae: 301.4798\n",
      "Epoch 228/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 225278.3731 - mse: 225278.3731 - mae: 263.6072 - val_loss: 307893.0625 - val_mse: 307893.0625 - val_mae: 298.8237\n",
      "Epoch 229/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 230856.5505 - mse: 230856.5505 - mae: 262.3430 - val_loss: 311627.4062 - val_mse: 311627.4062 - val_mae: 294.4547\n",
      "Epoch 230/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 226061.4385 - mse: 226061.4385 - mae: 262.8927 - val_loss: 309251.0938 - val_mse: 309251.0938 - val_mae: 296.1748\n",
      "Epoch 231/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 236897.1503 - mse: 236897.1503 - mae: 266.8070 - val_loss: 328671.9375 - val_mse: 328671.9375 - val_mae: 299.9698\n",
      "Epoch 232/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 245195.2038 - mse: 245195.2038 - mae: 271.0981 - val_loss: 315515.0938 - val_mse: 315515.0938 - val_mae: 295.6144\n",
      "Epoch 233/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 232074.4636 - mse: 232074.4636 - mae: 264.6643 - val_loss: 331759.3750 - val_mse: 331759.3750 - val_mae: 289.7338\n",
      "Epoch 234/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 228352.7952 - mse: 228352.7952 - mae: 265.4407 - val_loss: 324492.5938 - val_mse: 324492.5938 - val_mae: 294.5728\n",
      "Epoch 235/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 230375.9067 - mse: 230375.9067 - mae: 264.4567 - val_loss: 325691.8438 - val_mse: 325691.8438 - val_mae: 294.9519\n",
      "Epoch 236/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 230855.5625 - mse: 230855.5625 - mae: 263.2450 - val_loss: 322083.7500 - val_mse: 322083.7500 - val_mae: 294.0713\n",
      "Epoch 237/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 230274.8850 - mse: 230274.8850 - mae: 263.4692 - val_loss: 346123.7812 - val_mse: 346123.7812 - val_mae: 322.0343\n",
      "Epoch 238/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 227678.7231 - mse: 227678.7231 - mae: 264.8310 - val_loss: 320113.3750 - val_mse: 320113.3750 - val_mae: 295.6869\n",
      "Epoch 239/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 223935.8381 - mse: 223935.8381 - mae: 260.5772 - val_loss: 337401.9688 - val_mse: 337401.9688 - val_mae: 324.4095\n",
      "Epoch 240/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 226097.1385 - mse: 226097.1385 - mae: 262.5390 - val_loss: 318489.5938 - val_mse: 318489.5938 - val_mae: 303.2340\n",
      "Epoch 241/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 235604.0228 - mse: 235604.0228 - mae: 266.9478 - val_loss: 319421.5625 - val_mse: 319421.5625 - val_mae: 302.9268\n",
      "Epoch 242/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 226171.0255 - mse: 226171.0255 - mae: 262.5371 - val_loss: 324690.0938 - val_mse: 324690.0938 - val_mae: 299.7880\n",
      "Epoch 243/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 228431.8166 - mse: 228431.8166 - mae: 260.6226 - val_loss: 354120.4062 - val_mse: 354120.4062 - val_mae: 312.2012\n",
      "Epoch 244/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 228819.2745 - mse: 228819.2745 - mae: 263.5630 - val_loss: 348659.6562 - val_mse: 348659.6562 - val_mae: 317.5231\n",
      "Epoch 245/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 229416.4165 - mse: 229416.4165 - mae: 263.1896 - val_loss: 346976.0938 - val_mse: 346976.0938 - val_mae: 308.0357\n",
      "Epoch 246/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 221444.2466 - mse: 221444.2466 - mae: 261.1030 - val_loss: 331396.5625 - val_mse: 331396.5625 - val_mae: 299.6045\n",
      "Epoch 247/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 220874.6960 - mse: 220874.6960 - mae: 259.7651 - val_loss: 309277.7188 - val_mse: 309277.7188 - val_mae: 296.6714\n",
      "Epoch 248/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 233060.4025 - mse: 233060.4025 - mae: 262.6245 - val_loss: 336984.0625 - val_mse: 336984.0625 - val_mae: 322.0210\n",
      "Epoch 249/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 233699.4501 - mse: 233699.4501 - mae: 267.7328 - val_loss: 309516.0000 - val_mse: 309516.0000 - val_mae: 293.6530\n",
      "Epoch 250/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 231819.5553 - mse: 231819.5553 - mae: 262.9818 - val_loss: 329808.0000 - val_mse: 329808.0000 - val_mae: 291.8221\n",
      "Epoch 251/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 230664.9100 - mse: 230664.9100 - mae: 263.7090 - val_loss: 323629.4688 - val_mse: 323629.4688 - val_mae: 307.9368\n",
      "Epoch 252/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 235129.8097 - mse: 235129.8097 - mae: 266.3408 - val_loss: 321673.2188 - val_mse: 321673.2188 - val_mae: 305.9546\n",
      "Epoch 253/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 229737.3664 - mse: 229737.3664 - mae: 262.1358 - val_loss: 323782.2500 - val_mse: 323782.2500 - val_mae: 296.5764\n",
      "Epoch 254/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 222885.0267 - mse: 222885.0267 - mae: 261.9020 - val_loss: 333374.2812 - val_mse: 333374.2812 - val_mae: 313.6124\n",
      "Epoch 255/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 223858.2778 - mse: 223858.2778 - mae: 261.3555 - val_loss: 341549.4062 - val_mse: 341549.4062 - val_mae: 328.4956\n",
      "Epoch 256/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 226896.9791 - mse: 226896.9791 - mae: 263.4424 - val_loss: 324423.0625 - val_mse: 324423.0625 - val_mae: 296.6664\n",
      "Epoch 257/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 236440.1999 - mse: 236440.1999 - mae: 269.4516 - val_loss: 331344.5000 - val_mse: 331344.5000 - val_mae: 297.7448\n",
      "Epoch 258/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 229105.7670 - mse: 229105.7670 - mae: 262.6266 - val_loss: 321308.4375 - val_mse: 321308.4375 - val_mae: 293.8232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 219981.2948 - mse: 219981.2948 - mae: 258.6278 - val_loss: 310957.5312 - val_mse: 310957.5312 - val_mae: 292.5421\n",
      "Epoch 260/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 217186.0441 - mse: 217186.0441 - mae: 259.2535 - val_loss: 335067.4375 - val_mse: 335067.4375 - val_mae: 299.0980\n",
      "Epoch 261/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 223720.5413 - mse: 223720.5413 - mae: 261.9029 - val_loss: 323414.5625 - val_mse: 323414.5625 - val_mae: 300.1036\n",
      "Epoch 262/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 220900.7634 - mse: 220900.7634 - mae: 257.7059 - val_loss: 328993.3125 - val_mse: 328993.3125 - val_mae: 295.8835\n",
      "Epoch 263/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 221663.5825 - mse: 221663.5825 - mae: 260.8850 - val_loss: 335563.3438 - val_mse: 335563.3438 - val_mae: 306.6711\n",
      "Epoch 264/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 228563.5583 - mse: 228563.5583 - mae: 265.2619 - val_loss: 318719.3750 - val_mse: 318719.3750 - val_mae: 300.5758\n",
      "Epoch 265/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 230099.9837 - mse: 230099.9837 - mae: 263.1692 - val_loss: 310887.7812 - val_mse: 310887.7812 - val_mae: 293.2674\n",
      "Epoch 266/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 227922.9836 - mse: 227922.9836 - mae: 260.2334 - val_loss: 321867.2812 - val_mse: 321867.2812 - val_mae: 297.9471\n",
      "Epoch 267/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 223797.2160 - mse: 223797.2160 - mae: 260.8108 - val_loss: 314765.4375 - val_mse: 314765.4375 - val_mae: 293.3625\n",
      "Epoch 268/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 220467.3684 - mse: 220467.3684 - mae: 261.0365 - val_loss: 336888.4062 - val_mse: 336888.4062 - val_mae: 309.8225\n",
      "Epoch 269/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 227619.2838 - mse: 227619.2838 - mae: 261.3129 - val_loss: 318573.1562 - val_mse: 318573.1562 - val_mae: 301.3075\n",
      "Epoch 270/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 227589.8985 - mse: 227589.8985 - mae: 263.1327 - val_loss: 324697.2188 - val_mse: 324697.2188 - val_mae: 295.0111\n",
      "Epoch 271/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 222256.0804 - mse: 222256.0804 - mae: 263.2421 - val_loss: 313019.3750 - val_mse: 313019.3750 - val_mae: 295.7674\n",
      "Epoch 272/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 217137.5661 - mse: 217137.5661 - mae: 256.5826 - val_loss: 325908.9375 - val_mse: 325908.9375 - val_mae: 294.8534\n",
      "Epoch 273/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 220239.0389 - mse: 220239.0389 - mae: 260.7535 - val_loss: 318649.3125 - val_mse: 318649.3125 - val_mae: 299.6543\n",
      "Epoch 274/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 215937.9492 - mse: 215937.9492 - mae: 258.3016 - val_loss: 325982.0000 - val_mse: 325982.0000 - val_mae: 305.1850\n",
      "Epoch 275/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 220447.1719 - mse: 220447.1719 - mae: 258.5204 - val_loss: 319395.2188 - val_mse: 319395.2188 - val_mae: 297.0250\n",
      "Epoch 276/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 224298.4469 - mse: 224298.4469 - mae: 259.3606 - val_loss: 315127.9688 - val_mse: 315127.9688 - val_mae: 294.4969\n",
      "Epoch 277/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 215661.0262 - mse: 215661.0262 - mae: 257.6166 - val_loss: 327198.3125 - val_mse: 327198.3125 - val_mae: 290.1078\n",
      "Epoch 278/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 222070.7625 - mse: 222070.7625 - mae: 259.0165 - val_loss: 312252.7188 - val_mse: 312252.7188 - val_mae: 295.1366\n",
      "Epoch 279/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 213749.3561 - mse: 213749.3561 - mae: 255.6851 - val_loss: 314860.9375 - val_mse: 314860.9375 - val_mae: 308.6418\n",
      "Epoch 280/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 214157.8461 - mse: 214157.8461 - mae: 258.4564 - val_loss: 319581.8750 - val_mse: 319581.8750 - val_mae: 294.1986\n",
      "Epoch 281/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 213331.9024 - mse: 213331.9024 - mae: 256.2731 - val_loss: 320917.2812 - val_mse: 320917.2812 - val_mae: 298.2613\n",
      "Epoch 282/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 221964.8062 - mse: 221964.8062 - mae: 260.4203 - val_loss: 318091.1875 - val_mse: 318091.1875 - val_mae: 301.7417\n",
      "Epoch 283/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 215608.5599 - mse: 215608.5599 - mae: 256.9943 - val_loss: 321089.4062 - val_mse: 321089.4062 - val_mae: 304.9826\n",
      "Epoch 284/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 212410.5698 - mse: 212410.5698 - mae: 258.4146 - val_loss: 333660.9375 - val_mse: 333660.9375 - val_mae: 305.7179\n",
      "Epoch 285/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 218989.4110 - mse: 218989.4110 - mae: 259.3167 - val_loss: 313212.4062 - val_mse: 313212.4062 - val_mae: 292.5691\n",
      "Epoch 286/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 214449.9152 - mse: 214449.9152 - mae: 257.5660 - val_loss: 328203.9688 - val_mse: 328203.9688 - val_mae: 306.3287\n",
      "Epoch 287/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 217678.6559 - mse: 217678.6559 - mae: 259.6683 - val_loss: 308693.9375 - val_mse: 308693.9375 - val_mae: 292.6335\n",
      "Epoch 288/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 215638.3646 - mse: 215638.3646 - mae: 256.8541 - val_loss: 364858.0625 - val_mse: 364858.0625 - val_mae: 330.1000\n",
      "Epoch 289/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 218553.2492 - mse: 218553.2492 - mae: 260.6763 - val_loss: 323607.7812 - val_mse: 323607.7812 - val_mae: 297.8887\n",
      "Epoch 290/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 220397.2745 - mse: 220397.2745 - mae: 262.4879 - val_loss: 321330.4688 - val_mse: 321330.4688 - val_mae: 296.1822\n",
      "Epoch 291/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 211862.0924 - mse: 211862.0924 - mae: 256.9805 - val_loss: 318922.9688 - val_mse: 318922.9688 - val_mae: 299.4205\n",
      "Epoch 292/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 217095.6361 - mse: 217095.6361 - mae: 257.7092 - val_loss: 331693.7812 - val_mse: 331693.7812 - val_mae: 305.9102\n",
      "Epoch 293/300\n",
      "683/683 [==============================] - 2s 4ms/step - loss: 226361.1027 - mse: 226361.1027 - mae: 263.3305 - val_loss: 326332.5312 - val_mse: 326332.5312 - val_mae: 297.1034\n",
      "Epoch 294/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 211982.5627 - mse: 211982.5627 - mae: 255.3670 - val_loss: 317877.6562 - val_mse: 317877.6562 - val_mae: 299.0496\n",
      "Epoch 295/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 212972.1443 - mse: 212972.1443 - mae: 256.0955 - val_loss: 319910.3438 - val_mse: 319910.3438 - val_mae: 293.5346\n",
      "Epoch 296/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 208765.4572 - mse: 208765.4572 - mae: 255.1075 - val_loss: 331528.4375 - val_mse: 331528.4375 - val_mae: 300.5225\n",
      "Epoch 297/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 213415.6854 - mse: 213415.6854 - mae: 257.3417 - val_loss: 316351.5000 - val_mse: 316351.5000 - val_mae: 296.7169\n",
      "Epoch 298/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 223704.4441 - mse: 223704.4441 - mae: 260.5482 - val_loss: 317722.5938 - val_mse: 317722.5938 - val_mae: 301.5165\n",
      "Epoch 299/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 205669.1031 - mse: 205669.1031 - mae: 252.9769 - val_loss: 323710.9688 - val_mse: 323710.9688 - val_mae: 299.6107\n",
      "Epoch 300/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 210053.0026 - mse: 210053.0026 - mae: 254.5601 - val_loss: 327546.5000 - val_mse: 327546.5000 - val_mae: 305.4178\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 300\n",
    "history = nn_reg2.fit(X_train, y_train,\n",
    "                      epochs=n_epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(history.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(history.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_ylim(12,14)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stoping = EarlyStopping(monitor='val_mean_absolute_error',\n",
    "                              min_delta=5,\n",
    "                              patience=20,\n",
    "                              verbose=1,\n",
    "                              mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg2 = Sequential()\n",
    "n_hidden = 64\n",
    "# hidden layers\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu', input_shape=(n_input,)))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg2.add(Dense(units=n_hidden, activation='relu'))\n",
    "# output layer\n",
    "nn_reg2.add(Dense(units=1, activation=None))\n",
    "# compilation\n",
    "nn_reg2.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43683 samples, validate on 4854 samples\n",
      "Epoch 1/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 4003936.0924 - mse: 4003936.0000 - mae: 975.8764 - val_loss: 1007149.5623 - val_mse: 1007149.4375 - val_mae: 535.9521\n",
      "Epoch 2/300\n",
      " 6016/43683 [===>..........................] - ETA: 0s - loss: 802061.5098 - mse: 802061.5625 - mae: 482.7067"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\ho-pawp\\lib\\site-packages\\keras\\callbacks\\callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: val_loss,val_mse,val_mae,loss,mse,mae\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43683/43683 [==============================] - 1s 25us/step - loss: 737259.9787 - mse: 737260.0000 - mae: 449.3518 - val_loss: 654988.1771 - val_mse: 654988.1250 - val_mae: 411.0558\n",
      "Epoch 3/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 568669.9191 - mse: 568669.5625 - mae: 393.7597 - val_loss: 634119.4010 - val_mse: 634119.3750 - val_mae: 444.4188\n",
      "Epoch 4/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 494174.2445 - mse: 494174.1875 - mae: 374.5719 - val_loss: 530084.9866 - val_mse: 530085.1875 - val_mae: 416.8546\n",
      "Epoch 5/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 449628.1784 - mse: 449628.0625 - mae: 367.1833 - val_loss: 523303.5250 - val_mse: 523303.4375 - val_mae: 403.3629\n",
      "Epoch 6/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 413053.5653 - mse: 413053.5625 - mae: 352.9250 - val_loss: 416362.5259 - val_mse: 416362.5625 - val_mae: 343.4565\n",
      "Epoch 7/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 392941.7917 - mse: 392941.8125 - mae: 346.4460 - val_loss: 447790.0357 - val_mse: 447790.0938 - val_mae: 370.4063\n",
      "Epoch 8/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 371991.5748 - mse: 371991.5938 - mae: 340.3650 - val_loss: 416884.5309 - val_mse: 416884.5625 - val_mae: 342.1278\n",
      "Epoch 9/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 361214.9665 - mse: 361214.9688 - mae: 333.9273 - val_loss: 444311.8852 - val_mse: 444311.8438 - val_mae: 363.3210\n",
      "Epoch 10/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 354334.4986 - mse: 354334.4375 - mae: 331.8657 - val_loss: 427869.5430 - val_mse: 427869.4688 - val_mae: 362.2136\n",
      "Epoch 11/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 350694.8604 - mse: 350695.2188 - mae: 329.0718 - val_loss: 357026.0073 - val_mse: 357025.9375 - val_mae: 324.8131\n",
      "Epoch 12/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 339209.7734 - mse: 339209.7188 - mae: 324.1700 - val_loss: 356615.1635 - val_mse: 356615.1875 - val_mae: 323.4329\n",
      "Epoch 13/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 336881.2417 - mse: 336881.3438 - mae: 321.1198 - val_loss: 352088.9562 - val_mse: 352088.9375 - val_mae: 325.0019\n",
      "Epoch 14/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 333143.6400 - mse: 333143.9375 - mae: 321.2119 - val_loss: 351157.7556 - val_mse: 351157.7188 - val_mae: 315.0033\n",
      "Epoch 15/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 331396.5730 - mse: 331396.5938 - mae: 319.5787 - val_loss: 355793.0093 - val_mse: 355793.0000 - val_mae: 331.9779\n",
      "Epoch 16/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 332389.6030 - mse: 332389.5938 - mae: 319.7236 - val_loss: 377806.0365 - val_mse: 377806.0000 - val_mae: 330.5357\n",
      "Epoch 17/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 332896.2742 - mse: 332896.4062 - mae: 321.0887 - val_loss: 350744.5371 - val_mse: 350744.6250 - val_mae: 319.5370\n",
      "Epoch 18/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 326697.9964 - mse: 326697.8750 - mae: 316.4583 - val_loss: 357583.6508 - val_mse: 357583.6250 - val_mae: 321.2572\n",
      "Epoch 19/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 326514.6598 - mse: 326514.6250 - mae: 316.6749 - val_loss: 344265.0490 - val_mse: 344265.0625 - val_mae: 311.5296\n",
      "Epoch 20/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 325916.7013 - mse: 325916.8438 - mae: 316.3019 - val_loss: 344642.0461 - val_mse: 344642.0625 - val_mae: 320.9206\n",
      "Epoch 21/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 320389.1978 - mse: 320389.3438 - mae: 312.7044 - val_loss: 375903.8817 - val_mse: 375903.8438 - val_mae: 326.0506\n",
      "Epoch 22/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 318297.6324 - mse: 318297.5625 - mae: 311.5576 - val_loss: 354003.8597 - val_mse: 354003.8750 - val_mae: 310.3648\n",
      "Epoch 23/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 323684.5349 - mse: 323684.4375 - mae: 313.9506 - val_loss: 376578.1816 - val_mse: 376578.1875 - val_mae: 329.2351\n",
      "Epoch 24/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 319462.5803 - mse: 319462.7188 - mae: 310.0334 - val_loss: 334211.3133 - val_mse: 334211.2812 - val_mae: 308.8277\n",
      "Epoch 25/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 313737.9812 - mse: 313737.9688 - mae: 307.6099 - val_loss: 336641.3728 - val_mse: 336641.4062 - val_mae: 308.8768\n",
      "Epoch 26/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 307179.7947 - mse: 307179.8750 - mae: 302.0638 - val_loss: 337037.3895 - val_mse: 337037.4375 - val_mae: 306.5081\n",
      "Epoch 27/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 306253.8799 - mse: 306253.8438 - mae: 302.8835 - val_loss: 417575.1512 - val_mse: 417575.1250 - val_mae: 352.3109\n",
      "Epoch 28/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 306325.2782 - mse: 306325.2500 - mae: 303.7530 - val_loss: 360581.8627 - val_mse: 360581.8438 - val_mae: 322.2914\n",
      "Epoch 29/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 307673.9730 - mse: 307673.9062 - mae: 302.6741 - val_loss: 399490.4149 - val_mse: 399490.4375 - val_mae: 332.4572\n",
      "Epoch 30/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 306166.2742 - mse: 306166.2188 - mae: 304.5016 - val_loss: 455273.3778 - val_mse: 455273.2812 - val_mae: 378.6346\n",
      "Epoch 31/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 305404.1572 - mse: 305403.9375 - mae: 301.8528 - val_loss: 328123.6076 - val_mse: 328123.5625 - val_mae: 308.6534\n",
      "Epoch 32/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 308809.9138 - mse: 308809.8125 - mae: 302.7871 - val_loss: 321398.8897 - val_mse: 321398.8438 - val_mae: 303.6352\n",
      "Epoch 33/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 306718.9220 - mse: 306719.0000 - mae: 302.4326 - val_loss: 323312.4123 - val_mse: 323312.4688 - val_mae: 305.6357\n",
      "Epoch 34/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 300533.9888 - mse: 300533.9375 - mae: 299.6198 - val_loss: 337105.2880 - val_mse: 337105.2500 - val_mae: 314.7435\n",
      "Epoch 35/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 304439.4574 - mse: 304439.3125 - mae: 300.4066 - val_loss: 321102.2596 - val_mse: 321102.2812 - val_mae: 296.6237\n",
      "Epoch 36/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 300612.6849 - mse: 300612.6875 - mae: 298.7294 - val_loss: 319698.7039 - val_mse: 319698.6875 - val_mae: 303.9535\n",
      "Epoch 37/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 299616.5201 - mse: 299616.4375 - mae: 296.1544 - val_loss: 336342.4620 - val_mse: 336342.4688 - val_mae: 304.9429\n",
      "Epoch 38/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 298317.1604 - mse: 298317.1875 - mae: 297.8174 - val_loss: 397219.9228 - val_mse: 397219.8750 - val_mae: 348.9720\n",
      "Epoch 39/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 296180.9645 - mse: 296181.0938 - mae: 297.1197 - val_loss: 382650.7248 - val_mse: 382650.7188 - val_mae: 345.5117\n",
      "Epoch 40/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 298751.0988 - mse: 298751.0938 - mae: 298.2477 - val_loss: 325013.0392 - val_mse: 325013.0312 - val_mae: 301.2893\n",
      "Epoch 41/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 292092.7199 - mse: 292092.7500 - mae: 293.0572 - val_loss: 315502.7669 - val_mse: 315502.7500 - val_mae: 298.1691\n",
      "Epoch 42/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 290012.9862 - mse: 290012.9375 - mae: 293.2235 - val_loss: 342172.1684 - val_mse: 342172.1875 - val_mae: 309.7389\n",
      "Epoch 43/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 293282.5461 - mse: 293282.5000 - mae: 294.4001 - val_loss: 317579.6079 - val_mse: 317579.6250 - val_mae: 306.3517\n",
      "Epoch 44/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 295862.4372 - mse: 295862.2188 - mae: 294.7399 - val_loss: 369058.3286 - val_mse: 369058.3438 - val_mae: 330.8962\n",
      "Epoch 45/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 295401.3970 - mse: 295401.4375 - mae: 294.2591 - val_loss: 327868.1680 - val_mse: 327868.1875 - val_mae: 300.8989\n",
      "Epoch 46/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 289720.9281 - mse: 289721.0312 - mae: 291.7382 - val_loss: 374711.5872 - val_mse: 374711.6250 - val_mae: 300.6436\n",
      "Epoch 47/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 301246.5364 - mse: 301246.6562 - mae: 299.2052 - val_loss: 319288.4141 - val_mse: 319288.5000 - val_mae: 303.7585\n",
      "Epoch 48/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 287643.0735 - mse: 287643.0625 - mae: 289.6118 - val_loss: 349553.9847 - val_mse: 349553.9375 - val_mae: 323.7435\n",
      "Epoch 49/300\n",
      "43683/43683 [==============================] - ETA: 0s - loss: 287610.5679 - mse: 287610.5312 - mae: 290.934 - 1s 23us/step - loss: 289049.9648 - mse: 289049.8750 - mae: 291.4399 - val_loss: 321973.3925 - val_mse: 321973.4375 - val_mae: 301.7187\n",
      "Epoch 50/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 292877.0581 - mse: 292877.0000 - mae: 294.1315 - val_loss: 332352.3987 - val_mse: 332352.4062 - val_mae: 294.5467\n",
      "Epoch 51/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 288567.9435 - mse: 288568.1250 - mae: 289.7615 - val_loss: 356101.0392 - val_mse: 356101.1250 - val_mae: 306.5784\n",
      "Epoch 52/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 292337.1461 - mse: 292337.1250 - mae: 294.0284 - val_loss: 337541.2966 - val_mse: 337541.3125 - val_mae: 310.4595\n",
      "Epoch 53/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 287373.1848 - mse: 287373.2500 - mae: 291.1573 - val_loss: 316029.1339 - val_mse: 316029.1562 - val_mae: 296.7360\n",
      "Epoch 54/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 289379.1983 - mse: 289379.1250 - mae: 291.9216 - val_loss: 338584.6370 - val_mse: 338584.6250 - val_mae: 314.8083\n",
      "Epoch 55/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 288428.6846 - mse: 288428.9062 - mae: 291.3482 - val_loss: 319602.2836 - val_mse: 319602.2812 - val_mae: 300.0019\n",
      "Epoch 56/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 286939.0916 - mse: 286939.0938 - mae: 290.5670 - val_loss: 316204.8177 - val_mse: 316204.8438 - val_mae: 297.1051\n",
      "Epoch 57/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 287316.6751 - mse: 287316.7188 - mae: 289.6996 - val_loss: 388194.6297 - val_mse: 388194.5938 - val_mae: 359.1020\n",
      "Epoch 58/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 291823.6367 - mse: 291823.6250 - mae: 292.2290 - val_loss: 337637.5916 - val_mse: 337637.5625 - val_mae: 303.6115\n",
      "Epoch 59/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 283075.0867 - mse: 283075.3125 - mae: 287.3043 - val_loss: 365730.1860 - val_mse: 365730.1562 - val_mae: 329.4390\n",
      "Epoch 60/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 283478.8320 - mse: 283479.0000 - mae: 287.2532 - val_loss: 326888.3092 - val_mse: 326888.3750 - val_mae: 301.1861\n",
      "Epoch 61/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 286489.2178 - mse: 286489.3750 - mae: 289.9587 - val_loss: 344938.0351 - val_mse: 344938.0938 - val_mae: 313.0186\n",
      "Epoch 62/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 287145.7812 - mse: 287146.0312 - mae: 289.8172 - val_loss: 309379.3281 - val_mse: 309379.2812 - val_mae: 291.5886\n",
      "Epoch 63/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 284630.6981 - mse: 284630.7188 - mae: 288.4805 - val_loss: 316300.6904 - val_mse: 316300.7500 - val_mae: 288.4791\n",
      "Epoch 64/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 287478.3743 - mse: 287478.5312 - mae: 289.2070 - val_loss: 311818.8902 - val_mse: 311818.8438 - val_mae: 290.3627\n",
      "Epoch 65/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 281219.5630 - mse: 281219.7500 - mae: 286.4693 - val_loss: 315331.9626 - val_mse: 315331.9688 - val_mae: 296.0398\n",
      "Epoch 66/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 280260.8576 - mse: 280260.9062 - mae: 286.4787 - val_loss: 319754.0100 - val_mse: 319754.0312 - val_mae: 287.8061\n",
      "Epoch 67/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 278010.5457 - mse: 278010.5625 - mae: 284.7018 - val_loss: 330030.0718 - val_mse: 330030.1250 - val_mae: 329.8276\n",
      "Epoch 68/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 286291.1030 - mse: 286290.9062 - mae: 289.4108 - val_loss: 336808.6737 - val_mse: 336808.6562 - val_mae: 308.6267\n",
      "Epoch 69/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 281276.4253 - mse: 281276.3125 - mae: 285.8395 - val_loss: 310387.4814 - val_mse: 310387.5625 - val_mae: 292.5061\n",
      "Epoch 70/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 279473.7789 - mse: 279473.5312 - mae: 284.9728 - val_loss: 313056.7215 - val_mse: 313056.7188 - val_mae: 292.4235\n",
      "Epoch 71/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 280727.8163 - mse: 280727.8438 - mae: 284.5789 - val_loss: 309488.2282 - val_mse: 309488.2188 - val_mae: 284.6347\n",
      "Epoch 72/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 280029.6744 - mse: 280029.6250 - mae: 285.3153 - val_loss: 311710.6589 - val_mse: 311710.7188 - val_mae: 289.9978\n",
      "Epoch 73/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 283250.0529 - mse: 283250.1250 - mae: 287.5381 - val_loss: 313560.4119 - val_mse: 313560.3438 - val_mae: 296.8220\n",
      "Epoch 74/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 274155.3570 - mse: 274155.2500 - mae: 282.6621 - val_loss: 309921.3353 - val_mse: 309921.3438 - val_mae: 286.5617\n",
      "Epoch 75/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 281059.5614 - mse: 281059.6562 - mae: 285.7372 - val_loss: 333855.8424 - val_mse: 333855.8750 - val_mae: 308.6132\n",
      "Epoch 76/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 285284.8612 - mse: 285284.7812 - mae: 289.5501 - val_loss: 303255.6788 - val_mse: 303255.6875 - val_mae: 289.4071\n",
      "Epoch 77/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 274575.2370 - mse: 274575.2812 - mae: 282.1888 - val_loss: 299374.8010 - val_mse: 299374.8750 - val_mae: 286.6147\n",
      "Epoch 78/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 287731.3813 - mse: 287731.3750 - mae: 289.5809 - val_loss: 318476.8172 - val_mse: 318476.9062 - val_mae: 296.9714\n",
      "Epoch 79/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 273490.7012 - mse: 273490.6250 - mae: 282.4410 - val_loss: 332312.7313 - val_mse: 332312.7500 - val_mae: 320.0858\n",
      "Epoch 80/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 277843.1901 - mse: 277843.1875 - mae: 284.6530 - val_loss: 317576.8379 - val_mse: 317576.9062 - val_mae: 289.6458\n",
      "Epoch 81/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 273804.3183 - mse: 273804.4688 - mae: 283.1208 - val_loss: 304791.4312 - val_mse: 304791.4688 - val_mae: 290.8829\n",
      "Epoch 82/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 276836.1064 - mse: 276836.0625 - mae: 284.2069 - val_loss: 336645.1052 - val_mse: 336645.0625 - val_mae: 306.6288\n",
      "Epoch 83/300\n",
      "43683/43683 [==============================] - ETA: 0s - loss: 275445.1637 - mse: 275445.1562 - mae: 282.232 - 1s 24us/step - loss: 274842.6948 - mse: 274842.6875 - mae: 282.0891 - val_loss: 333664.7212 - val_mse: 333664.6875 - val_mae: 295.2873\n",
      "Epoch 84/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 278110.2914 - mse: 278110.4375 - mae: 285.3434 - val_loss: 309953.2706 - val_mse: 309953.2812 - val_mae: 299.4075\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43683/43683 [==============================] - 1s 24us/step - loss: 270060.0140 - mse: 270060.1250 - mae: 279.7009 - val_loss: 314722.6687 - val_mse: 314722.6250 - val_mae: 292.0833\n",
      "Epoch 86/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 273887.1708 - mse: 273887.0938 - mae: 282.5605 - val_loss: 306906.9907 - val_mse: 306906.9688 - val_mae: 291.1053\n",
      "Epoch 87/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 274445.9768 - mse: 274446.0938 - mae: 282.3090 - val_loss: 340669.2319 - val_mse: 340669.2188 - val_mae: 308.8387\n",
      "Epoch 88/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 270403.3062 - mse: 270403.2812 - mae: 280.4783 - val_loss: 328163.4853 - val_mse: 328163.5000 - val_mae: 301.4230\n",
      "Epoch 89/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 274955.0034 - mse: 274954.8750 - mae: 282.6527 - val_loss: 305554.3486 - val_mse: 305554.3125 - val_mae: 290.4977\n",
      "Epoch 90/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 271997.7535 - mse: 271997.8438 - mae: 280.8861 - val_loss: 305570.9870 - val_mse: 305571.0312 - val_mae: 291.4323\n",
      "Epoch 91/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 270062.1049 - mse: 270061.9062 - mae: 280.8344 - val_loss: 305497.0100 - val_mse: 305497.1250 - val_mae: 289.0956\n",
      "Epoch 92/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 272892.8706 - mse: 272892.9062 - mae: 282.5260 - val_loss: 303274.6220 - val_mse: 303274.6562 - val_mae: 288.2534\n",
      "Epoch 93/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 276096.8655 - mse: 276097.0938 - mae: 282.8866 - val_loss: 308339.8959 - val_mse: 308339.9375 - val_mae: 292.1053\n",
      "Epoch 94/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 270283.7269 - mse: 270283.7812 - mae: 281.1064 - val_loss: 313083.5773 - val_mse: 313083.5625 - val_mae: 297.2391\n",
      "Epoch 95/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 272425.5766 - mse: 272425.5000 - mae: 281.9653 - val_loss: 305817.1570 - val_mse: 305817.1250 - val_mae: 292.0575\n",
      "Epoch 96/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 276923.2874 - mse: 276923.1562 - mae: 285.6942 - val_loss: 345134.9731 - val_mse: 345134.9688 - val_mae: 306.6909\n",
      "Epoch 97/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 268680.2912 - mse: 268680.2500 - mae: 279.0560 - val_loss: 318869.8268 - val_mse: 318869.7812 - val_mae: 296.2910\n",
      "Epoch 98/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 276403.5517 - mse: 276403.5625 - mae: 283.3313 - val_loss: 313248.1853 - val_mse: 313248.1562 - val_mae: 289.3951\n",
      "Epoch 99/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 266542.8156 - mse: 266542.7812 - mae: 278.3502 - val_loss: 366969.9897 - val_mse: 366969.9375 - val_mae: 333.7301\n",
      "Epoch 100/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 272949.4336 - mse: 272949.5625 - mae: 281.8365 - val_loss: 314577.5199 - val_mse: 314577.5000 - val_mae: 294.0912\n",
      "Epoch 101/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 264342.7561 - mse: 264342.6250 - mae: 278.6046 - val_loss: 308154.0489 - val_mse: 308154.1250 - val_mae: 289.9248\n",
      "Epoch 102/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 268571.9273 - mse: 268571.9375 - mae: 279.4060 - val_loss: 340082.0389 - val_mse: 340082.0938 - val_mae: 315.2452\n",
      "Epoch 103/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 269545.1549 - mse: 269545.1875 - mae: 281.0064 - val_loss: 324806.0256 - val_mse: 324806.0938 - val_mae: 300.3329\n",
      "Epoch 104/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 268336.3625 - mse: 268336.2812 - mae: 279.0092 - val_loss: 340341.8916 - val_mse: 340341.8438 - val_mae: 310.7274\n",
      "Epoch 105/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 263439.4468 - mse: 263439.3438 - mae: 276.6681 - val_loss: 297433.1071 - val_mse: 297433.0625 - val_mae: 288.1931\n",
      "Epoch 106/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 265656.2338 - mse: 265656.1250 - mae: 278.9770 - val_loss: 345136.6465 - val_mse: 345136.5938 - val_mae: 313.4157\n",
      "Epoch 107/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 266465.9591 - mse: 266466.0625 - mae: 279.1889 - val_loss: 343138.0125 - val_mse: 343138.0312 - val_mae: 323.8173\n",
      "Epoch 108/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 268223.7690 - mse: 268223.7812 - mae: 280.3290 - val_loss: 371941.1477 - val_mse: 371941.1250 - val_mae: 313.1924\n",
      "Epoch 109/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 266152.1047 - mse: 266152.1250 - mae: 278.5280 - val_loss: 315607.3876 - val_mse: 315607.4062 - val_mae: 291.6393\n",
      "Epoch 110/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 267440.3948 - mse: 267440.3750 - mae: 278.7634 - val_loss: 321616.1832 - val_mse: 321616.1875 - val_mae: 304.6168\n",
      "Epoch 111/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 262560.6312 - mse: 262560.6562 - mae: 276.2894 - val_loss: 299988.8287 - val_mse: 299988.8125 - val_mae: 285.0544\n",
      "Epoch 112/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 261234.3705 - mse: 261234.3750 - mae: 274.6666 - val_loss: 301036.2528 - val_mse: 301036.1562 - val_mae: 286.9766\n",
      "Epoch 113/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 264437.1579 - mse: 264437.2812 - mae: 277.6098 - val_loss: 311718.1900 - val_mse: 311718.2188 - val_mae: 302.8306\n",
      "Epoch 114/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 265888.1811 - mse: 265888.3125 - mae: 278.9052 - val_loss: 305962.5361 - val_mse: 305962.4375 - val_mae: 287.4059\n",
      "Epoch 115/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 267786.8396 - mse: 267786.7812 - mae: 278.5187 - val_loss: 330517.3564 - val_mse: 330517.3438 - val_mae: 339.7585\n",
      "Epoch 116/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 262149.7030 - mse: 262149.8750 - mae: 276.1630 - val_loss: 319391.8620 - val_mse: 319391.8438 - val_mae: 292.7494\n",
      "Epoch 117/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 261884.7975 - mse: 261884.7344 - mae: 277.6031 - val_loss: 297526.2588 - val_mse: 297526.2188 - val_mae: 285.8243\n",
      "Epoch 118/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 265357.3055 - mse: 265357.4062 - mae: 279.0652 - val_loss: 346646.3517 - val_mse: 346646.3750 - val_mae: 328.3971\n",
      "Epoch 119/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 264775.0534 - mse: 264775.1250 - mae: 278.8280 - val_loss: 299169.2716 - val_mse: 299169.3438 - val_mae: 284.3704\n",
      "Epoch 120/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 264315.7854 - mse: 264315.7812 - mae: 277.7792 - val_loss: 307302.9704 - val_mse: 307302.9375 - val_mae: 293.8249\n",
      "Epoch 121/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 258728.6968 - mse: 258728.8125 - mae: 274.3849 - val_loss: 302700.4807 - val_mse: 302700.4375 - val_mae: 286.5170\n",
      "Epoch 122/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 260416.1563 - mse: 260416.1250 - mae: 274.4950 - val_loss: 310591.6365 - val_mse: 310591.5938 - val_mae: 293.1663\n",
      "Epoch 123/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 260255.9106 - mse: 260256.0156 - mae: 275.4096 - val_loss: 298173.8817 - val_mse: 298173.9688 - val_mae: 287.3353\n",
      "Epoch 124/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 261930.8601 - mse: 261930.7344 - mae: 277.2644 - val_loss: 341550.8693 - val_mse: 341550.8750 - val_mae: 319.7318\n",
      "Epoch 125/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 266656.2509 - mse: 266656.4062 - mae: 279.7474 - val_loss: 304777.4333 - val_mse: 304777.3750 - val_mae: 283.6125\n",
      "Epoch 126/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 260965.7523 - mse: 260965.6406 - mae: 274.9376 - val_loss: 319393.1758 - val_mse: 319393.1562 - val_mae: 298.4681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 253140.9366 - mse: 253140.8750 - mae: 270.4144 - val_loss: 309238.0732 - val_mse: 309238.0938 - val_mae: 295.8020\n",
      "Epoch 128/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 267934.9018 - mse: 267935.1250 - mae: 280.5613 - val_loss: 323124.4446 - val_mse: 323124.4688 - val_mae: 292.1029\n",
      "Epoch 129/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 263503.0688 - mse: 263503.0625 - mae: 278.3088 - val_loss: 304527.3884 - val_mse: 304527.4062 - val_mae: 296.8335\n",
      "Epoch 130/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 260755.7998 - mse: 260755.7812 - mae: 275.1534 - val_loss: 351893.0284 - val_mse: 351892.9688 - val_mae: 331.7328\n",
      "Epoch 131/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 259554.7555 - mse: 259554.7969 - mae: 276.1285 - val_loss: 317606.1352 - val_mse: 317606.1562 - val_mae: 297.1856\n",
      "Epoch 132/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 256399.1861 - mse: 256399.2969 - mae: 272.3231 - val_loss: 298632.2746 - val_mse: 298632.3125 - val_mae: 287.6785\n",
      "Epoch 133/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 258990.4839 - mse: 258990.5000 - mae: 275.4297 - val_loss: 319742.1374 - val_mse: 319742.0938 - val_mae: 287.8960\n",
      "Epoch 134/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 255622.7361 - mse: 255622.6406 - mae: 272.7566 - val_loss: 294917.4532 - val_mse: 294917.3438 - val_mae: 280.9335\n",
      "Epoch 135/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 257806.5131 - mse: 257806.5938 - mae: 273.6565 - val_loss: 312062.9840 - val_mse: 312062.9375 - val_mae: 295.5735\n",
      "Epoch 136/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 259731.0113 - mse: 259730.8281 - mae: 275.8299 - val_loss: 309026.7830 - val_mse: 309026.7812 - val_mae: 297.9456\n",
      "Epoch 137/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 260729.0680 - mse: 260729.1406 - mae: 275.7881 - val_loss: 296012.6373 - val_mse: 296012.5938 - val_mae: 287.1650\n",
      "Epoch 138/300\n",
      "43683/43683 [==============================] - 1s 26us/step - loss: 254883.2201 - mse: 254883.0469 - mae: 273.3513 - val_loss: 326753.9614 - val_mse: 326754.0000 - val_mae: 292.7778\n",
      "Epoch 139/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 258555.3458 - mse: 258555.3906 - mae: 275.0963 - val_loss: 336717.3538 - val_mse: 336717.3438 - val_mae: 313.1776\n",
      "Epoch 140/300\n",
      "43683/43683 [==============================] - 1s 26us/step - loss: 256396.5203 - mse: 256396.5156 - mae: 273.3856 - val_loss: 405120.9402 - val_mse: 405120.9375 - val_mae: 329.4843\n",
      "Epoch 141/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 254813.0163 - mse: 254812.9688 - mae: 272.2725 - val_loss: 310451.7898 - val_mse: 310451.7812 - val_mae: 295.0655\n",
      "Epoch 142/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 256605.7838 - mse: 256605.7812 - mae: 274.1300 - val_loss: 320143.3900 - val_mse: 320143.4062 - val_mae: 293.0154\n",
      "Epoch 143/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 255206.0128 - mse: 255205.9688 - mae: 273.2810 - val_loss: 317453.7010 - val_mse: 317453.6875 - val_mae: 306.7397\n",
      "Epoch 144/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 256607.8044 - mse: 256607.7656 - mae: 273.4417 - val_loss: 310008.1407 - val_mse: 310008.1562 - val_mae: 297.1042\n",
      "Epoch 145/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 252196.7323 - mse: 252196.7656 - mae: 272.5515 - val_loss: 307811.6984 - val_mse: 307811.6562 - val_mae: 293.2406\n",
      "Epoch 146/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 254909.8884 - mse: 254909.7500 - mae: 272.3197 - val_loss: 299663.5022 - val_mse: 299663.5312 - val_mae: 285.9557\n",
      "Epoch 147/300\n",
      "43683/43683 [==============================] - 1s 31us/step - loss: 252646.2607 - mse: 252646.2031 - mae: 271.8866 - val_loss: 394616.5224 - val_mse: 394616.5312 - val_mae: 335.1357\n",
      "Epoch 148/300\n",
      "43683/43683 [==============================] - 1s 31us/step - loss: 255741.2856 - mse: 255741.1094 - mae: 273.4777 - val_loss: 303482.6225 - val_mse: 303482.6562 - val_mae: 291.1996\n",
      "Epoch 149/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 254581.6263 - mse: 254581.6406 - mae: 272.2417 - val_loss: 305644.2799 - val_mse: 305644.2812 - val_mae: 288.6601\n",
      "Epoch 150/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 257983.1914 - mse: 257983.3906 - mae: 274.9337 - val_loss: 329700.6514 - val_mse: 329700.6250 - val_mae: 306.2557\n",
      "Epoch 151/300\n",
      "43683/43683 [==============================] - 1s 21us/step - loss: 252840.8237 - mse: 252840.9688 - mae: 271.2344 - val_loss: 303812.0292 - val_mse: 303812.0000 - val_mae: 292.0795\n",
      "Epoch 152/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 253259.9369 - mse: 253260.0781 - mae: 272.6422 - val_loss: 306408.4416 - val_mse: 306408.4375 - val_mae: 298.0029\n",
      "Epoch 153/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 248721.2391 - mse: 248721.2656 - mae: 268.7751 - val_loss: 301603.2181 - val_mse: 301603.3125 - val_mae: 287.7414\n",
      "Epoch 154/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 255113.5182 - mse: 255113.5312 - mae: 273.3937 - val_loss: 300594.9479 - val_mse: 300594.8438 - val_mae: 290.7595\n",
      "Epoch 155/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 250664.7339 - mse: 250665.0156 - mae: 270.9468 - val_loss: 308030.5002 - val_mse: 308030.4375 - val_mae: 299.8636\n",
      "Epoch 156/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 251475.1988 - mse: 251475.3438 - mae: 269.8551 - val_loss: 345722.5876 - val_mse: 345722.5312 - val_mae: 318.4887\n",
      "Epoch 157/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 253451.0383 - mse: 253451.0781 - mae: 270.6457 - val_loss: 320729.8662 - val_mse: 320729.8125 - val_mae: 301.1846\n",
      "Epoch 158/300\n",
      "43683/43683 [==============================] - 1s 21us/step - loss: 251235.2447 - mse: 251235.1562 - mae: 271.6956 - val_loss: 320650.5691 - val_mse: 320650.5625 - val_mae: 303.9059\n",
      "Epoch 159/300\n",
      "43683/43683 [==============================] - 1s 21us/step - loss: 254525.8532 - mse: 254525.7031 - mae: 272.2840 - val_loss: 370417.5025 - val_mse: 370417.5000 - val_mae: 319.2662\n",
      "Epoch 160/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 254335.6454 - mse: 254335.6406 - mae: 272.6345 - val_loss: 311225.2445 - val_mse: 311225.2500 - val_mae: 285.4181\n",
      "Epoch 161/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 248455.7195 - mse: 248455.7656 - mae: 268.7730 - val_loss: 300407.1810 - val_mse: 300407.2188 - val_mae: 288.3472\n",
      "Epoch 162/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 251221.7654 - mse: 251221.7812 - mae: 270.6060 - val_loss: 316778.6068 - val_mse: 316778.5938 - val_mae: 302.0399\n",
      "Epoch 163/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 250948.2780 - mse: 250948.2188 - mae: 271.0794 - val_loss: 319278.8672 - val_mse: 319278.8438 - val_mae: 289.8905\n",
      "Epoch 164/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 251605.7682 - mse: 251605.6094 - mae: 269.9060 - val_loss: 322229.2313 - val_mse: 322229.1875 - val_mae: 295.9096\n",
      "Epoch 165/300\n",
      "43683/43683 [==============================] - 1s 26us/step - loss: 253644.4347 - mse: 253644.5156 - mae: 272.1126 - val_loss: 297070.1666 - val_mse: 297070.1875 - val_mae: 284.3691\n",
      "Epoch 166/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 246514.8282 - mse: 246514.9062 - mae: 268.4432 - val_loss: 319672.5132 - val_mse: 319672.5625 - val_mae: 289.4091\n",
      "Epoch 167/300\n",
      "43683/43683 [==============================] - 1s 21us/step - loss: 247847.9313 - mse: 247847.9219 - mae: 270.0724 - val_loss: 309808.4200 - val_mse: 309808.3750 - val_mae: 293.5742\n",
      "Epoch 168/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 250828.1726 - mse: 250828.1250 - mae: 271.4505 - val_loss: 307294.5653 - val_mse: 307294.6250 - val_mae: 292.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 251112.5465 - mse: 251112.5625 - mae: 270.7813 - val_loss: 317203.1109 - val_mse: 317203.1562 - val_mae: 290.3416\n",
      "Epoch 170/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 248232.2100 - mse: 248232.0781 - mae: 269.4083 - val_loss: 309842.1648 - val_mse: 309842.2188 - val_mae: 295.8124\n",
      "Epoch 171/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 249007.3590 - mse: 249007.2500 - mae: 268.5227 - val_loss: 307618.6899 - val_mse: 307618.7500 - val_mae: 291.2469\n",
      "Epoch 172/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 257253.8784 - mse: 257253.7344 - mae: 275.3708 - val_loss: 309892.2889 - val_mse: 309892.2812 - val_mae: 292.3600\n",
      "Epoch 173/300\n",
      "43683/43683 [==============================] - 1s 22us/step - loss: 250345.8265 - mse: 250345.9531 - mae: 269.5359 - val_loss: 302745.6324 - val_mse: 302745.5938 - val_mae: 291.6599\n",
      "Epoch 174/300\n",
      "43683/43683 [==============================] - 1s 21us/step - loss: 247874.6407 - mse: 247874.7656 - mae: 269.0338 - val_loss: 313957.9621 - val_mse: 313957.9688 - val_mae: 298.1862\n",
      "Epoch 175/300\n",
      "43683/43683 [==============================] - 1s 23us/step - loss: 245986.5412 - mse: 245986.5000 - mae: 267.9955 - val_loss: 346097.0854 - val_mse: 346097.1250 - val_mae: 298.1289\n",
      "Epoch 176/300\n",
      "43683/43683 [==============================] - 1s 21us/step - loss: 248456.1948 - mse: 248456.2031 - mae: 269.3174 - val_loss: 303536.6340 - val_mse: 303536.5312 - val_mae: 289.4405\n",
      "Epoch 177/300\n",
      "43683/43683 [==============================] - 1s 21us/step - loss: 246369.0496 - mse: 246369.0156 - mae: 267.6820 - val_loss: 313094.3451 - val_mse: 313094.3125 - val_mae: 284.9302\n",
      "Epoch 178/300\n",
      "43683/43683 [==============================] - 1s 21us/step - loss: 247136.9844 - mse: 247136.9844 - mae: 268.7485 - val_loss: 337279.0539 - val_mse: 337279.0312 - val_mae: 324.1644\n",
      "Epoch 179/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 246356.6536 - mse: 246356.7344 - mae: 269.0647 - val_loss: 326940.1740 - val_mse: 326940.1250 - val_mae: 304.3377\n",
      "Epoch 180/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 246370.2581 - mse: 246370.1406 - mae: 268.1941 - val_loss: 405537.6657 - val_mse: 405537.7188 - val_mae: 343.5464\n",
      "Epoch 181/300\n",
      "43683/43683 [==============================] - 2s 36us/step - loss: 253025.2023 - mse: 253025.2344 - mae: 272.4787 - val_loss: 342269.7344 - val_mse: 342269.7812 - val_mae: 315.5700\n",
      "Epoch 182/300\n",
      "43683/43683 [==============================] - 1s 30us/step - loss: 247989.6413 - mse: 247989.7031 - mae: 267.5409 - val_loss: 307409.3231 - val_mse: 307409.3750 - val_mae: 292.7521\n",
      "Epoch 183/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 243969.3442 - mse: 243969.0625 - mae: 266.5375 - val_loss: 304437.0497 - val_mse: 304437.0312 - val_mae: 292.3315\n",
      "Epoch 184/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 244749.7455 - mse: 244749.8125 - mae: 268.2072 - val_loss: 300599.4318 - val_mse: 300599.5312 - val_mae: 287.2083\n",
      "Epoch 185/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 249360.2811 - mse: 249360.3281 - mae: 271.0447 - val_loss: 316995.3507 - val_mse: 316995.4375 - val_mae: 307.8862\n",
      "Epoch 186/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 244750.8039 - mse: 244750.8438 - mae: 266.2702 - val_loss: 312624.9049 - val_mse: 312624.8750 - val_mae: 302.2087\n",
      "Epoch 187/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 245907.1685 - mse: 245907.0781 - mae: 270.2602 - val_loss: 300195.2047 - val_mse: 300195.1875 - val_mae: 291.4229\n",
      "Epoch 188/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 246290.0914 - mse: 246290.1094 - mae: 269.4161 - val_loss: 323466.1702 - val_mse: 323466.0938 - val_mae: 292.5381\n",
      "Epoch 189/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 245489.3052 - mse: 245489.3594 - mae: 268.2570 - val_loss: 319378.3822 - val_mse: 319378.3750 - val_mae: 291.2203\n",
      "Epoch 190/300\n",
      "43683/43683 [==============================] - 1s 24us/step - loss: 240717.4753 - mse: 240717.5469 - mae: 265.4500 - val_loss: 298414.2658 - val_mse: 298414.2812 - val_mae: 286.6893\n",
      "Epoch 191/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 246210.2907 - mse: 246210.3125 - mae: 268.5905 - val_loss: 305450.6807 - val_mse: 305450.6250 - val_mae: 294.7041\n",
      "Epoch 192/300\n",
      "43683/43683 [==============================] - 1s 30us/step - loss: 244873.7423 - mse: 244873.8125 - mae: 267.1975 - val_loss: 301631.8872 - val_mse: 301631.9062 - val_mae: 290.0466\n",
      "Epoch 193/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 242212.6643 - mse: 242212.5781 - mae: 265.5771 - val_loss: 313249.4425 - val_mse: 313249.4375 - val_mae: 295.4699\n",
      "Epoch 194/300\n",
      "43683/43683 [==============================] - 1s 26us/step - loss: 243448.2788 - mse: 243448.4062 - mae: 267.2162 - val_loss: 356696.9919 - val_mse: 356697.0000 - val_mae: 322.6242\n",
      "Epoch 195/300\n",
      "43683/43683 [==============================] - 1s 26us/step - loss: 244507.1418 - mse: 244507.1094 - mae: 268.5392 - val_loss: 306922.6486 - val_mse: 306922.6562 - val_mae: 285.4905\n",
      "Epoch 196/300\n",
      "43683/43683 [==============================] - 1s 26us/step - loss: 243350.7612 - mse: 243350.7812 - mae: 268.3823 - val_loss: 331614.5587 - val_mse: 331614.5938 - val_mae: 308.4216\n",
      "Epoch 197/300\n",
      "43683/43683 [==============================] - 1s 25us/step - loss: 244819.1875 - mse: 244819.2344 - mae: 267.7898 - val_loss: 299621.4049 - val_mse: 299621.4688 - val_mae: 287.8683\n",
      "Epoch 198/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 240821.6354 - mse: 240821.6562 - mae: 264.9038 - val_loss: 310847.7912 - val_mse: 310847.7500 - val_mae: 291.7814\n",
      "Epoch 199/300\n",
      "43683/43683 [==============================] - 1s 30us/step - loss: 243866.4781 - mse: 243866.2656 - mae: 266.9753 - val_loss: 304662.3227 - val_mse: 304662.3125 - val_mae: 289.5500\n",
      "Epoch 200/300\n",
      "43683/43683 [==============================] - 2s 45us/step - loss: 240862.6527 - mse: 240862.5469 - mae: 264.4292 - val_loss: 302386.1511 - val_mse: 302386.2500 - val_mae: 289.0694\n",
      "Epoch 201/300\n",
      "43683/43683 [==============================] - 2s 40us/step - loss: 244205.0814 - mse: 244205.1719 - mae: 268.1824 - val_loss: 304709.6453 - val_mse: 304709.6250 - val_mae: 290.8288\n",
      "Epoch 202/300\n",
      "43683/43683 [==============================] - 1s 34us/step - loss: 242893.2365 - mse: 242893.2969 - mae: 266.6398 - val_loss: 321962.6960 - val_mse: 321962.7188 - val_mae: 300.7642\n",
      "Epoch 203/300\n",
      "43683/43683 [==============================] - 1s 34us/step - loss: 239835.9448 - mse: 239835.8594 - mae: 264.0528 - val_loss: 313515.6113 - val_mse: 313515.6875 - val_mae: 297.7866\n",
      "Epoch 204/300\n",
      "43683/43683 [==============================] - 2s 35us/step - loss: 244056.4883 - mse: 244056.2812 - mae: 267.8957 - val_loss: 318128.1215 - val_mse: 318128.1562 - val_mae: 301.4567\n",
      "Epoch 205/300\n",
      "43683/43683 [==============================] - 1s 33us/step - loss: 240368.4505 - mse: 240368.5625 - mae: 266.6449 - val_loss: 302879.3521 - val_mse: 302879.3438 - val_mae: 297.6199\n",
      "Epoch 206/300\n",
      "43683/43683 [==============================] - 2s 35us/step - loss: 242078.5210 - mse: 242078.4688 - mae: 265.9164 - val_loss: 316272.0759 - val_mse: 316272.0312 - val_mae: 299.7141\n",
      "Epoch 207/300\n",
      "43683/43683 [==============================] - 2s 36us/step - loss: 242700.9370 - mse: 242701.0312 - mae: 266.4838 - val_loss: 326396.0724 - val_mse: 326396.0625 - val_mae: 304.4688\n",
      "Epoch 208/300\n",
      "43683/43683 [==============================] - 2s 36us/step - loss: 238961.2775 - mse: 238961.1562 - mae: 264.9659 - val_loss: 304016.5953 - val_mse: 304016.5938 - val_mae: 294.8853\n",
      "Epoch 209/300\n",
      "43683/43683 [==============================] - 1s 33us/step - loss: 238607.7243 - mse: 238607.7812 - mae: 264.5266 - val_loss: 314236.5256 - val_mse: 314236.4688 - val_mae: 290.0946\n",
      "Epoch 210/300\n",
      "43683/43683 [==============================] - 1s 33us/step - loss: 239453.7605 - mse: 239453.7188 - mae: 266.0219 - val_loss: 318645.0669 - val_mse: 318645.0312 - val_mae: 304.5804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/300\n",
      "43683/43683 [==============================] - 1s 31us/step - loss: 236720.7612 - mse: 236720.6094 - mae: 262.3046 - val_loss: 318278.1550 - val_mse: 318278.1875 - val_mae: 295.3968\n",
      "Epoch 212/300\n",
      "43683/43683 [==============================] - 1s 30us/step - loss: 242441.5851 - mse: 242441.6719 - mae: 267.0202 - val_loss: 311546.8406 - val_mse: 311546.7812 - val_mae: 290.4359\n",
      "Epoch 213/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 236055.5589 - mse: 236055.4062 - mae: 263.0277 - val_loss: 308473.3796 - val_mse: 308473.3125 - val_mae: 287.6947\n",
      "Epoch 214/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 236934.8552 - mse: 236934.9062 - mae: 263.1708 - val_loss: 299303.4062 - val_mse: 299303.4688 - val_mae: 286.1061\n",
      "Epoch 215/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 237231.3330 - mse: 237231.2656 - mae: 265.1322 - val_loss: 300960.5573 - val_mse: 300960.5000 - val_mae: 284.4994\n",
      "Epoch 216/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 242751.2969 - mse: 242751.2500 - mae: 266.2033 - val_loss: 302713.5586 - val_mse: 302713.4688 - val_mae: 285.2706\n",
      "Epoch 217/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 237564.2645 - mse: 237564.2969 - mae: 265.0935 - val_loss: 312554.1202 - val_mse: 312554.1250 - val_mae: 294.9397\n",
      "Epoch 218/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 234883.8029 - mse: 234883.7188 - mae: 262.0462 - val_loss: 323556.5182 - val_mse: 323556.5312 - val_mae: 302.7719\n",
      "Epoch 219/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 241580.2762 - mse: 241580.1250 - mae: 265.9547 - val_loss: 300380.0551 - val_mse: 300380.0312 - val_mae: 287.9963\n",
      "Epoch 220/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 241001.2029 - mse: 241001.2812 - mae: 264.9016 - val_loss: 311133.0044 - val_mse: 311133.0312 - val_mae: 293.5154\n",
      "Epoch 221/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 235303.0162 - mse: 235302.8906 - mae: 261.9813 - val_loss: 311948.2833 - val_mse: 311948.3438 - val_mae: 291.8230\n",
      "Epoch 222/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 235740.6690 - mse: 235740.5312 - mae: 262.9352 - val_loss: 322488.4654 - val_mse: 322488.5000 - val_mae: 296.5143\n",
      "Epoch 223/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 235942.5390 - mse: 235942.7188 - mae: 263.2539 - val_loss: 307021.9858 - val_mse: 307022.0000 - val_mae: 289.9249\n",
      "Epoch 224/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 238983.5101 - mse: 238983.5156 - mae: 265.6814 - val_loss: 318386.7506 - val_mse: 318386.7500 - val_mae: 290.1063\n",
      "Epoch 225/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 237159.3604 - mse: 237159.4062 - mae: 263.6954 - val_loss: 336273.8507 - val_mse: 336273.8750 - val_mae: 312.2180\n",
      "Epoch 226/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 240913.9406 - mse: 240913.8438 - mae: 265.4120 - val_loss: 311950.4875 - val_mse: 311950.5312 - val_mae: 292.3072\n",
      "Epoch 227/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 233330.1089 - mse: 233330.1562 - mae: 261.3246 - val_loss: 319666.8113 - val_mse: 319666.7500 - val_mae: 293.9720\n",
      "Epoch 228/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 237503.4049 - mse: 237503.3750 - mae: 265.1284 - val_loss: 306393.8326 - val_mse: 306393.8438 - val_mae: 290.4258\n",
      "Epoch 229/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 234154.1409 - mse: 234154.1250 - mae: 262.8722 - val_loss: 306566.9797 - val_mse: 306566.9375 - val_mae: 291.3896\n",
      "Epoch 230/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 236286.8588 - mse: 236286.8906 - mae: 264.0231 - val_loss: 307291.9051 - val_mse: 307291.9688 - val_mae: 287.7572\n",
      "Epoch 231/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 233473.6600 - mse: 233473.7344 - mae: 260.7533 - val_loss: 325540.7807 - val_mse: 325540.6875 - val_mae: 291.9243\n",
      "Epoch 232/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 235467.7048 - mse: 235467.7500 - mae: 262.2390 - val_loss: 327803.2111 - val_mse: 327803.1875 - val_mae: 310.4732\n",
      "Epoch 233/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 233183.7319 - mse: 233183.7188 - mae: 261.7302 - val_loss: 341619.7233 - val_mse: 341619.7188 - val_mae: 315.6071\n",
      "Epoch 234/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 235344.6693 - mse: 235344.6562 - mae: 264.7474 - val_loss: 353258.6581 - val_mse: 353258.6250 - val_mae: 295.5620\n",
      "Epoch 235/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 231811.0846 - mse: 231811.2969 - mae: 260.4119 - val_loss: 304389.6973 - val_mse: 304389.7188 - val_mae: 294.4604\n",
      "Epoch 236/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 232333.9878 - mse: 232334.0469 - mae: 261.5238 - val_loss: 333029.7549 - val_mse: 333029.7500 - val_mae: 295.5566\n",
      "Epoch 237/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 236529.5816 - mse: 236529.7656 - mae: 263.3025 - val_loss: 324243.0648 - val_mse: 324243.0938 - val_mae: 303.6595\n",
      "Epoch 238/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 233770.8760 - mse: 233770.7344 - mae: 262.2407 - val_loss: 311332.1227 - val_mse: 311332.1875 - val_mae: 305.1677\n",
      "Epoch 239/300\n",
      "43683/43683 [==============================] - 1s 28us/step - loss: 232680.7740 - mse: 232680.5938 - mae: 261.2521 - val_loss: 320297.9903 - val_mse: 320297.9688 - val_mae: 294.9456\n",
      "Epoch 240/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 231555.8044 - mse: 231555.7656 - mae: 261.6978 - val_loss: 317585.5013 - val_mse: 317585.5000 - val_mae: 289.0314\n",
      "Epoch 241/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 233333.8335 - mse: 233334.1094 - mae: 262.2162 - val_loss: 317783.1295 - val_mse: 317783.2188 - val_mae: 296.4365\n",
      "Epoch 242/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 234530.6657 - mse: 234530.7656 - mae: 261.9599 - val_loss: 358674.3963 - val_mse: 358674.4062 - val_mae: 327.3955\n",
      "Epoch 243/300\n",
      "43683/43683 [==============================] - 1s 27us/step - loss: 233525.9695 - mse: 233526.0625 - mae: 263.1369 - val_loss: 318075.9067 - val_mse: 318075.8750 - val_mae: 298.6364\n",
      "Epoch 244/300\n",
      "43683/43683 [==============================] - 1s 29us/step - loss: 229529.4313 - mse: 229529.5469 - mae: 258.8604 - val_loss: 314447.1957 - val_mse: 314447.2188 - val_mae: 297.3106\n",
      "Epoch 245/300\n",
      "43683/43683 [==============================] - 1s 29us/step - loss: 231423.3738 - mse: 231423.5312 - mae: 262.4770 - val_loss: 309338.0673 - val_mse: 309338.0625 - val_mae: 290.0151\n",
      "Epoch 246/300\n",
      "43683/43683 [==============================] - 1s 32us/step - loss: 231037.5179 - mse: 231037.3750 - mae: 260.4218 - val_loss: 332081.4084 - val_mse: 332081.4062 - val_mae: 306.2689\n",
      "Epoch 247/300\n",
      "43683/43683 [==============================] - 1s 34us/step - loss: 231795.6677 - mse: 231795.6406 - mae: 261.3861 - val_loss: 314275.8381 - val_mse: 314275.8125 - val_mae: 308.3525\n",
      "Epoch 248/300\n",
      "43683/43683 [==============================] - 1s 34us/step - loss: 229428.0708 - mse: 229428.0000 - mae: 260.5728 - val_loss: 314887.9745 - val_mse: 314887.9375 - val_mae: 287.1780\n",
      "Epoch 249/300\n",
      "43683/43683 [==============================] - 2s 34us/step - loss: 231599.2602 - mse: 231599.3125 - mae: 262.0602 - val_loss: 313524.8408 - val_mse: 313524.8125 - val_mae: 293.2822\n",
      "Epoch 250/300\n",
      "43683/43683 [==============================] - 2s 40us/step - loss: 230522.0979 - mse: 230522.1719 - mae: 260.6064 - val_loss: 309723.1114 - val_mse: 309723.0312 - val_mae: 286.7708\n",
      "Epoch 251/300\n",
      "43683/43683 [==============================] - 2s 43us/step - loss: 229201.3695 - mse: 229201.3438 - mae: 258.8055 - val_loss: 335007.3653 - val_mse: 335007.3125 - val_mae: 308.2768\n",
      "Epoch 252/300\n",
      "43683/43683 [==============================] - 2s 41us/step - loss: 229246.8372 - mse: 229246.7656 - mae: 259.7215 - val_loss: 387624.8974 - val_mse: 387624.8750 - val_mae: 356.2321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/300\n",
      "43683/43683 [==============================] - 2s 39us/step - loss: 232629.7857 - mse: 232629.7969 - mae: 263.1397 - val_loss: 309203.5596 - val_mse: 309203.5625 - val_mae: 288.1516\n",
      "Epoch 254/300\n",
      "43683/43683 [==============================] - 2s 41us/step - loss: 228025.3956 - mse: 228025.2969 - mae: 258.2357 - val_loss: 308101.8359 - val_mse: 308101.8125 - val_mae: 293.1370\n",
      "Epoch 255/300\n",
      "43683/43683 [==============================] - 2s 42us/step - loss: 228752.1442 - mse: 228752.1250 - mae: 259.7159 - val_loss: 312935.5288 - val_mse: 312935.5625 - val_mae: 298.5047\n",
      "Epoch 256/300\n",
      "43683/43683 [==============================] - 2s 41us/step - loss: 226521.2992 - mse: 226521.2344 - mae: 259.3836 - val_loss: 318219.2843 - val_mse: 318219.3438 - val_mae: 294.3840\n",
      "Epoch 257/300\n",
      "43683/43683 [==============================] - 2s 44us/step - loss: 229944.0214 - mse: 229943.8750 - mae: 260.6496 - val_loss: 308512.8591 - val_mse: 308512.7812 - val_mae: 289.7315\n",
      "Epoch 258/300\n",
      "43683/43683 [==============================] - 2s 42us/step - loss: 226450.9359 - mse: 226451.0312 - mae: 258.0338 - val_loss: 310082.2394 - val_mse: 310082.2812 - val_mae: 287.8613\n",
      "Epoch 259/300\n",
      "43683/43683 [==============================] - 2s 45us/step - loss: 229480.8814 - mse: 229480.9219 - mae: 261.7196 - val_loss: 309414.6967 - val_mse: 309414.6875 - val_mae: 297.5072\n",
      "Epoch 260/300\n",
      "43683/43683 [==============================] - 2s 45us/step - loss: 227781.2441 - mse: 227781.2500 - mae: 258.7200 - val_loss: 332702.5043 - val_mse: 332702.5312 - val_mae: 296.4763\n",
      "Epoch 261/300\n",
      "43683/43683 [==============================] - 2s 41us/step - loss: 226264.8297 - mse: 226264.9062 - mae: 258.2465 - val_loss: 307036.1731 - val_mse: 307036.2500 - val_mae: 287.6579\n",
      "Epoch 262/300\n",
      "43683/43683 [==============================] - 2s 37us/step - loss: 228240.4806 - mse: 228240.5781 - mae: 259.5157 - val_loss: 338631.0635 - val_mse: 338631.0938 - val_mae: 309.2271\n",
      "Epoch 263/300\n",
      "43683/43683 [==============================] - 2s 39us/step - loss: 229038.6291 - mse: 229038.6562 - mae: 259.6560 - val_loss: 321495.2309 - val_mse: 321495.1562 - val_mae: 307.6927\n",
      "Epoch 264/300\n",
      "43683/43683 [==============================] - 2s 42us/step - loss: 230323.8865 - mse: 230323.9844 - mae: 261.3656 - val_loss: 309574.5899 - val_mse: 309574.5000 - val_mae: 289.1224\n",
      "Epoch 265/300\n",
      "43683/43683 [==============================] - 2s 39us/step - loss: 225001.1398 - mse: 225001.0469 - mae: 258.0251 - val_loss: 369505.5128 - val_mse: 369505.5938 - val_mae: 329.3251\n",
      "Epoch 266/300\n",
      "43683/43683 [==============================] - 2s 35us/step - loss: 230666.0969 - mse: 230665.9688 - mae: 261.7633 - val_loss: 334668.8602 - val_mse: 334668.8750 - val_mae: 303.6085\n",
      "Epoch 267/300\n",
      "43683/43683 [==============================] - 1s 33us/step - loss: 225897.8173 - mse: 225897.7500 - mae: 258.8944 - val_loss: 321374.2200 - val_mse: 321374.3125 - val_mae: 300.8568\n",
      "Epoch 268/300\n",
      "43683/43683 [==============================] - 2s 38us/step - loss: 226779.3227 - mse: 226779.2344 - mae: 258.5413 - val_loss: 314192.6885 - val_mse: 314192.6875 - val_mae: 295.8882\n",
      "Epoch 269/300\n",
      "43683/43683 [==============================] - 2s 40us/step - loss: 228865.8243 - mse: 228865.6719 - mae: 260.7435 - val_loss: 317355.6291 - val_mse: 317355.6562 - val_mae: 296.4719\n",
      "Epoch 270/300\n",
      "43683/43683 [==============================] - 1s 33us/step - loss: 224493.5789 - mse: 224493.7031 - mae: 258.1157 - val_loss: 306077.7505 - val_mse: 306077.8125 - val_mae: 289.3695\n",
      "Epoch 271/300\n",
      "43683/43683 [==============================] - 1s 33us/step - loss: 226691.1717 - mse: 226691.1094 - mae: 258.1564 - val_loss: 332695.4401 - val_mse: 332695.4375 - val_mae: 293.3090\n",
      "Epoch 272/300\n",
      "43683/43683 [==============================] - 1s 32us/step - loss: 224871.2262 - mse: 224871.3906 - mae: 257.5186 - val_loss: 310458.3127 - val_mse: 310458.3125 - val_mae: 291.0046\n",
      "Epoch 273/300\n",
      "43683/43683 [==============================] - 2s 40us/step - loss: 225170.9564 - mse: 225171.0000 - mae: 259.3068 - val_loss: 322052.7597 - val_mse: 322052.8125 - val_mae: 297.3538\n",
      "Epoch 274/300\n",
      "43683/43683 [==============================] - 2s 38us/step - loss: 222799.0735 - mse: 222798.9375 - mae: 256.2435 - val_loss: 325652.7817 - val_mse: 325652.7812 - val_mae: 300.6502\n",
      "Epoch 275/300\n",
      "43683/43683 [==============================] - 1s 33us/step - loss: 225274.1841 - mse: 225274.1094 - mae: 257.4527 - val_loss: 334484.8220 - val_mse: 334484.8438 - val_mae: 297.8802\n",
      "Epoch 276/300\n",
      "43683/43683 [==============================] - 1s 30us/step - loss: 223969.8060 - mse: 223969.8906 - mae: 258.4083 - val_loss: 322908.8671 - val_mse: 322908.9062 - val_mae: 300.8177\n",
      "Epoch 277/300\n",
      "43683/43683 [==============================] - 1s 31us/step - loss: 225677.6804 - mse: 225677.7812 - mae: 256.9983 - val_loss: 329212.3880 - val_mse: 329212.3750 - val_mae: 299.7456\n",
      "Epoch 278/300\n",
      "43683/43683 [==============================] - 1s 34us/step - loss: 229267.9473 - mse: 229267.8906 - mae: 260.4952 - val_loss: 323824.0376 - val_mse: 323824.0938 - val_mae: 299.2484\n",
      "Epoch 279/300\n",
      "43683/43683 [==============================] - 2s 35us/step - loss: 218422.3404 - mse: 218422.2969 - mae: 254.8637 - val_loss: 310070.6477 - val_mse: 310070.5938 - val_mae: 290.5801\n",
      "Epoch 280/300\n",
      "43683/43683 [==============================] - 2s 35us/step - loss: 225152.8655 - mse: 225153.0469 - mae: 258.5899 - val_loss: 319713.5378 - val_mse: 319713.5625 - val_mae: 293.5276\n",
      "Epoch 281/300\n",
      "43683/43683 [==============================] - 2s 35us/step - loss: 224529.7208 - mse: 224529.7969 - mae: 257.5576 - val_loss: 318202.3052 - val_mse: 318202.2812 - val_mae: 299.5035\n",
      "Epoch 282/300\n",
      "43683/43683 [==============================] - 1s 34us/step - loss: 224245.4403 - mse: 224245.4688 - mae: 257.9237 - val_loss: 319593.1678 - val_mse: 319593.2188 - val_mae: 293.7586\n",
      "Epoch 283/300\n",
      "43683/43683 [==============================] - 1s 33us/step - loss: 222337.0585 - mse: 222336.9688 - mae: 256.4297 - val_loss: 319223.3809 - val_mse: 319223.4062 - val_mae: 295.2503\n",
      "Epoch 284/300\n",
      "43683/43683 [==============================] - 2s 36us/step - loss: 221637.9209 - mse: 221637.9531 - mae: 255.6393 - val_loss: 332995.8889 - val_mse: 332995.9688 - val_mae: 307.9755\n",
      "Epoch 285/300\n",
      "43683/43683 [==============================] - 2s 37us/step - loss: 223195.6772 - mse: 223195.5938 - mae: 256.5394 - val_loss: 333256.6537 - val_mse: 333256.6875 - val_mae: 295.7037\n",
      "Epoch 286/300\n",
      "43683/43683 [==============================] - 2s 38us/step - loss: 221410.8401 - mse: 221410.8281 - mae: 257.7133 - val_loss: 324146.8202 - val_mse: 324146.7500 - val_mae: 299.1289\n",
      "Epoch 287/300\n",
      "43683/43683 [==============================] - 2s 39us/step - loss: 224482.3348 - mse: 224482.3750 - mae: 257.9719 - val_loss: 318430.6506 - val_mse: 318430.6562 - val_mae: 292.3298\n",
      "Epoch 288/300\n",
      "43683/43683 [==============================] - 2s 37us/step - loss: 220771.5925 - mse: 220771.6406 - mae: 255.2905 - val_loss: 355612.6587 - val_mse: 355612.6562 - val_mae: 301.9673\n",
      "Epoch 289/300\n",
      "43683/43683 [==============================] - 2s 39us/step - loss: 222387.3862 - mse: 222387.4531 - mae: 256.2555 - val_loss: 328173.2819 - val_mse: 328173.3125 - val_mae: 297.0490\n",
      "Epoch 290/300\n",
      "43683/43683 [==============================] - 2s 41us/step - loss: 221855.3030 - mse: 221855.2812 - mae: 258.1356 - val_loss: 304505.5484 - val_mse: 304505.5312 - val_mae: 293.3497\n",
      "Epoch 291/300\n",
      "43683/43683 [==============================] - 2s 42us/step - loss: 221128.6751 - mse: 221128.6562 - mae: 256.8065 - val_loss: 317864.4024 - val_mse: 317864.4375 - val_mae: 292.3666\n",
      "Epoch 292/300\n",
      "43683/43683 [==============================] - 2s 42us/step - loss: 220529.9942 - mse: 220529.8438 - mae: 255.2591 - val_loss: 318476.0984 - val_mse: 318476.0625 - val_mae: 293.7855\n",
      "Epoch 293/300\n",
      "43683/43683 [==============================] - 2s 42us/step - loss: 221477.0820 - mse: 221477.1562 - mae: 256.8320 - val_loss: 331550.1014 - val_mse: 331550.0625 - val_mae: 300.9704\n",
      "Epoch 294/300\n",
      "43683/43683 [==============================] - 2s 41us/step - loss: 219028.0669 - mse: 219028.0781 - mae: 253.6654 - val_loss: 322566.7469 - val_mse: 322566.7188 - val_mae: 288.5352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/300\n",
      "43683/43683 [==============================] - 2s 42us/step - loss: 222610.7383 - mse: 222610.6562 - mae: 258.1408 - val_loss: 310414.6229 - val_mse: 310414.6562 - val_mae: 289.1908\n",
      "Epoch 296/300\n",
      "43683/43683 [==============================] - 2s 44us/step - loss: 221285.6813 - mse: 221285.7344 - mae: 255.9925 - val_loss: 319430.7825 - val_mse: 319430.7812 - val_mae: 291.5093\n",
      "Epoch 297/300\n",
      "43683/43683 [==============================] - 2s 43us/step - loss: 218200.9968 - mse: 218201.1250 - mae: 254.1126 - val_loss: 320209.2912 - val_mse: 320209.2500 - val_mae: 303.5133\n",
      "Epoch 298/300\n",
      "43683/43683 [==============================] - 2s 44us/step - loss: 217379.3926 - mse: 217379.3594 - mae: 253.2491 - val_loss: 308016.5229 - val_mse: 308016.5312 - val_mae: 289.8444\n",
      "Epoch 299/300\n",
      "43683/43683 [==============================] - 2s 42us/step - loss: 222547.6608 - mse: 222547.5781 - mae: 256.5767 - val_loss: 340908.1940 - val_mse: 340908.1562 - val_mae: 315.7738\n",
      "Epoch 300/300\n",
      "43683/43683 [==============================] - 2s 40us/step - loss: 221042.8976 - mse: 221042.7812 - mae: 256.7215 - val_loss: 313107.5273 - val_mse: 313107.5000 - val_mae: 293.5104\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 300\n",
    "history = nn_reg2.fit(X_train, y_train,\n",
    "                      epochs=n_epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      validation_split=0.1,\n",
    "                      callbacks=[early_stoping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(np.log(history.history['loss']), label='Training Loss')\n",
    "ax.plot(np.log(history.history['val_loss']), label='Validation Loss')\n",
    "ax.set_title(\"log(Loss) vs. epochs\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_ylim(12,14)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg_dropout = Sequential()\n",
    "n_hidden = 64\n",
    "dropout_rate = 0.2\n",
    "\n",
    "## Dropout for input layer\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate, input_shape=(n_input,)))\n",
    "                   \n",
    "## Now adding four hidden layers + dropout for each of them\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu', input_shape=(n_input,)))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "                   \n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "nn_reg_dropout.add(Dense(units=n_hidden, activation='relu'))\n",
    "nn_reg_dropout.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "nn_reg_dropout.add(Dense(units=1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                1408      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 22,273\n",
      "Trainable params: 22,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_reg_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation\n",
    "nn_reg_dropout.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 12607723.1528 - mse: 12607723.1528 - mae: 2123.0770 - val_loss: 1398520.0000 - val_mse: 1398520.0000 - val_mae: 635.9626\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 2/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 3390143.6287 - mse: 3390143.6287 - mae: 1101.5210 - val_loss: 2013797.0000 - val_mse: 2013797.0000 - val_mae: 770.9499\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 3/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2960856.1552 - mse: 2960856.1552 - mae: 1002.7929 - val_loss: 1759849.0000 - val_mse: 1759849.0000 - val_mae: 715.1693\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 4/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2861161.5152 - mse: 2861161.5152 - mae: 978.5809 - val_loss: 1885888.1250 - val_mse: 1885888.1250 - val_mae: 755.8987\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 5/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2792549.4748 - mse: 2792549.4748 - mae: 963.2335 - val_loss: 2315325.5000 - val_mse: 2315325.5000 - val_mae: 848.0447\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 6/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2809761.8713 - mse: 2809761.8713 - mae: 960.4361 - val_loss: 2476938.7500 - val_mse: 2476938.7500 - val_mae: 899.1901\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 7/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2800353.9832 - mse: 2800353.9832 - mae: 953.4884 - val_loss: 1964804.1250 - val_mse: 1964804.1250 - val_mae: 791.0026\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 8/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2826104.0318 - mse: 2826104.0318 - mae: 958.9940 - val_loss: 1727071.1250 - val_mse: 1727071.1250 - val_mae: 746.3345\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 9/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2747251.8629 - mse: 2747251.8629 - mae: 951.5990 - val_loss: 1455331.1250 - val_mse: 1455331.1250 - val_mae: 686.5494\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 10/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2603416.0024 - mse: 2603416.0024 - mae: 928.8345 - val_loss: 1995673.2500 - val_mse: 1995673.2500 - val_mae: 821.6915\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 11/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2712453.7100 - mse: 2712453.7100 - mae: 927.9805 - val_loss: 1783381.5000 - val_mse: 1783381.5000 - val_mae: 762.8544\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 12/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2625217.6919 - mse: 2625217.6919 - mae: 926.6415 - val_loss: 2188656.2500 - val_mse: 2188656.2500 - val_mae: 829.2252\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 13/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2677208.4209 - mse: 2677208.4209 - mae: 920.0020 - val_loss: 1798731.1250 - val_mse: 1798731.1250 - val_mae: 770.1625\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 14/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2527611.0550 - mse: 2527611.0550 - mae: 896.8654 - val_loss: 1826903.5000 - val_mse: 1826903.5000 - val_mae: 767.8871\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 15/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2739647.6535 - mse: 2739647.6535 - mae: 922.6454 - val_loss: 2165482.5000 - val_mse: 2165482.5000 - val_mae: 821.7410\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 16/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2596713.8023 - mse: 2596713.8023 - mae: 902.4273 - val_loss: 1909635.3750 - val_mse: 1909635.3750 - val_mae: 793.2820\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 17/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2639573.2209 - mse: 2639573.2209 - mae: 903.3228 - val_loss: 1914471.3750 - val_mse: 1914471.3750 - val_mae: 762.7525\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 18/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2503672.9689 - mse: 2503672.9689 - mae: 885.7717 - val_loss: 2095685.0000 - val_mse: 2095685.0000 - val_mae: 869.6176\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 19/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2577359.9817 - mse: 2577359.9817 - mae: 903.4481 - val_loss: 2282243.5000 - val_mse: 2282243.5000 - val_mae: 867.8931\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 20/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2404604.7622 - mse: 2404604.7622 - mae: 876.1087 - val_loss: 1424478.8750 - val_mse: 1424478.8750 - val_mae: 653.3090\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 21/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2446038.8739 - mse: 2446038.8739 - mae: 872.0051 - val_loss: 2105995.0000 - val_mse: 2105995.0000 - val_mae: 803.7617\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 22/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2441464.7610 - mse: 2441464.7610 - mae: 875.4912 - val_loss: 2239971.0000 - val_mse: 2239971.0000 - val_mae: 863.1395\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 23/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2567826.6294 - mse: 2567826.6294 - mae: 882.2413 - val_loss: 2229055.5000 - val_mse: 2229055.5000 - val_mae: 856.6783\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2558275.9426 - mse: 2558275.9426 - mae: 883.2097 - val_loss: 1782629.0000 - val_mse: 1782629.0000 - val_mae: 792.9767\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 25/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2537802.8750 - mse: 2537802.8750 - mae: 871.9541 - val_loss: 2053851.0000 - val_mse: 2053851.0000 - val_mae: 842.5262\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 26/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2466271.2908 - mse: 2466271.2908 - mae: 865.7617 - val_loss: 3282464.2500 - val_mse: 3282464.2500 - val_mae: 1069.7770\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 27/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2520182.8317 - mse: 2520182.8317 - mae: 882.1975 - val_loss: 1832416.1250 - val_mse: 1832416.1250 - val_mae: 854.7798\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 28/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2540062.5941 - mse: 2540062.5941 - mae: 883.4115 - val_loss: 2445658.5000 - val_mse: 2445658.5000 - val_mae: 918.1509\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 29/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2385654.6038 - mse: 2385654.6038 - mae: 859.9336 - val_loss: 1735924.0000 - val_mse: 1735924.0000 - val_mae: 843.8386\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 30/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2469548.9229 - mse: 2469548.9229 - mae: 870.8504 - val_loss: 1936342.0000 - val_mse: 1936342.0000 - val_mae: 843.9517\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 31/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2396397.7171 - mse: 2396397.7171 - mae: 854.0804 - val_loss: 2256480.0000 - val_mse: 2256480.0000 - val_mae: 920.1905\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 32/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2462085.3673 - mse: 2462085.3673 - mae: 870.8860 - val_loss: 1698122.6250 - val_mse: 1698122.6250 - val_mae: 820.2524\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 33/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2439527.9719 - mse: 2439527.9719 - mae: 858.1343 - val_loss: 2060787.5000 - val_mse: 2060787.5000 - val_mae: 883.9279\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 34/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2381648.4370 - mse: 2381648.4370 - mae: 850.6057 - val_loss: 2066900.7500 - val_mse: 2066900.7500 - val_mae: 882.3849\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 35/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2503587.8423 - mse: 2503587.8423 - mae: 863.6846 - val_loss: 2403068.2500 - val_mse: 2403068.2500 - val_mae: 929.2442\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 36/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2446854.8452 - mse: 2446854.8452 - mae: 858.7509 - val_loss: 1849710.5000 - val_mse: 1849710.5000 - val_mae: 814.7678\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 37/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2411842.8187 - mse: 2411842.8187 - mae: 853.9530 - val_loss: 2380683.7500 - val_mse: 2380683.7500 - val_mae: 906.3939\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 38/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2404174.2511 - mse: 2404174.2511 - mae: 852.4305 - val_loss: 1930763.3750 - val_mse: 1930763.3750 - val_mae: 841.0126\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 39/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2451917.2588 - mse: 2451917.2588 - mae: 849.8038 - val_loss: 2218696.7500 - val_mse: 2218696.7500 - val_mae: 863.3373\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 40/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2431331.6458 - mse: 2431331.6458 - mae: 856.2065 - val_loss: 3034926.0000 - val_mse: 3034926.0000 - val_mae: 1011.7333\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 41/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2462012.1793 - mse: 2462012.1793 - mae: 853.5906 - val_loss: 2449864.2500 - val_mse: 2449864.2500 - val_mae: 935.5070\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 42/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2409440.6577 - mse: 2409440.6577 - mae: 845.2541 - val_loss: 2244444.5000 - val_mse: 2244444.5000 - val_mae: 914.6274\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 43/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2337570.3518 - mse: 2337570.3518 - mae: 840.4021 - val_loss: 2137687.5000 - val_mse: 2137687.5000 - val_mae: 893.9323\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 44/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2194496.5857 - mse: 2194496.5857 - mae: 823.8890 - val_loss: 2250317.2500 - val_mse: 2250317.2500 - val_mae: 903.2828\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 45/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2339204.6444 - mse: 2339204.6444 - mae: 831.0189 - val_loss: 2256927.2500 - val_mse: 2256927.2500 - val_mae: 917.9286\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 46/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2409916.4916 - mse: 2409916.4916 - mae: 844.8858 - val_loss: 2154818.5000 - val_mse: 2154818.5000 - val_mae: 902.8438\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2392342.3342 - mse: 2392342.3342 - mae: 846.2084 - val_loss: 1701668.8750 - val_mse: 1701668.8750 - val_mae: 816.6760\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 48/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2266654.9748 - mse: 2266654.9748 - mae: 823.4438 - val_loss: 2119271.5000 - val_mse: 2119271.5000 - val_mae: 891.1743\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 49/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2241114.8233 - mse: 2241114.8233 - mae: 828.3476 - val_loss: 2810285.2500 - val_mse: 2810285.2500 - val_mae: 1024.5798\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 50/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2304270.5386 - mse: 2304270.5386 - mae: 831.1174 - val_loss: 2541592.0000 - val_mse: 2541592.0000 - val_mae: 1005.3866\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 51/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2456643.8204 - mse: 2456643.8204 - mae: 848.4677 - val_loss: 2483188.5000 - val_mse: 2483188.5000 - val_mae: 971.1364\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 52/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2379910.4883 - mse: 2379910.4883 - mae: 842.5219 - val_loss: 1657819.8750 - val_mse: 1657819.8750 - val_mae: 818.9104\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 53/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2295044.5680 - mse: 2295044.5680 - mae: 833.0108 - val_loss: 2532409.5000 - val_mse: 2532409.5000 - val_mae: 992.9703\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 54/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2273612.0789 - mse: 2273612.0789 - mae: 826.2440 - val_loss: 2098304.7500 - val_mse: 2098304.7500 - val_mae: 878.7310\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 55/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2278870.9965 - mse: 2278870.9965 - mae: 823.1414 - val_loss: 2741143.2500 - val_mse: 2741143.2500 - val_mae: 1020.4088\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 56/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2343280.8480 - mse: 2343280.8480 - mae: 837.0925 - val_loss: 2303392.5000 - val_mse: 2303392.5000 - val_mae: 974.8950\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 57/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2400738.3070 - mse: 2400738.3070 - mae: 845.9950 - val_loss: 2959571.5000 - val_mse: 2959571.5000 - val_mae: 1050.1703\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 58/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2365497.8370 - mse: 2365497.8370 - mae: 845.7328 - val_loss: 2518769.7500 - val_mse: 2518769.7500 - val_mae: 972.8052\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 59/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2326244.9998 - mse: 2326244.9998 - mae: 832.7002 - val_loss: 2894026.7500 - val_mse: 2894026.7500 - val_mae: 1056.6692\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 60/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2363779.7261 - mse: 2363779.7261 - mae: 836.2096 - val_loss: 2245590.7500 - val_mse: 2245590.7500 - val_mae: 976.3959\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 61/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2365807.4753 - mse: 2365807.4753 - mae: 839.3848 - val_loss: 2485310.7500 - val_mse: 2485310.7500 - val_mae: 977.7714\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 62/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2317985.0243 - mse: 2317985.0243 - mae: 830.8502 - val_loss: 2341823.5000 - val_mse: 2341823.5000 - val_mae: 987.7295\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 63/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2324845.6033 - mse: 2324845.6033 - mae: 829.7710 - val_loss: 2219971.5000 - val_mse: 2219971.5000 - val_mae: 952.7689\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 64/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2194022.7041 - mse: 2194022.7041 - mae: 810.4348 - val_loss: 2958652.5000 - val_mse: 2958652.5000 - val_mae: 1064.1682\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 65/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2294776.9764 - mse: 2294776.9764 - mae: 832.2280 - val_loss: 1996041.0000 - val_mse: 1996041.0000 - val_mae: 895.0632\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 66/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2305269.0948 - mse: 2305269.0948 - mae: 826.6918 - val_loss: 2588613.7500 - val_mse: 2588613.7500 - val_mae: 1003.8663\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 67/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2204872.1106 - mse: 2204872.1106 - mae: 818.4961 - val_loss: 3105343.5000 - val_mse: 3105343.5000 - val_mae: 1073.0552\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 68/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2254890.5168 - mse: 2254890.5168 - mae: 821.4448 - val_loss: 2386388.2500 - val_mse: 2386388.2500 - val_mae: 978.1995\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 69/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2179794.6202 - mse: 2179794.6202 - mae: 817.8650 - val_loss: 2523066.5000 - val_mse: 2523066.5000 - val_mae: 981.1624\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2241146.2438 - mse: 2241146.2438 - mae: 821.2693 - val_loss: 2534526.5000 - val_mse: 2534526.5000 - val_mae: 983.3090\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 71/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2225836.6976 - mse: 2225836.6976 - mae: 813.8642 - val_loss: 2120852.0000 - val_mse: 2120852.0000 - val_mae: 922.0388\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 72/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2216428.8130 - mse: 2216428.8130 - mae: 821.5317 - val_loss: 2283019.7500 - val_mse: 2283019.7500 - val_mae: 948.0585\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 73/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2201501.2829 - mse: 2201501.2829 - mae: 812.3116 - val_loss: 1764958.7500 - val_mse: 1764958.7500 - val_mae: 867.4617\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 74/300\n",
      "683/683 [==============================] - 5s 7ms/step - loss: 2224113.9731 - mse: 2224113.9731 - mae: 819.2458 - val_loss: 1972889.6250 - val_mse: 1972889.6250 - val_mae: 900.5006\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 75/300\n",
      "683/683 [==============================] - 5s 7ms/step - loss: 2237926.5978 - mse: 2237926.5978 - mae: 815.5780 - val_loss: 2166139.7500 - val_mse: 2166139.7500 - val_mae: 936.8585\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 76/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2228368.2817 - mse: 2228368.2817 - mae: 824.2978 - val_loss: 2688323.2500 - val_mse: 2688323.2500 - val_mae: 1019.1317\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 77/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2231614.3591 - mse: 2231614.3591 - mae: 826.9664 - val_loss: 2384018.5000 - val_mse: 2384018.5000 - val_mae: 987.3593\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 78/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2294196.6553 - mse: 2294196.6553 - mae: 824.7312 - val_loss: 3138284.5000 - val_mse: 3138284.5000 - val_mae: 1078.3888\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 79/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2220792.3518 - mse: 2220792.3518 - mae: 812.2412 - val_loss: 3126138.2500 - val_mse: 3126138.2500 - val_mae: 1063.1831\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 80/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2106076.5448 - mse: 2106076.5448 - mae: 810.5336 - val_loss: 3325111.7500 - val_mse: 3325111.7500 - val_mae: 1108.2906\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 81/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2262902.4379 - mse: 2262902.4379 - mae: 819.1094 - val_loss: 2559077.7500 - val_mse: 2559077.7500 - val_mae: 1030.2272\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 82/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2254910.1009 - mse: 2254910.1009 - mae: 819.9859 - val_loss: 2369235.2500 - val_mse: 2369235.2500 - val_mae: 959.2024\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 83/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 2272254.0588 - mse: 2272254.0588 - mae: 823.0390 - val_loss: 1999037.6250 - val_mse: 1999037.6250 - val_mae: 911.9675\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 84/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2248044.8960 - mse: 2248044.8960 - mae: 817.3446 - val_loss: 2369701.2500 - val_mse: 2369701.2500 - val_mae: 973.2161\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 85/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2229740.7222 - mse: 2229740.7222 - mae: 811.8910 - val_loss: 2611950.0000 - val_mse: 2611950.0000 - val_mae: 1006.1741\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 86/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2271656.6283 - mse: 2271656.6283 - mae: 828.3183 - val_loss: 3102973.2500 - val_mse: 3102973.2500 - val_mae: 1070.1873\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 87/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2188242.2515 - mse: 2188242.2515 - mae: 810.0875 - val_loss: 2551363.7500 - val_mse: 2551363.7500 - val_mae: 974.7197\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 88/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 2222758.2061 - mse: 2222758.2061 - mae: 817.3115 - val_loss: 2803402.5000 - val_mse: 2803402.5000 - val_mae: 1026.0597\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 89/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2191623.1959 - mse: 2191623.1959 - mae: 820.4303 - val_loss: 2052319.0000 - val_mse: 2052319.0000 - val_mae: 920.1552\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 90/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2207409.1096 - mse: 2207409.1096 - mae: 819.8563 - val_loss: 2622754.7500 - val_mse: 2622754.7500 - val_mae: 989.1624\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 91/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2248835.9426 - mse: 2248835.9426 - mae: 817.8326 - val_loss: 2321834.0000 - val_mse: 2321834.0000 - val_mae: 961.3160\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 92/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2133679.2887 - mse: 2133679.2887 - mae: 810.2164 - val_loss: 2382762.7500 - val_mse: 2382762.7500 - val_mae: 987.8770\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2192362.5360 - mse: 2192362.5360 - mae: 818.7982 - val_loss: 2286356.5000 - val_mse: 2286356.5000 - val_mae: 972.8716\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 94/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2229791.8185 - mse: 2229791.8185 - mae: 814.0583 - val_loss: 2422500.7500 - val_mse: 2422500.7500 - val_mae: 981.8851\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 95/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2236292.9181 - mse: 2236292.9181 - mae: 824.3426 - val_loss: 2360621.5000 - val_mse: 2360621.5000 - val_mae: 977.1644\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 96/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2253472.6579 - mse: 2253472.6579 - mae: 817.0028 - val_loss: 2711625.7500 - val_mse: 2711625.7500 - val_mae: 1024.0050\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 97/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2120026.5693 - mse: 2120026.5693 - mae: 802.7028 - val_loss: 2377426.2500 - val_mse: 2377426.2500 - val_mae: 951.1658\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 98/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 2176663.8644 - mse: 2176663.8644 - mae: 805.3918 - val_loss: 2831407.0000 - val_mse: 2831407.0000 - val_mae: 1060.3585\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 99/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2093967.8537 - mse: 2093967.8537 - mae: 797.0777 - val_loss: 2391160.5000 - val_mse: 2391160.5000 - val_mae: 981.1113\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 100/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2167949.3374 - mse: 2167949.3374 - mae: 802.0863 - val_loss: 2600886.2500 - val_mse: 2600886.2500 - val_mae: 1000.4319\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 101/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2192375.1305 - mse: 2192375.1305 - mae: 811.5284 - val_loss: 2824146.2500 - val_mse: 2824146.2500 - val_mae: 1066.0817\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 102/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2146885.2153 - mse: 2146885.2153 - mae: 807.7618 - val_loss: 2766259.2500 - val_mse: 2766259.2500 - val_mae: 1030.6230\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 103/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2212728.7350 - mse: 2212728.7350 - mae: 805.7772 - val_loss: 2343631.2500 - val_mse: 2343631.2500 - val_mae: 968.1702\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 104/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2098164.3247 - mse: 2098164.3247 - mae: 798.6256 - val_loss: 3000030.0000 - val_mse: 3000030.0000 - val_mae: 1064.4520\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 105/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2228720.4889 - mse: 2228720.4889 - mae: 809.4648 - val_loss: 2264813.0000 - val_mse: 2264813.0000 - val_mae: 974.8300\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 106/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2270316.0821 - mse: 2270316.0821 - mae: 827.6162 - val_loss: 2555623.7500 - val_mse: 2555623.7500 - val_mae: 1013.9695\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 107/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2116489.2162 - mse: 2116489.2162 - mae: 797.4423 - val_loss: 2602751.0000 - val_mse: 2602751.0000 - val_mae: 1037.7120\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 108/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2186552.8958 - mse: 2186552.8958 - mae: 812.3602 - val_loss: 2800458.0000 - val_mse: 2800458.0000 - val_mae: 1051.2863\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 109/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2221057.2113 - mse: 2221057.2113 - mae: 822.2598 - val_loss: 2500284.0000 - val_mse: 2500284.0000 - val_mae: 990.5685\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 110/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2094266.0901 - mse: 2094266.0901 - mae: 804.1992 - val_loss: 2236325.2500 - val_mse: 2236325.2500 - val_mae: 961.4880\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 111/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2114750.6502 - mse: 2114750.6502 - mae: 798.9002 - val_loss: 3262051.7500 - val_mse: 3262051.7500 - val_mae: 1136.2183\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 112/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2198992.1168 - mse: 2198992.1168 - mae: 812.1965 - val_loss: 2577282.7500 - val_mse: 2577282.7500 - val_mae: 999.7892\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 113/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2120878.7557 - mse: 2120878.7557 - mae: 798.3327 - val_loss: 3585631.5000 - val_mse: 3585631.5000 - val_mae: 1154.9821\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 114/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2168207.0590 - mse: 2168207.0590 - mae: 808.9297 - val_loss: 2170678.5000 - val_mse: 2170678.5000 - val_mae: 949.4780\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 115/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2197627.0331 - mse: 2197627.0331 - mae: 814.5067 - val_loss: 2509501.2500 - val_mse: 2509501.2500 - val_mae: 1008.0704\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2121814.6246 - mse: 2121814.6246 - mae: 801.0970 - val_loss: 1955515.1250 - val_mse: 1955515.1250 - val_mae: 904.8039\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 117/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2250567.2734 - mse: 2250567.2734 - mae: 821.3919 - val_loss: 1836016.7500 - val_mse: 1836016.7500 - val_mae: 873.3304\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 118/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2267003.6488 - mse: 2267003.6488 - mae: 819.5844 - val_loss: 2630993.0000 - val_mse: 2630993.0000 - val_mae: 1040.9923\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 119/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2197420.8534 - mse: 2197420.8534 - mae: 811.9054 - val_loss: 2215674.5000 - val_mse: 2215674.5000 - val_mae: 965.3329\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 120/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2169296.1195 - mse: 2169296.1195 - mae: 800.5786 - val_loss: 2728940.2500 - val_mse: 2728940.2500 - val_mae: 1069.2445\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 121/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2059940.1804 - mse: 2059940.1804 - mae: 797.5712 - val_loss: 2537682.7500 - val_mse: 2537682.7500 - val_mae: 1005.3619\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 122/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2165456.9804 - mse: 2165456.9804 - mae: 807.9909 - val_loss: 2927026.0000 - val_mse: 2927026.0000 - val_mae: 1079.0109\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 123/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2229039.8017 - mse: 2229039.8017 - mae: 812.5887 - val_loss: 2961288.2500 - val_mse: 2961288.2500 - val_mae: 1072.2996\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 124/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2129061.9211 - mse: 2129061.9211 - mae: 804.8857 - val_loss: 2703627.5000 - val_mse: 2703627.5000 - val_mae: 1044.2488\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 125/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2156002.2529 - mse: 2156002.2529 - mae: 807.5189 - val_loss: 2274819.5000 - val_mse: 2274819.5000 - val_mae: 958.1212\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 126/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2159689.5484 - mse: 2159689.5484 - mae: 812.4638 - val_loss: 3133271.0000 - val_mse: 3133271.0000 - val_mae: 1106.0817\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 127/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2171877.5910 - mse: 2171877.5910 - mae: 805.5421 - val_loss: 3315459.0000 - val_mse: 3315459.0000 - val_mae: 1118.6647\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 128/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2113016.2237 - mse: 2113016.2237 - mae: 800.7628 - val_loss: 2351742.2500 - val_mse: 2351742.2500 - val_mae: 986.3180\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 129/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2220105.3067 - mse: 2220105.3067 - mae: 806.9609 - val_loss: 2228097.2500 - val_mse: 2228097.2500 - val_mae: 959.3346\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 130/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2170127.1334 - mse: 2170127.1334 - mae: 806.3241 - val_loss: 2248173.7500 - val_mse: 2248173.7500 - val_mae: 977.2917\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 131/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2172826.9024 - mse: 2172826.9024 - mae: 812.4544 - val_loss: 2924581.0000 - val_mse: 2924581.0000 - val_mae: 1055.3091\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 132/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2215536.2764 - mse: 2215536.2764 - mae: 806.3205 - val_loss: 3171313.2500 - val_mse: 3171313.2500 - val_mae: 1086.9724\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 133/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2152348.6391 - mse: 2152348.6391 - mae: 803.2988 - val_loss: 2734682.7500 - val_mse: 2734682.7500 - val_mae: 1054.6906\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 134/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2158938.9070 - mse: 2158938.9070 - mae: 809.3358 - val_loss: 3203914.0000 - val_mse: 3203914.0000 - val_mae: 1104.6399\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 135/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2084505.4488 - mse: 2084505.4488 - mae: 801.3878 - val_loss: 2304066.2500 - val_mse: 2304066.2500 - val_mae: 934.8118\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 136/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2186157.9079 - mse: 2186157.9079 - mae: 810.4783 - val_loss: 2148095.7500 - val_mse: 2148095.7500 - val_mae: 930.7741\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 137/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2121812.2039 - mse: 2121812.2039 - mae: 795.8023 - val_loss: 2487471.5000 - val_mse: 2487471.5000 - val_mae: 983.9398\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 138/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2123010.5833 - mse: 2123010.5833 - mae: 794.2244 - val_loss: 2919200.5000 - val_mse: 2919200.5000 - val_mae: 1027.8835\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2082453.9962 - mse: 2082453.9962 - mae: 794.2397 - val_loss: 3151636.2500 - val_mse: 3151636.2500 - val_mae: 1064.6586\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 140/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2057120.0623 - mse: 2057120.0623 - mae: 789.2631 - val_loss: 2858949.2500 - val_mse: 2858949.2500 - val_mae: 1019.6384\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 141/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2037008.9041 - mse: 2037008.9041 - mae: 787.8157 - val_loss: 3854742.7500 - val_mse: 3854742.7500 - val_mae: 1168.6547\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 142/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2166239.7357 - mse: 2166239.7357 - mae: 816.5587 - val_loss: 1829626.2500 - val_mse: 1829626.2500 - val_mae: 889.9682\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 143/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2057189.2030 - mse: 2057189.2030 - mae: 795.5822 - val_loss: 2044180.7500 - val_mse: 2044180.7500 - val_mae: 893.7388\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 144/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2133027.0956 - mse: 2133027.0956 - mae: 810.5160 - val_loss: 2471439.0000 - val_mse: 2471439.0000 - val_mae: 988.7609\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 145/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2050962.1678 - mse: 2050962.1678 - mae: 789.8266 - val_loss: 2784225.7500 - val_mse: 2784225.7500 - val_mae: 995.3273\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 146/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2108464.3907 - mse: 2108464.3907 - mae: 800.8997 - val_loss: 2686544.5000 - val_mse: 2686544.5000 - val_mae: 1015.0646\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 147/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2160598.9152 - mse: 2160598.9152 - mae: 805.3599 - val_loss: 2533967.7500 - val_mse: 2533967.7500 - val_mae: 963.4189\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 148/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2124140.3480 - mse: 2124140.3480 - mae: 798.5403 - val_loss: 2617245.5000 - val_mse: 2617245.5000 - val_mae: 1003.5876\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 149/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2162811.2858 - mse: 2162811.2858 - mae: 803.7843 - val_loss: 2345526.7500 - val_mse: 2345526.7500 - val_mae: 956.4406\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 150/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2090634.6942 - mse: 2090634.6942 - mae: 797.6914 - val_loss: 2644060.0000 - val_mse: 2644060.0000 - val_mae: 967.3745\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 151/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2078162.5680 - mse: 2078162.5680 - mae: 790.1327 - val_loss: 2333386.0000 - val_mse: 2333386.0000 - val_mae: 947.8950\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 152/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2189939.6694 - mse: 2189939.6694 - mae: 803.0537 - val_loss: 2910665.7500 - val_mse: 2910665.7500 - val_mae: 1006.6766\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 153/300\n",
      "683/683 [==============================] - 5s 8ms/step - loss: 2162565.2763 - mse: 2162565.2763 - mae: 808.2630 - val_loss: 2376722.2500 - val_mse: 2376722.2500 - val_mae: 917.9172\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 154/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2024786.3911 - mse: 2024786.3911 - mae: 785.0674 - val_loss: 2521786.2500 - val_mse: 2521786.2500 - val_mae: 948.3665\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 155/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2176466.8628 - mse: 2176466.8628 - mae: 811.6424 - val_loss: 2719012.7500 - val_mse: 2719012.7500 - val_mae: 1029.7095\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 156/300\n",
      "683/683 [==============================] - 5s 7ms/step - loss: 2110679.0840 - mse: 2110679.0840 - mae: 797.6252 - val_loss: 3243863.7500 - val_mse: 3243863.7500 - val_mae: 1074.0291\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 157/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2121766.3480 - mse: 2121766.3480 - mae: 796.8818 - val_loss: 2108591.0000 - val_mse: 2108591.0000 - val_mae: 932.6373\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 158/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2231915.1115 - mse: 2231915.1115 - mae: 814.5376 - val_loss: 2681191.2500 - val_mse: 2681191.2500 - val_mae: 1030.2562\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 159/300\n",
      "683/683 [==============================] - 5s 7ms/step - loss: 2118355.1011 - mse: 2118355.1011 - mae: 798.0446 - val_loss: 3302985.0000 - val_mse: 3302985.0000 - val_mae: 1093.0881\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 160/300\n",
      "683/683 [==============================] - 5s 7ms/step - loss: 2077270.1104 - mse: 2077270.1104 - mae: 798.0777 - val_loss: 2616505.2500 - val_mse: 2616505.2500 - val_mae: 961.0106\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 161/300\n",
      "683/683 [==============================] - 5s 7ms/step - loss: 2165961.6288 - mse: 2165961.6288 - mae: 801.4640 - val_loss: 2498471.2500 - val_mse: 2498471.2500 - val_mae: 953.5193\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2098271.8655 - mse: 2098271.8655 - mae: 800.0998 - val_loss: 2358947.2500 - val_mse: 2358947.2500 - val_mae: 968.8204\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 163/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2087099.9675 - mse: 2087099.9675 - mae: 792.8589 - val_loss: 2476583.0000 - val_mse: 2476583.0000 - val_mae: 979.2433\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 164/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2060955.6120 - mse: 2060955.6120 - mae: 788.0543 - val_loss: 2954725.0000 - val_mse: 2954725.0000 - val_mae: 1000.3990\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 165/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2083988.8299 - mse: 2083988.8299 - mae: 791.1176 - val_loss: 2294501.2500 - val_mse: 2294501.2500 - val_mae: 914.8052\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 166/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2003528.2312 - mse: 2003528.2312 - mae: 788.1516 - val_loss: 3142805.0000 - val_mse: 3142805.0000 - val_mae: 1042.9843\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 167/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2139891.1866 - mse: 2139891.1866 - mae: 796.7506 - val_loss: 2697908.7500 - val_mse: 2697908.7500 - val_mae: 970.1663\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 168/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2137330.9211 - mse: 2137330.9211 - mae: 804.6627 - val_loss: 2567566.0000 - val_mse: 2567566.0000 - val_mae: 949.4002\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 169/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2139933.4717 - mse: 2139933.4717 - mae: 803.5017 - val_loss: 3209871.2500 - val_mse: 3209871.2500 - val_mae: 1028.4900\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 170/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2026080.1683 - mse: 2026080.1683 - mae: 788.6410 - val_loss: 2851225.0000 - val_mse: 2851225.0000 - val_mae: 1009.6120\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 171/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2044343.2752 - mse: 2044343.2752 - mae: 786.1956 - val_loss: 2609903.2500 - val_mse: 2609903.2500 - val_mae: 973.4452\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 172/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1965110.3609 - mse: 1965110.3609 - mae: 781.0388 - val_loss: 2733959.0000 - val_mse: 2733959.0000 - val_mae: 984.8585\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 173/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1897830.7566 - mse: 1897830.7566 - mae: 767.2088 - val_loss: 2607350.7500 - val_mse: 2607350.7500 - val_mae: 982.9566\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 174/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2101951.1321 - mse: 2101951.1321 - mae: 795.2261 - val_loss: 3113145.7500 - val_mse: 3113145.7500 - val_mae: 1034.4618\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 175/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2019071.1687 - mse: 2019071.1687 - mae: 789.5379 - val_loss: 2515784.2500 - val_mse: 2515784.2500 - val_mae: 944.3255\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 176/300\n",
      "683/683 [==============================] - 5s 7ms/step - loss: 2108437.2520 - mse: 2108437.2520 - mae: 791.9001 - val_loss: 2478681.5000 - val_mse: 2478681.5000 - val_mae: 938.6631\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 177/300\n",
      "683/683 [==============================] - 5s 7ms/step - loss: 2122013.0026 - mse: 2122013.0026 - mae: 801.1082 - val_loss: 3154022.0000 - val_mse: 3154022.0000 - val_mae: 1029.0702\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 178/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2047833.7814 - mse: 2047833.7814 - mae: 791.6543 - val_loss: 2367325.2500 - val_mse: 2367325.2500 - val_mae: 931.6636\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 179/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2111090.2222 - mse: 2111090.2222 - mae: 795.3729 - val_loss: 2795239.2500 - val_mse: 2795239.2500 - val_mae: 957.9167\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 180/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2087915.3872 - mse: 2087915.3872 - mae: 794.5893 - val_loss: 3014522.2500 - val_mse: 3014522.2500 - val_mae: 1018.0903\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 181/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2160860.3342 - mse: 2160860.3342 - mae: 800.8351 - val_loss: 2372362.5000 - val_mse: 2372362.5000 - val_mae: 909.2814\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 182/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2080812.0291 - mse: 2080812.0291 - mae: 797.6933 - val_loss: 2810770.0000 - val_mse: 2810770.0000 - val_mae: 952.4299\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 183/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2005338.0576 - mse: 2005338.0576 - mae: 784.1294 - val_loss: 2629536.0000 - val_mse: 2629536.2500 - val_mae: 970.6489\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 184/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2092457.9762 - mse: 2092457.9762 - mae: 790.8171 - val_loss: 2600279.7500 - val_mse: 2600279.7500 - val_mae: 946.7703\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2130914.7405 - mse: 2130914.7405 - mae: 797.6582 - val_loss: 2713485.2500 - val_mse: 2713485.2500 - val_mae: 974.9086\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 186/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2173022.5718 - mse: 2173022.5718 - mae: 802.3420 - val_loss: 2696519.2500 - val_mse: 2696519.2500 - val_mae: 982.4213\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 187/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2046883.1663 - mse: 2046883.1663 - mae: 782.7410 - val_loss: 2562772.0000 - val_mse: 2562772.0000 - val_mae: 928.8420\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 188/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2176499.1687 - mse: 2176499.1687 - mae: 795.8229 - val_loss: 2978180.7500 - val_mse: 2978180.7500 - val_mae: 990.3716\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 189/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1983866.6491 - mse: 1983866.6491 - mae: 774.1713 - val_loss: 2735213.5000 - val_mse: 2735213.5000 - val_mae: 959.3050\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 190/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1960091.1864 - mse: 1960091.1864 - mae: 773.0121 - val_loss: 2494223.2500 - val_mse: 2494223.2500 - val_mae: 928.1495\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 191/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2143666.7652 - mse: 2143666.7652 - mae: 794.1584 - val_loss: 2797547.0000 - val_mse: 2797547.0000 - val_mae: 970.5140\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 192/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2071830.2725 - mse: 2071830.2725 - mae: 790.9785 - val_loss: 2650567.5000 - val_mse: 2650567.5000 - val_mae: 950.6892\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 193/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2003842.0668 - mse: 2003842.0668 - mae: 780.6798 - val_loss: 2713813.2500 - val_mse: 2713813.2500 - val_mae: 987.0540\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 194/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2145254.5630 - mse: 2145254.5630 - mae: 795.3801 - val_loss: 2334383.2500 - val_mse: 2334383.2500 - val_mae: 909.9207\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 195/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2025940.4838 - mse: 2025940.4838 - mae: 779.7738 - val_loss: 2943073.5000 - val_mse: 2943073.5000 - val_mae: 1001.6268\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 196/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1954807.1146 - mse: 1954807.1146 - mae: 769.4018 - val_loss: 3430181.7500 - val_mse: 3430181.7500 - val_mae: 1066.2258\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 197/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2050938.6034 - mse: 2050938.6034 - mae: 787.9016 - val_loss: 3219331.2500 - val_mse: 3219331.2500 - val_mae: 1052.4769\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 198/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1991946.1526 - mse: 1991946.1526 - mae: 779.9220 - val_loss: 3360917.7500 - val_mse: 3360917.7500 - val_mae: 1032.5173\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 199/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2044422.8704 - mse: 2044422.8704 - mae: 777.2229 - val_loss: 2662223.7500 - val_mse: 2662223.7500 - val_mae: 969.6736\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 200/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2215243.4446 - mse: 2215243.4446 - mae: 804.6641 - val_loss: 2878117.7500 - val_mse: 2878117.7500 - val_mae: 1014.7208\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 201/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2051002.4963 - mse: 2051002.4963 - mae: 782.0743 - val_loss: 2829726.7500 - val_mse: 2829726.7500 - val_mae: 1013.5157\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 202/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2170881.7763 - mse: 2170881.7763 - mae: 803.1038 - val_loss: 2757645.0000 - val_mse: 2757645.0000 - val_mae: 1012.4143\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 203/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1958549.9664 - mse: 1958549.9664 - mae: 775.0457 - val_loss: 3256704.5000 - val_mse: 3256704.5000 - val_mae: 1073.0527\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 204/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1969017.9304 - mse: 1969017.9304 - mae: 769.9132 - val_loss: 2337218.2500 - val_mse: 2337218.2500 - val_mae: 936.5601\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 205/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2061568.6255 - mse: 2061568.6255 - mae: 791.1766 - val_loss: 2846509.5000 - val_mse: 2846509.5000 - val_mae: 1007.5150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 206/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2063806.8750 - mse: 2063806.8750 - mae: 787.8962 - val_loss: 2822154.5000 - val_mse: 2822154.5000 - val_mae: 965.3005\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 207/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1985810.6341 - mse: 1985810.6341 - mae: 776.0378 - val_loss: 2883026.2500 - val_mse: 2883026.2500 - val_mae: 994.1785\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2026747.0519 - mse: 2026747.0519 - mae: 772.8593 - val_loss: 3080861.0000 - val_mse: 3080861.0000 - val_mae: 1016.9347\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 209/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2040456.2440 - mse: 2040456.2440 - mae: 776.4869 - val_loss: 3176409.0000 - val_mse: 3176409.0000 - val_mae: 1038.7819\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 210/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2099546.6933 - mse: 2099546.6933 - mae: 795.2692 - val_loss: 2823524.0000 - val_mse: 2823524.0000 - val_mae: 998.7748\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 211/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2006859.2694 - mse: 2006859.2694 - mae: 778.7735 - val_loss: 3373122.0000 - val_mse: 3373122.0000 - val_mae: 1056.4623\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 212/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2087233.7658 - mse: 2087233.7658 - mae: 788.7162 - val_loss: 3028953.0000 - val_mse: 3028953.0000 - val_mae: 984.7004\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 213/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2025700.0345 - mse: 2025700.0345 - mae: 785.7508 - val_loss: 2303929.0000 - val_mse: 2303929.0000 - val_mae: 918.7272\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 214/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1994770.0736 - mse: 1994770.0736 - mae: 780.1575 - val_loss: 2419931.7500 - val_mse: 2419931.7500 - val_mae: 922.2327\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 215/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2130615.6438 - mse: 2130615.6438 - mae: 786.7264 - val_loss: 2523556.5000 - val_mse: 2523556.5000 - val_mae: 925.9272\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 216/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2058061.0994 - mse: 2058061.0994 - mae: 786.9699 - val_loss: 2719187.2500 - val_mse: 2719187.2500 - val_mae: 962.0145\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 217/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2001847.3783 - mse: 2001847.3783 - mae: 779.9068 - val_loss: 2317750.2500 - val_mse: 2317750.2500 - val_mae: 923.1399\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 218/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1985078.1610 - mse: 1985078.1610 - mae: 768.1986 - val_loss: 2665968.0000 - val_mse: 2665968.0000 - val_mae: 949.7265\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 219/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2006524.7208 - mse: 2006524.7208 - mae: 783.1401 - val_loss: 2916548.0000 - val_mse: 2916548.0000 - val_mae: 1000.6854\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 220/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1997992.6361 - mse: 1997992.6361 - mae: 777.9407 - val_loss: 2793604.7500 - val_mse: 2793604.7500 - val_mae: 986.3958\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 221/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 2094568.9077 - mse: 2094568.9077 - mae: 787.7643 - val_loss: 2847255.7500 - val_mse: 2847255.7500 - val_mae: 971.1230\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 222/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2002718.0610 - mse: 2002718.0610 - mae: 774.1638 - val_loss: 2574929.7500 - val_mse: 2574929.7500 - val_mae: 931.3149\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 223/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2071088.4726 - mse: 2071088.4726 - mae: 786.3000 - val_loss: 3147559.2500 - val_mse: 3147559.2500 - val_mae: 1006.5975\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 224/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2045979.9912 - mse: 2045979.9912 - mae: 783.5388 - val_loss: 2639875.5000 - val_mse: 2639875.5000 - val_mae: 939.6100\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 225/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2090751.7849 - mse: 2090751.7849 - mae: 784.9864 - val_loss: 2571487.7500 - val_mse: 2571487.7500 - val_mae: 939.3495\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 226/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1973618.7261 - mse: 1973618.7261 - mae: 769.3801 - val_loss: 2325303.5000 - val_mse: 2325303.5000 - val_mae: 919.8842\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 227/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2072629.2195 - mse: 2072629.2195 - mae: 787.1209 - val_loss: 2857366.0000 - val_mse: 2857366.0000 - val_mae: 959.3068\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 228/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1960889.3147 - mse: 1960889.3147 - mae: 772.0611 - val_loss: 2672987.5000 - val_mse: 2672987.5000 - val_mae: 927.2468\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 229/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2029745.9496 - mse: 2029745.9496 - mae: 776.0760 - val_loss: 2978921.0000 - val_mse: 2978921.0000 - val_mae: 969.9952\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 230/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2045763.7584 - mse: 2045763.7584 - mae: 777.6431 - val_loss: 2699568.0000 - val_mse: 2699568.0000 - val_mae: 930.3646\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1918058.5689 - mse: 1918058.5689 - mae: 758.5377 - val_loss: 2858791.0000 - val_mse: 2858791.0000 - val_mae: 962.1059\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 232/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2069938.2579 - mse: 2069938.2579 - mae: 779.5960 - val_loss: 3449417.2500 - val_mse: 3449417.2500 - val_mae: 1033.0093\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 233/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2020736.1946 - mse: 2020736.1946 - mae: 776.6064 - val_loss: 2895309.2500 - val_mse: 2895309.2500 - val_mae: 981.3618\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 234/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1972665.1389 - mse: 1972665.1389 - mae: 768.9448 - val_loss: 2479899.7500 - val_mse: 2479899.7500 - val_mae: 935.5394\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 235/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2132923.8393 - mse: 2132923.8393 - mae: 785.1623 - val_loss: 3177917.0000 - val_mse: 3177917.0000 - val_mae: 1012.6613\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 236/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1941821.0592 - mse: 1941821.0592 - mae: 769.9467 - val_loss: 3563954.2500 - val_mse: 3563954.2500 - val_mae: 1040.7018\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 237/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2101569.9317 - mse: 2101569.9317 - mae: 793.3917 - val_loss: 2991611.7500 - val_mse: 2991611.7500 - val_mae: 969.4753\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 238/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1796100.4830 - mse: 1796100.4830 - mae: 746.4120 - val_loss: 2763981.0000 - val_mse: 2763981.0000 - val_mae: 948.1174\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 239/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2037617.9724 - mse: 2037617.9724 - mae: 773.0513 - val_loss: 2547727.2500 - val_mse: 2547727.2500 - val_mae: 908.2756\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 240/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2044256.2078 - mse: 2044256.2078 - mae: 778.8346 - val_loss: 3194619.2500 - val_mse: 3194619.2500 - val_mae: 1009.5374\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 241/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1915859.2390 - mse: 1915859.2390 - mae: 758.2935 - val_loss: 2351834.2500 - val_mse: 2351834.2500 - val_mae: 883.5414\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 242/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1964445.1641 - mse: 1964445.1641 - mae: 767.5591 - val_loss: 2497705.2500 - val_mse: 2497705.2500 - val_mae: 907.7904\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 243/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2018484.1897 - mse: 2018484.1897 - mae: 775.6012 - val_loss: 2882593.7500 - val_mse: 2882593.7500 - val_mae: 959.1405\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 244/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 2003019.6340 - mse: 2003019.6340 - mae: 774.0342 - val_loss: 2722414.0000 - val_mse: 2722414.0000 - val_mae: 963.7810\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 245/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2074114.5181 - mse: 2074114.5181 - mae: 783.0759 - val_loss: 2828885.2500 - val_mse: 2828885.2500 - val_mae: 955.1431\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 246/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1966042.3551 - mse: 1966042.3551 - mae: 769.9937 - val_loss: 3038680.2500 - val_mse: 3038680.2500 - val_mae: 964.3989\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 247/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2016078.6981 - mse: 2016078.6981 - mae: 770.6676 - val_loss: 2716672.0000 - val_mse: 2716672.0000 - val_mae: 948.1896\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 248/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1982808.9558 - mse: 1982808.9558 - mae: 765.7988 - val_loss: 2677235.2500 - val_mse: 2677235.2500 - val_mae: 921.3589\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 249/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1984254.5764 - mse: 1984254.5764 - mae: 769.8964 - val_loss: 2818154.0000 - val_mse: 2818154.0000 - val_mae: 953.4731\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 250/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1976052.7279 - mse: 1976052.7279 - mae: 764.3609 - val_loss: 2595715.0000 - val_mse: 2595715.0000 - val_mae: 912.8656\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 251/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2004058.2370 - mse: 2004058.2370 - mae: 769.9127 - val_loss: 3028583.2500 - val_mse: 3028583.2500 - val_mae: 954.3799\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 252/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2033125.6149 - mse: 2033125.6149 - mae: 777.9341 - val_loss: 2411482.0000 - val_mse: 2411482.0000 - val_mae: 877.6417\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 253/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1918027.9457 - mse: 1918027.9457 - mae: 758.5076 - val_loss: 2655614.2500 - val_mse: 2655614.2500 - val_mae: 900.5144\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1827291.3299 - mse: 1827291.3299 - mae: 747.0108 - val_loss: 3048927.5000 - val_mse: 3048927.5000 - val_mae: 989.9203\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 255/300\n",
      "683/683 [==============================] - 2s 3ms/step - loss: 1900749.7480 - mse: 1900749.7480 - mae: 760.3922 - val_loss: 2356224.5000 - val_mse: 2356224.5000 - val_mae: 908.3765\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 256/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2080597.6047 - mse: 2080597.6047 - mae: 775.9286 - val_loss: 2750189.5000 - val_mse: 2750189.5000 - val_mae: 935.8127\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 257/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2015375.9295 - mse: 2015375.9295 - mae: 774.9910 - val_loss: 2851009.5000 - val_mse: 2851009.5000 - val_mae: 948.6365\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 258/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2111807.6087 - mse: 2111807.6087 - mae: 782.2414 - val_loss: 2835896.0000 - val_mse: 2835896.0000 - val_mae: 944.9772\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 259/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1925496.6570 - mse: 1925496.6570 - mae: 763.6035 - val_loss: 2702198.7500 - val_mse: 2702198.7500 - val_mae: 928.5276\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 260/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1948511.2675 - mse: 1948511.2675 - mae: 766.2494 - val_loss: 2423856.7500 - val_mse: 2423856.7500 - val_mae: 896.6193\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 261/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1931678.2265 - mse: 1931678.2265 - mae: 761.3732 - val_loss: 2812922.0000 - val_mse: 2812922.0000 - val_mae: 949.4838\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 262/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1972923.2431 - mse: 1972923.2431 - mae: 758.9536 - val_loss: 3419796.0000 - val_mse: 3419796.0000 - val_mae: 1010.6755\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 263/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1904795.4716 - mse: 1904795.4716 - mae: 759.3099 - val_loss: 2474199.5000 - val_mse: 2474199.5000 - val_mae: 885.7426\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 264/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1997753.6714 - mse: 1997753.6714 - mae: 766.2734 - val_loss: 3072638.2500 - val_mse: 3072638.2500 - val_mae: 990.7380\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 265/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1985789.2175 - mse: 1985789.2175 - mae: 772.0277 - val_loss: 3374673.2500 - val_mse: 3374673.2500 - val_mae: 1051.1611\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 266/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2152274.7641 - mse: 2152274.7641 - mae: 788.1578 - val_loss: 2759092.0000 - val_mse: 2759092.0000 - val_mae: 939.8063\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 267/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2010327.1264 - mse: 2010327.1264 - mae: 773.8121 - val_loss: 2670199.0000 - val_mse: 2670199.0000 - val_mae: 940.6118\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 268/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1999443.6736 - mse: 1999443.6736 - mae: 771.3317 - val_loss: 2646429.7500 - val_mse: 2646429.7500 - val_mae: 929.2192\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 269/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1946983.4483 - mse: 1946983.4483 - mae: 767.5526 - val_loss: 2769137.0000 - val_mse: 2769137.0000 - val_mae: 958.1750\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 270/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1846125.7562 - mse: 1846125.7562 - mae: 750.8920 - val_loss: 2786831.0000 - val_mse: 2786831.0000 - val_mae: 955.5875\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 271/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1932497.1537 - mse: 1932497.1537 - mae: 762.6253 - val_loss: 2431284.2500 - val_mse: 2431284.2500 - val_mae: 886.9886\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 272/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 2091827.6542 - mse: 2091827.6542 - mae: 776.8341 - val_loss: 2633604.7500 - val_mse: 2633604.7500 - val_mae: 922.8868\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 273/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1993414.1923 - mse: 1993414.1923 - mae: 765.8433 - val_loss: 3442510.2500 - val_mse: 3442510.2500 - val_mae: 1021.7132\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 274/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1959849.4733 - mse: 1959849.4733 - mae: 767.2472 - val_loss: 2603197.5000 - val_mse: 2603197.5000 - val_mae: 902.0028\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 275/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1921403.4108 - mse: 1921403.4108 - mae: 754.0561 - val_loss: 2660294.5000 - val_mse: 2660294.5000 - val_mae: 915.9838\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 276/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1909989.2145 - mse: 1909989.2145 - mae: 752.5554 - val_loss: 2475838.5000 - val_mse: 2475838.5000 - val_mae: 891.0881\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1978136.8925 - mse: 1978136.8925 - mae: 758.9887 - val_loss: 2867631.2500 - val_mse: 2867631.2500 - val_mae: 945.2579\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 278/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1903390.4152 - mse: 1903390.4152 - mae: 756.9184 - val_loss: 3010057.2500 - val_mse: 3010057.2500 - val_mae: 992.5686\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 279/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1987750.0309 - mse: 1987750.0309 - mae: 766.1537 - val_loss: 2291686.5000 - val_mse: 2291686.5000 - val_mae: 860.2595\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 280/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1914895.0486 - mse: 1914895.0486 - mae: 760.2269 - val_loss: 2904162.0000 - val_mse: 2904162.0000 - val_mae: 953.3854\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 281/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1955205.0296 - mse: 1955205.0296 - mae: 756.9862 - val_loss: 2637463.5000 - val_mse: 2637463.5000 - val_mae: 928.5490\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 282/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1963808.1550 - mse: 1963808.1550 - mae: 762.5401 - val_loss: 2743007.5000 - val_mse: 2743007.5000 - val_mae: 926.7407\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 283/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1896585.2582 - mse: 1896585.2582 - mae: 754.4591 - val_loss: 2366075.2500 - val_mse: 2366075.2500 - val_mae: 886.4249\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 284/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1933296.7003 - mse: 1933296.7003 - mae: 760.6247 - val_loss: 3145473.2500 - val_mse: 3145473.2500 - val_mae: 964.3484\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 285/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1950885.7732 - mse: 1950885.7732 - mae: 762.4538 - val_loss: 2459959.5000 - val_mse: 2459959.5000 - val_mae: 884.5239\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 286/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2024456.4435 - mse: 2024456.4435 - mae: 766.3676 - val_loss: 2690278.2500 - val_mse: 2690278.2500 - val_mae: 897.9970\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 287/300\n",
      "683/683 [==============================] - 3s 4ms/step - loss: 1953989.9497 - mse: 1953989.9497 - mae: 759.0165 - val_loss: 2951024.7500 - val_mse: 2951024.7500 - val_mae: 960.3149\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 288/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1980282.9088 - mse: 1980282.9088 - mae: 770.0933 - val_loss: 2625396.2500 - val_mse: 2625396.2500 - val_mae: 893.0980\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 289/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1969582.5080 - mse: 1969582.5080 - mae: 767.6646 - val_loss: 2437883.5000 - val_mse: 2437883.5000 - val_mae: 892.4797\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 290/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1929428.1859 - mse: 1929428.1859 - mae: 759.4590 - val_loss: 2827285.7500 - val_mse: 2827285.7500 - val_mae: 938.6981\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 291/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1924130.8087 - mse: 1924130.8087 - mae: 752.6271 - val_loss: 2816075.5000 - val_mse: 2816075.5000 - val_mae: 958.0764\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 292/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1944503.6079 - mse: 1944503.6079 - mae: 760.1185 - val_loss: 3085869.2500 - val_mse: 3085869.2500 - val_mae: 963.0133\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 293/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1881918.9061 - mse: 1881918.9061 - mae: 752.6185 - val_loss: 2866147.5000 - val_mse: 2866147.5000 - val_mae: 937.2440\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 294/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1863253.4081 - mse: 1863253.4081 - mae: 754.5624 - val_loss: 2490629.5000 - val_mse: 2490629.5000 - val_mae: 914.3364\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 295/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 1913098.2898 - mse: 1913098.2898 - mae: 758.1213 - val_loss: 2495698.5000 - val_mse: 2495698.5000 - val_mae: 895.7334\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 296/300\n",
      "683/683 [==============================] - 3s 5ms/step - loss: 2004272.3763 - mse: 2004272.3763 - mae: 773.2461 - val_loss: 2316137.2500 - val_mse: 2316137.2500 - val_mae: 879.3145\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 297/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1916472.5744 - mse: 1916472.5744 - mae: 757.2820 - val_loss: 2522398.7500 - val_mse: 2522398.7500 - val_mae: 887.3859\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 298/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1978500.7230 - mse: 1978500.7230 - mae: 766.3057 - val_loss: 2809855.7500 - val_mse: 2809855.7500 - val_mae: 924.5958\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n",
      "Epoch 299/300\n",
      "683/683 [==============================] - 4s 5ms/step - loss: 1954199.9311 - mse: 1954199.9311 - mae: 757.5595 - val_loss: 2573085.7500 - val_mse: 2573085.7500 - val_mae: 877.8364\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "683/683 [==============================] - 4s 6ms/step - loss: 1977639.5133 - mse: 1977639.5133 - mae: 764.0773 - val_loss: 2611589.7500 - val_mse: 2611589.7500 - val_mae: 906.6702\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: loss,mse,mae,val_loss,val_mse,val_mae\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 300\n",
    "early_stoping = EarlyStopping(monitor='val_mean_absolute_error',\n",
    "                              min_delta=5,\n",
    "                              patience=40,\n",
    "                              verbose=1,\n",
    "                              mode='auto')\n",
    "\n",
    "history = nn_reg_dropout.fit(X_train, y_train,\n",
    "                      epochs=n_epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      validation_split=0.1,\n",
    "                      callbacks=[early_stoping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(history.history['mse'], label='Train MAE')\n",
    "ax.plot(history.history['val_mae'], label='Validation MAE')\n",
    "ax.set_title(\"MAE vs. epochs using dropout\", fontsize=15)\n",
    "ax.set_xlabel(\"epoch number\", fontsize=14)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8.2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6cf82ae82e828d200fab7f5ba9abf59b6516bb6b46a916fa44930a67d435a4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
